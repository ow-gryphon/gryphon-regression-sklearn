{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4553245",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <span style=\"font-size:20px\">&#9888;</span> <span style=\"font-size:16px\">This is a read-only notebook! If you want to make and save changes, save a copy by clicking on <b>File</b> &#8594; <b>Save a copy</b>. If this is already a copy, you can delete this cell.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a492c97",
   "metadata": {},
   "source": [
    "<h1>Model calibration and fit for sklearn regressions<span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32cd72",
   "metadata": {},
   "source": [
    "This notebook illustrates how to calibrate and calculate fit for a variety of sklearn regression models:\n",
    "* sklearn's linear_model family, with and without regularization\n",
    "* Decision trees: DecisionTreeRegressor \n",
    "* Basic ensemble methods: Random Forest and Gradient Boosting\n",
    "\n",
    "We make use of train-test splits (insample & out-of-sample), and where necessary also cross-validation for purposes of hyperparameter tuning. \n",
    "\n",
    "Explicit variable selection is covered in the notebook \"sklearn Linear Model Variable Selection\". Some models, such as regularized models (LASSO, Elastic Net) and tree-based models have \"built-in\" feature selection, and are covered in this notebook.\n",
    "\n",
    "**All sklearn models follow a similar approach:**\n",
    "1. Instantiate the model class (e.g. LinearRegression, LASSO, RandomForest, etc.) with relevant parameters (e.g. intercept, complexity / regularization penalty)\n",
    "2. Fit model on the train dataset\n",
    "3. Apply model on train and test dataset, and explore the model further using e.g. metrics (https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) and/or plots such as those provided by the \"model diagnostics\" template\n",
    "\n",
    "Some models benefit from hyperparameter tuning as part of Step 1, and we will cover Hyper-Parameter tuning for the model types that most benefit from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cdf3d",
   "metadata": {},
   "source": [
    "<h2>Table of Contents<span class=\"tocSkip\"></span></h2>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Import-key-libraries\" data-toc-modified-id=\"Import-key-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import key libraries</a></span></li><li><span><a href=\"#Data-import-and-preparation\" data-toc-modified-id=\"Data-import-and-preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data import and preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-Test-split\" data-toc-modified-id=\"Train-Test-split-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Train-Test split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-train-test-split\" data-toc-modified-id=\"Random-train-test-split-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Random train-test split</a></span></li><li><span><a href=\"#Stratified-train-test-split\" data-toc-modified-id=\"Stratified-train-test-split-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Stratified train-test split</a></span></li><li><span><a href=\"#Random-sample-taken-based-on-a-subject-variable-(e.g.-Customer)\" data-toc-modified-id=\"Random-sample-taken-based-on-a-subject-variable-(e.g.-Customer)-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Random sample taken based on a subject variable (e.g. Customer)</a></span></li><li><span><a href=\"#Time/value-based-splitting\" data-toc-modified-id=\"Time/value-based-splitting-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Time/value based splitting</a></span></li></ul></li><li><span><a href=\"#Data-transformations\" data-toc-modified-id=\"Data-transformations-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data transformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transform-the-train-dataset\" data-toc-modified-id=\"Transform-the-train-dataset-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Transform the train dataset</a></span></li><li><span><a href=\"#Transform-the-test-dataset\" data-toc-modified-id=\"Transform-the-test-dataset-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Transform the test dataset</a></span></li></ul></li></ul></li><li><span><a href=\"#Linear-model-calibration\" data-toc-modified-id=\"Linear-model-calibration-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Linear model calibration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-regression-(OLS)-without-regularization\" data-toc-modified-id=\"Linear-regression-(OLS)-without-regularization-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Linear regression (OLS) without regularization</a></span></li><li><span><a href=\"#Generalized-Linear-Models\" data-toc-modified-id=\"Generalized-Linear-Models-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generalized Linear Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gamma-regression\" data-toc-modified-id=\"Gamma-regression-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Gamma regression</a></span></li><li><span><a href=\"#Experimental-GLM-regression\" data-toc-modified-id=\"Experimental-GLM-regression-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Experimental GLM regression</a></span></li></ul></li><li><span><a href=\"#Quantile-regression\" data-toc-modified-id=\"Quantile-regression-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Quantile regression</a></span></li><li><span><a href=\"#LASSO-regression-with-hyperparameter-tuning-(for-penalty-parameter)\" data-toc-modified-id=\"LASSO-regression-with-hyperparameter-tuning-(for-penalty-parameter)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>LASSO regression with hyperparameter tuning (for penalty parameter)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lasso-Cross-Validation-for-tuning-alpha-penalty-parameter\" data-toc-modified-id=\"Lasso-Cross-Validation-for-tuning-alpha-penalty-parameter-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Lasso Cross-Validation for tuning alpha penalty parameter</a></span></li><li><span><a href=\"#Lasso-calibration-for-a-single-alpha-penalty-parameter\" data-toc-modified-id=\"Lasso-calibration-for-a-single-alpha-penalty-parameter-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Lasso calibration for a single alpha penalty parameter</a></span></li><li><span><a href=\"#Lasso-calibration-for-multiple-alpha-penalty-parameters---TBD\" data-toc-modified-id=\"Lasso-calibration-for-multiple-alpha-penalty-parameters---TBD-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Lasso calibration for multiple alpha penalty parameters - TBD</a></span></li></ul></li><li><span><a href=\"#Elastic-Net\" data-toc-modified-id=\"Elastic-Net-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Elastic Net</a></span><ul class=\"toc-item\"><li><span><a href=\"#Elastic-Net-hyperparameter-tuning-of-alpha-and-l1_ratio-parameters\" data-toc-modified-id=\"Elastic-Net-hyperparameter-tuning-of-alpha-and-l1_ratio-parameters-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Elastic Net hyperparameter tuning of alpha and l1_ratio parameters</a></span></li><li><span><a href=\"#Elastic-Net-calibration-for-a-single-alpha-and-l1_ratio-penalty-parameter-pair\" data-toc-modified-id=\"Elastic-Net-calibration-for-a-single-alpha-and-l1_ratio-penalty-parameter-pair-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Elastic Net calibration for a single alpha and l1_ratio penalty parameter pair</a></span></li></ul></li></ul></li><li><span><a href=\"#Tree-based-methods\" data-toc-modified-id=\"Tree-based-methods-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Tree-based methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-decision-tree-regressions\" data-toc-modified-id=\"Binary-decision-tree-regressions-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Binary decision tree regressions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-a-single-decision-tree\" data-toc-modified-id=\"Training-a-single-decision-tree-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Training a single decision tree</a></span></li><li><span><a href=\"#Tuning-the-decision-tree-regression-using-Grid-Search\" data-toc-modified-id=\"Tuning-the-decision-tree-regression-using-Grid-Search-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Tuning the decision tree regression using Grid Search</a></span></li></ul></li><li><span><a href=\"#Random-Forest-regression\" data-toc-modified-id=\"Random-Forest-regression-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Random Forest regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tuning-the-random-forest-model-using-Grid-Search\" data-toc-modified-id=\"Tuning-the-random-forest-model-using-Grid-Search-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Tuning the random forest model using Grid Search</a></span></li><li><span><a href=\"#Fit-a-single-random-forest-model\" data-toc-modified-id=\"Fit-a-single-random-forest-model-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Fit a single random forest model</a></span></li><li><span><a href=\"#Examine-model-performance-across-trees-in-random-forest\" data-toc-modified-id=\"Examine-model-performance-across-trees-in-random-forest-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Examine model performance across trees in random forest</a></span></li></ul></li><li><span><a href=\"#Gradient-Boosted-Tree-Regression\" data-toc-modified-id=\"Gradient-Boosted-Tree-Regression-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Gradient Boosted Tree Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tuning-the-gradient-boosted-tree-regression-using-Randomized-Search\" data-toc-modified-id=\"Tuning-the-gradient-boosted-tree-regression-using-Randomized-Search-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Tuning the gradient boosted tree regression using Randomized Search</a></span></li><li><span><a href=\"#Fit-a-single-gradient-boosting-model\" data-toc-modified-id=\"Fit-a-single-gradient-boosting-model-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Fit a single gradient boosting model</a></span></li></ul></li></ul></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb399ec9",
   "metadata": {},
   "source": [
    "# Import key libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fdb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Formatting of pandas dataframe\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f38793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically update custom py scripts that are loaded in\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load in OW color scheme and plot style\n",
    "plt.style.use('../../utilities/resources/ow_style.mplstyle')\n",
    "\n",
    "# Add path of the folder 'resources' to the path from which we can import modules  \n",
    "import sys\n",
    "sys.path.insert(0, \"../../utilities\")\n",
    "from resources.ow_colormap import ow_colormap\n",
    "from regression import sklearn_regression_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab7c42",
   "metadata": {},
   "source": [
    "# Data import and preparation\n",
    "\n",
    "We will use a dataset for predicting car prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a378ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Levy</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prod. year</th>\n",
       "      <th>Category</th>\n",
       "      <th>Leather interior</th>\n",
       "      <th>Fuel type</th>\n",
       "      <th>Engine volume</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gear box type</th>\n",
       "      <th>Drive wheels</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Wheel</th>\n",
       "      <th>Color</th>\n",
       "      <th>Airbags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45654403</td>\n",
       "      <td>13328</td>\n",
       "      <td>1,399.0000</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>RX 450</td>\n",
       "      <td>2010</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>3.5</td>\n",
       "      <td>186005</td>\n",
       "      <td>6</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Silver</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44731507</td>\n",
       "      <td>16621</td>\n",
       "      <td>1,018.0000</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>Equinox</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>No</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3</td>\n",
       "      <td>192000</td>\n",
       "      <td>6</td>\n",
       "      <td>Tiptronic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45774419</td>\n",
       "      <td>8467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>FIT</td>\n",
       "      <td>2006</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>No</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1.3</td>\n",
       "      <td>200000</td>\n",
       "      <td>4</td>\n",
       "      <td>Variator</td>\n",
       "      <td>Front</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Right-hand drive</td>\n",
       "      <td>Black</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45769185</td>\n",
       "      <td>3607</td>\n",
       "      <td>862.0000</td>\n",
       "      <td>FORD</td>\n",
       "      <td>Escape</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2.5</td>\n",
       "      <td>168966</td>\n",
       "      <td>4</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45809263</td>\n",
       "      <td>11726</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>FIT</td>\n",
       "      <td>2014</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1.3</td>\n",
       "      <td>91901</td>\n",
       "      <td>4</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Front</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Silver</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Price       Levy Manufacturer    Model  Prod. year   Category  \\\n",
       "0  45654403  13328 1,399.0000        LEXUS   RX 450        2010       Jeep   \n",
       "1  44731507  16621 1,018.0000    CHEVROLET  Equinox        2011       Jeep   \n",
       "2  45774419   8467        NaN        HONDA      FIT        2006  Hatchback   \n",
       "3  45769185   3607   862.0000         FORD   Escape        2011       Jeep   \n",
       "4  45809263  11726   446.0000        HONDA      FIT        2014  Hatchback   \n",
       "\n",
       "  Leather interior Fuel type Engine volume  Mileage  Cylinders Gear box type  \\\n",
       "0              Yes    Hybrid           3.5   186005          6     Automatic   \n",
       "1               No    Petrol             3   192000          6     Tiptronic   \n",
       "2               No    Petrol           1.3   200000          4      Variator   \n",
       "3              Yes    Hybrid           2.5   168966          4     Automatic   \n",
       "4              Yes    Petrol           1.3    91901          4     Automatic   \n",
       "\n",
       "  Drive wheels Doors             Wheel   Color  Airbags  \n",
       "0          4x4   4/5        Left wheel  Silver       12  \n",
       "1          4x4   4/5        Left wheel   Black        8  \n",
       "2        Front   4/5  Right-hand drive   Black        2  \n",
       "3          4x4   4/5        Left wheel   White        0  \n",
       "4        Front   4/5        Left wheel  Silver        4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data using pandas, with low_memory=False in case the dataset is large\n",
    "raw_dataset = pd.read_csv(\"sample_input/car_price_prediction.csv\", low_memory=False)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15e69a",
   "metadata": {},
   "source": [
    "**To keep this notebook focused on model calibration, we remove outliers where price is below 5000 and above 100000**\n",
    "\n",
    "Refer to data exploration and model exploration templates for more in-depth analysis of the data itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ec9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset[(raw_dataset['Price'] >= 5000) & (raw_dataset['Price'] <= 100000)].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120f73e",
   "metadata": {},
   "source": [
    "## Train-Test split\n",
    "\n",
    "Regression models identify the relationship between a target variable (also known as dependent variable) and predictive (independent) variables found in the calibration data. \n",
    "\n",
    "To flexible and complex models may mis-interpret noise in the data as real signal, and thereby cause the model to overfit to the calibration data. Therefore, it is good practice to understand how the model performs on an 'unseen' portion of the dataset. This type of approach of splitting the data is often called 'train-test' split or in-sample vs. out-of-sample split. The idea is to use the train-sample to select variables and train your model, and review final candidate models on the test-sample to assess model performance. \n",
    "\n",
    "If you choose this approach, know that there are many ways to select how to split the data into train and test samples. It is important to keep in mind how the model will be used. \n",
    "* If the model is merely a descriptive model of the data you have gathered, then a random train-test split may be relevant\n",
    "* If your model is used to predict new data, the relationship between the 'new data' and 'current data' should be similar to the relationship between 'test data' and 'train data', so that the model's performance on new data is proxied by the test data. For example:\n",
    "    * If you are predicting the future of existing subjects (e.g. patients in a hospital), you will want the train-test split to be based on time\n",
    "    * If you are predicting the outcome of new subjects, you will want the train-test split to be based on subject\n",
    "\n",
    "**Note: Train-test splitting the data is not the only way to understand if a model is overfitted and its ability to generalize.** \n",
    "For example:\n",
    "* Cross-validation can be a good alternative especially when data is too limited for a train-test split\n",
    "* Some models have built-in capabilities (e.g. out-of-bag for random forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bf72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = dataset[\"Price\"]\n",
    "X = dataset[['Levy', 'Manufacturer', 'Model', 'Prod. year',\n",
    "       'Category', 'Leather interior', 'Fuel type', 'Engine volume',\n",
    "       'Mileage', 'Cylinders', 'Gear box type', 'Drive wheels', 'Doors',\n",
    "       'Wheel', 'Color', 'Airbags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0794e",
   "metadata": {},
   "source": [
    "**Below we show a few different ways to split this data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494939c",
   "metadata": {},
   "source": [
    "### Random train-test split\n",
    "\n",
    "75% train and 25% test dataset, random sampling across all data. The 'random_state' can be set to make it possible to recreate the sampling outcome.\n",
    "\n",
    "**This is the train-test split we will use in this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90a36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68986ef4",
   "metadata": {},
   "source": [
    "### Stratified train-test split\n",
    "\n",
    "Stratified sampling helps ensure the sampling rate to be applied separately to each strata, to improve representativeness to the original (full) dataset.\n",
    "\n",
    "**Here we stratify based by car Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbcc619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sedan</th>\n",
       "      <td>4768</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>3070</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hatchback</th>\n",
       "      <td>1603</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minivan</th>\n",
       "      <td>450</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coupe</th>\n",
       "      <td>322</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Universal</th>\n",
       "      <td>256</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microbus</th>\n",
       "      <td>213</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goods wagon</th>\n",
       "      <td>145</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup</th>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabriolet</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limousine</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Train  Test\n",
       "Sedan         4768  1590\n",
       "Jeep          3070  1023\n",
       "Hatchback     1603   534\n",
       "Minivan        450   150\n",
       "Coupe          322   108\n",
       "Universal      256    85\n",
       "Microbus       213    71\n",
       "Goods wagon    145    48\n",
       "Pickup          29    10\n",
       "Cabriolet       22     8\n",
       "Limousine        5     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stratified, X_test_stratified, y_train_stratified, y_test_stratified = train_test_split(X, y, test_size=0.25, stratify=X['Category'], random_state=1000)\n",
    "\n",
    "pd.DataFrame({\"Train\": X_train_stratified['Category'].value_counts(), \"Test\": X_test_stratified['Category'].value_counts()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8d036",
   "metadata": {},
   "source": [
    "### Random sample taken based on a subject variable (e.g. Customer)\n",
    "\n",
    "This approach ensures that every observation per subject (e.g. customer) will be in the same sample. Here we need to write our own implementation, for 'Model'. There are many ways to accomplish the sampling -- here we use the simplest: random sampling without replacement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ff9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_variable = \"Model\"\n",
    "test_size = 0.25\n",
    "seed = 1000\n",
    "\n",
    "# This works when there are no missing values for the subject variable\n",
    "unique_subjects = X[subject_variable].unique()\n",
    "N_subjects = len(unique_subjects)\n",
    "np.random.seed(seed)\n",
    "train_subject_idx = np.where(np.random.uniform(size = N_subjects) > test_size, 1, 0)\n",
    "train_subject = unique_subjects[train_subject_idx == 1]\n",
    "\n",
    "train_idx = X[subject_variable].isin(train_subject)\n",
    "X_train_subject, y_train_subject = X[train_idx], y[train_idx]\n",
    "X_test_subject, y_test_subject = X[~train_idx], y[~train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb6f13",
   "metadata": {},
   "source": [
    "### Time/value based splitting\n",
    "\n",
    "The train-test split can be done based on the value of a variable. Most frequently this is done using time, using e.g. using the most recent time-period for test sample for a model to be used to forecast into the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccaa58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_variable = \"Prod. year\"\n",
    "threshold = 2010\n",
    "\n",
    "train_idx = X[subject_variable] <= threshold\n",
    "X_train_time, y_train_time = X[train_idx], y[train_idx]\n",
    "X_test_time, y_test_time = X[~train_idx], y[~train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ab21c",
   "metadata": {},
   "source": [
    "## Data transformations\n",
    "\n",
    "Many data transformations can be applied to the dataset before performing the train / test split. However, some transformations are data dependent and have parameters that need to be calibrated (e.g. winsorization, median-imputation, standardization) on the train dataset, to make sure the test dataset remains representative of the data that the model will eventually be used on. \n",
    "\n",
    "Here, we will apply the data transformations to the train and then to the test dataset, and for transformations requiring calibration, we will calibrate on train and apply to the test dataset.\n",
    "\n",
    "To keep this notebook limited to model calibration and fit, we will apply some data transformations upfront, skipping the data exploration steps (separate templates exist for data diagnostics).\n",
    "\n",
    "Lastly, be careful with how you handle missing values. Many models cannot calibrate on missing data, so either impute the missing values (in some cases, you may want to impute the missing value and then create an indicator for whether the value was originally missing) or remove those rows using dropna. If you drop missing values, make sure your X and y datasets are still aligned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3fac9",
   "metadata": {},
   "source": [
    "### Transform the train dataset\n",
    "\n",
    "We perform the following transformations:\n",
    "* Bucket categorical variables to fewer buckets\n",
    "* Create 0-1 indicator variables based on values or intervals of variables\n",
    "* Impute missings of certain numerical variables to their median (requires calibration on train dataset)\n",
    "* Perform a functional transformation (log) on certain numerical variables\n",
    "* Convert categorical variables to 0-1 indicator variables. Keeping all indicators -- some models must have 1 indicator removed to avoid multicollinearity\n",
    "* Some categorical variables have too many unique values (high cardinality) to be converted to separate 0-1 variables. If categories cannot be grouped up to form a less diverse categorical variable, and the variable is very important, we can consider encoding it by mapping its values to numeric values, based on the target variable in the train data (e.g. average or median target value). This needs to be done carefully (refer to the Data Transformation template for more information)\n",
    "* Standardize continuous variables to a min of 0 and max of 1. The min and max used are calibrated on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d213ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform certain columns\n",
    "X_train['Category_clean'] = np.where(X_train['Category'].isin(['Sedan', 'Jeep', \"Hatchback\"]), X_train['Category'], \"Other\")\n",
    "X_train['Recent'] = np.where(X_train['Prod. year'] > 2012, 1, 0)\n",
    "X_train['IsLeather'] = np.where(X_train['Leather interior'] == \"Yes\", 1, 0)\n",
    "X_train['Automatic'] = np.where(X_train['Gear box type'] == 'Automatic', 1, 0)\n",
    "X_train['FuelType_clean'] = np.where(X_train['Fuel type'].isin(['Petrol', 'Diesel', \"Hybrid\"]), X_train['Fuel type'], \"Other\")\n",
    "X_train['Cylinders_clean'] = np.where(X_train['Cylinders']<=4, \"4 or less\", np.where(X_train['Cylinders'] <= 6, \"5 or 6\", \"7 or more\"))\n",
    "X_train['ColorType'] = np.where(X_train['Color'].isin([\"Black\", \"White\", \"Silver\", \"Grey\", \"Blue\", \"Red\"]), \"Standard\", \"Unusual\")\n",
    "X_train['Manufacturer_clean'] = np.where(X_train['Manufacturer'].isin(['HYUNDAI', \"TOYOTA\", \"MERCEDES-BENZ\", \"FORD\", \"CHEVROLET\", 'BMW', \"LEXUS\", \"HONDA\", \"NISSAN\", \"VOLKSWAGEN\"]), \n",
    "                                                       X_train['Manufacturer'], \"Other\")\n",
    "\n",
    "# Encode the 'Model' categorical variable. As long as there are at least 10 records, encode to the median target variable. If not in list, encode to median of entire dataset\n",
    "model_values = X_train['Model'].value_counts()\n",
    "model_values = model_values[model_values >= 10].index.tolist()\n",
    "model_encoding = dict(pd.DataFrame({\"Target\": y_train, \"Var\": X_train[\"Model\"]}).groupby(\"Var\").median().filter(items=model_values, axis=0).reset_index().itertuples(index=False, name=None))\n",
    "model_median_others = y_train[X_train['Model'].isin(model_values)].median()\n",
    "X_train['Model_encoded'] = X_train['Model'].map(model_encoding).fillna(model_median_others)\n",
    "\n",
    "# Median imputations requiring parameters\n",
    "median_Levy = X_train['Levy'].median()\n",
    "median_Mileage = X_train['Mileage'].median()\n",
    "\n",
    "X_train['log_Levy'] = np.log10(X_train['Levy'].fillna(median_Levy))  # Impute and log-transform\n",
    "X_train['log_Mileage'] = np.log10(1+X_train['Mileage'].fillna(median_Mileage)) # Impute and log-transform\n",
    "\n",
    "# Retain only relevant vaiables\n",
    "x_candidates = ['Category_clean', 'Recent', 'IsLeather', \"Automatic\", \n",
    "                \"FuelType_clean\", \"Cylinders_clean\", \"Manufacturer_clean\", \"Model_encoded\",\n",
    "                \"ColorType\", \"log_Levy\", \"log_Mileage\"]\n",
    "X_train_slim = X_train[x_candidates].copy()\n",
    "\n",
    "# Some models should have numerical variables that are standardized. Here we standardize using MinMaxScaler (since we already have several 0-1 variables)\n",
    "# We chose to create separate scalers for each of the two numeric variables that are not already 0-1. It is possible to create a scaler that covers multiple variables as once\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_log_Levy = MinMaxScaler().fit(X_train_slim[['log_Levy']])\n",
    "scaler_log_Mileage = MinMaxScaler().fit(X_train_slim[['log_Mileage']])\n",
    "scaled_Model_encoded = MinMaxScaler().fit(X_train_slim[['Model_encoded']])\n",
    "\n",
    "X_train_slim['log_Levy_standardized'] = scaler_log_Levy.transform(X_train_slim[['log_Levy']])\n",
    "X_train_slim['log_Mileage_standardized'] = scaler_log_Mileage.transform(X_train_slim[['log_Mileage']])\n",
    "X_train_slim['Model_encoded_standardized'] = scaled_Model_encoded.transform(X_train_slim[['Model_encoded']])\n",
    "\n",
    "# Convert categorical variables to 0-1 indicator variables\n",
    "categorical_variables = ['Category_clean', \"FuelType_clean\", \"Cylinders_clean\", \"ColorType\", \"Manufacturer_clean\"]\n",
    "X_train_num = pd.get_dummies(X_train_slim, dummy_na=False, columns=categorical_variables, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbfb06",
   "metadata": {},
   "source": [
    "**Note: We manually imputed the Levy and Mileage variables above before log-transforming them.** But you can use sklearn's SimpleImputer to be calibrated on Train and then applied to both Train and Test samples. \n",
    "\n",
    "The syntax for SimpleImputer is here: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html, and we make use of it in the data transformation template (download it through Gryphon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467825c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recent</th>\n",
       "      <th>IsLeather</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>Model_encoded</th>\n",
       "      <th>log_Levy</th>\n",
       "      <th>log_Mileage</th>\n",
       "      <th>log_Levy_standardized</th>\n",
       "      <th>log_Mileage_standardized</th>\n",
       "      <th>Category_clean_Hatchback</th>\n",
       "      <th>Category_clean_Jeep</th>\n",
       "      <th>...</th>\n",
       "      <th>Manufacturer_clean_CHEVROLET</th>\n",
       "      <th>Manufacturer_clean_FORD</th>\n",
       "      <th>Manufacturer_clean_HONDA</th>\n",
       "      <th>Manufacturer_clean_HYUNDAI</th>\n",
       "      <th>Manufacturer_clean_LEXUS</th>\n",
       "      <th>Manufacturer_clean_MERCEDES-BENZ</th>\n",
       "      <th>Manufacturer_clean_NISSAN</th>\n",
       "      <th>Manufacturer_clean_Other</th>\n",
       "      <th>Manufacturer_clean_TOYOTA</th>\n",
       "      <th>Manufacturer_clean_VOLKSWAGEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16,935.0000</td>\n",
       "      <td>2.8915</td>\n",
       "      <td>3.0004</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14,740.0000</td>\n",
       "      <td>2.8915</td>\n",
       "      <td>5.2041</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13,634.0000</td>\n",
       "      <td>2.8837</td>\n",
       "      <td>5.8284</td>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.6246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11,525.5000</td>\n",
       "      <td>2.8915</td>\n",
       "      <td>5.2504</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.5626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12039</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7,997.0000</td>\n",
       "      <td>2.7657</td>\n",
       "      <td>5.2058</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recent  IsLeather  Automatic  Model_encoded  log_Levy  log_Mileage  \\\n",
       "2144        0          1          0    16,935.0000    2.8915       3.0004   \n",
       "12142       0          0          1    14,740.0000    2.8915       5.2041   \n",
       "4610        1          1          1    13,634.0000    2.8837       5.8284   \n",
       "1713        0          0          0    11,525.5000    2.8915       5.2504   \n",
       "12039       0          1          1     7,997.0000    2.7657       5.2058   \n",
       "\n",
       "       log_Levy_standardized  log_Mileage_standardized  \\\n",
       "2144                  0.4472                    0.3215   \n",
       "12142                 0.4472                    0.5577   \n",
       "4610                  0.4435                    0.6246   \n",
       "1713                  0.4472                    0.5626   \n",
       "12039                 0.3881                    0.5578   \n",
       "\n",
       "       Category_clean_Hatchback  Category_clean_Jeep  ...  \\\n",
       "2144                          0                    0  ...   \n",
       "12142                         0                    0  ...   \n",
       "4610                          0                    0  ...   \n",
       "1713                          1                    0  ...   \n",
       "12039                         0                    0  ...   \n",
       "\n",
       "       Manufacturer_clean_CHEVROLET  Manufacturer_clean_FORD  \\\n",
       "2144                              0                        0   \n",
       "12142                             0                        0   \n",
       "4610                              0                        0   \n",
       "1713                              0                        0   \n",
       "12039                             0                        0   \n",
       "\n",
       "       Manufacturer_clean_HONDA  Manufacturer_clean_HYUNDAI  \\\n",
       "2144                          0                           0   \n",
       "12142                         0                           0   \n",
       "4610                          0                           1   \n",
       "1713                          1                           0   \n",
       "12039                         0                           0   \n",
       "\n",
       "       Manufacturer_clean_LEXUS  Manufacturer_clean_MERCEDES-BENZ  \\\n",
       "2144                          0                                 0   \n",
       "12142                         0                                 0   \n",
       "4610                          0                                 0   \n",
       "1713                          0                                 0   \n",
       "12039                         0                                 0   \n",
       "\n",
       "       Manufacturer_clean_NISSAN  Manufacturer_clean_Other  \\\n",
       "2144                           0                         1   \n",
       "12142                          0                         0   \n",
       "4610                           0                         0   \n",
       "1713                           0                         0   \n",
       "12039                          0                         1   \n",
       "\n",
       "       Manufacturer_clean_TOYOTA  Manufacturer_clean_VOLKSWAGEN  \n",
       "2144                           0                              0  \n",
       "12142                          1                              0  \n",
       "4610                           0                              0  \n",
       "1713                           0                              0  \n",
       "12039                          0                              0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First few rows of the data\n",
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97721f",
   "metadata": {},
   "source": [
    "### Transform the test dataset\n",
    "\n",
    "Here we need to apply the corresponding transformations on the test data. For transformations that required calibration on the train dataset, we re-use the calibrated values. \n",
    "\n",
    "**If we received a new dataset on which to predict, we would apply these transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b69d40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform certain columns\n",
    "X_test['Category_clean'] = np.where(X_test['Category'].isin(['Sedan', 'Jeep', \"Hatchback\"]), X_test['Category'], \"Other\")\n",
    "X_test['Recent'] = np.where(X_test['Prod. year'] > 2012, 1, 0)\n",
    "X_test['IsLeather'] = np.where(X_test['Leather interior'] == \"Yes\", 1, 0)\n",
    "X_test['Automatic'] = np.where(X_test['Gear box type'] == 'Automatic', 1, 0)\n",
    "X_test['FuelType_clean'] = np.where(X_test['Fuel type'].isin(['Petrol', 'Diesel', \"Hybrid\"]), X_test['Fuel type'], \"Other\")\n",
    "X_test['Cylinders_clean'] = np.where(X_test['Cylinders']<=4, \"4 or less\", np.where(X_test['Cylinders'] <= 6, \"5 or 6\", \"7 or more\"))\n",
    "X_test['ColorType'] = np.where(X_test['Color'].isin([\"Black\", \"White\", \"Silver\", \"Grey\", \"Blue\", \"Red\"]), \"Standard\", \"Unusual\")\n",
    "X_test['Manufacturer_clean'] = np.where(X_test['Manufacturer'].isin(['HYUNDAI', \"TOYOTA\", \"MERCEDES-BENZ\", \"FORD\", \"CHEVROLET\", 'BMW', \"LEXUS\", \"HONDA\", \"NISSAN\", \"VOLKSWAGEN\"]), \n",
    "                                                       X_test['Manufacturer'], \"Other\")\n",
    "\n",
    "# Encode Car Model\n",
    "X_test['Model_encoded'] = X_test['Model'].map(model_encoding).fillna(model_median_others)\n",
    "\n",
    "# Median imputations -- reuse the medians calculated on train data\n",
    "X_test['log_Levy'] = np.log10(X_test['Levy'].fillna(median_Levy))  # Impute and log-transform\n",
    "X_test['log_Mileage'] = np.log10(1+X_test['Mileage'].fillna(median_Mileage)) # Impute and log-transform\n",
    "\n",
    "# Retain only relevant vaiables\n",
    "X_test_slim = X_test[x_candidates].copy()\n",
    "\n",
    "# Re-use the scaling transformation that was calibrated on the train dataset\n",
    "X_test_slim['log_Levy_standardized'] = scaler_log_Levy.transform(X_test_slim[['log_Levy']])\n",
    "X_test_slim['log_Mileage_standardized'] = scaler_log_Mileage.transform(X_test_slim[['log_Mileage']])\n",
    "X_test_slim['Model_encoded_standardized'] = scaled_Model_encoded.transform(X_test_slim[['Model_encoded']])\n",
    "\n",
    "# Convert categorical variables to 0-1 indicator variables\n",
    "categorical_variables = ['Category_clean', \"FuelType_clean\", \"Cylinders_clean\", \"ColorType\", \"Manufacturer_clean\"]\n",
    "X_test_num = pd.get_dummies(X_test_slim, dummy_na=False, columns=categorical_variables, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f395864",
   "metadata": {},
   "source": [
    "**When converting categorical variables to a set of indicator variables, it is possible that the test dataset doesn't have all the categories that are available in the train dataset**\n",
    "\n",
    "This is certainly true if you later apply the model to predict a single data point, and often true when you have some infrequent categories (increasing the chances that all are found in the train data). \n",
    "\n",
    "So we may need to create additional indicator variables (all with 0 value) for the test dataset to mirror those in the train dataset. This is done, using 'reindex'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e6c3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Recent', 'IsLeather', 'Automatic', 'Model_encoded', 'log_Levy',\n",
       "       'log_Mileage', 'log_Levy_standardized', 'log_Mileage_standardized',\n",
       "       'Category_clean_Hatchback', 'Category_clean_Jeep',\n",
       "       'Category_clean_Other', 'Category_clean_Sedan', 'FuelType_clean_Diesel',\n",
       "       'FuelType_clean_Hybrid', 'FuelType_clean_Other',\n",
       "       'FuelType_clean_Petrol', 'Cylinders_clean_4 or less',\n",
       "       'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
       "       'ColorType_Standard', 'ColorType_Unusual', 'Manufacturer_clean_BMW',\n",
       "       'Manufacturer_clean_CHEVROLET', 'Manufacturer_clean_FORD',\n",
       "       'Manufacturer_clean_HONDA', 'Manufacturer_clean_HYUNDAI',\n",
       "       'Manufacturer_clean_LEXUS', 'Manufacturer_clean_MERCEDES-BENZ',\n",
       "       'Manufacturer_clean_NISSAN', 'Manufacturer_clean_Other',\n",
       "       'Manufacturer_clean_TOYOTA', 'Manufacturer_clean_VOLKSWAGEN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_num = X_test_num.reindex(columns = X_test_num.columns, fill_value=0)\n",
    "\n",
    "X_test_num.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f18b2",
   "metadata": {},
   "source": [
    "# Linear model calibration\n",
    "\n",
    "This covers calibration and model fit for popular linear models in sklearn, which are found here: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
    "\n",
    "Here we will showcase the following:\n",
    "* LinearRegression (without regularization)\n",
    "* Generalized Linear Model using the example with GammaRegression (without regularization) \n",
    "* Quantile regression for a more outlier robust model\n",
    "* LASSO regression (with regularization, and with hyperparameter tuning)\n",
    "* Elastic Net regression (with regularization, and with hyperparameter tuning)\n",
    "\n",
    "A few tips:\n",
    "\n",
    "When using regularized models, standardization of the data is recommended to avoid favoring certain variables over others due to their scale. In some cases selective standardization can be used to your favor (e.g. to force in specific variables) when using a regularized regression.\n",
    "\n",
    "Some feature selection techniques rely on coefficient sizes, causing standardization to matter even for non-regularized regressions (see the sklearn Linear Model Variable Selection notebook). \n",
    "\n",
    "Non-regularized models require variables to not be fully multicollinear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aacb91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3227a33",
   "metadata": {},
   "source": [
    "## Linear regression (OLS) without regularization\n",
    "\n",
    "The main parameter you need to specify is whether to use an intercept or not. Intercept is almost always used, unless there is reason to believe that when X = 0 that you also have y = 0.\n",
    "\n",
    "Syntax available here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18280ab",
   "metadata": {},
   "source": [
    "**Start by instantiating the model class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2aa2b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_reg = linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e778d3",
   "metadata": {},
   "source": [
    "**Calibrate the model by fitting on the train dataset for the selected set of variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ffd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variables = ['Recent', 'Automatic', 'log_Levy', 'log_Mileage', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', 'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded\"\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a798cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_reg_fitted = ols_reg.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0aecd",
   "metadata": {},
   "source": [
    "**Obtain information about the model, such as coefficients and basic metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83e9e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>9,973.1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>-4,072.9721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy</td>\n",
       "      <td>4,781.1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage</td>\n",
       "      <td>-349.3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>5,256.3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>3,030.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>2,190.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>5,804.9210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>-2,943.3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>-334.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>-3,505.2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>-4,681.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>-2,967.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_encoded</td>\n",
       "      <td>0.6641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-7,355.4145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature        Coef\n",
       "0                          Recent  9,973.1915\n",
       "1                       Automatic -4,072.9721\n",
       "2                        log_Levy  4,781.1503\n",
       "3                     log_Mileage   -349.3028\n",
       "4             Category_clean_Jeep  5,256.3884\n",
       "5            Category_clean_Other  3,030.3056\n",
       "6          Cylinders_clean_5 or 6  2,190.0665\n",
       "7       Cylinders_clean_7 or more  5,804.9210\n",
       "8         Manufacturer_clean_FORD -2,943.3507\n",
       "9      Manufacturer_clean_HYUNDAI   -334.5106\n",
       "10      Manufacturer_clean_NISSAN -3,505.2408\n",
       "11  Manufacturer_clean_VOLKSWAGEN -4,681.6325\n",
       "12       Manufacturer_clean_Other -2,967.1460\n",
       "13                  Model_encoded      0.6641\n",
       "14                      Intercept -7,355.4145"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model coefficients\n",
    "\n",
    "if ols_reg_fitted.fit_intercept:\n",
    "    ols_coefs = pd.DataFrame({\"Feature\": list(ols_reg_fitted.feature_names_in_) + [\"Intercept\"], \n",
    "                              \"Coef\": list(ols_reg_fitted.coef_) + [ols_reg_fitted.intercept_]})\n",
    "else:\n",
    "    ols_coefs = pd.DataFrame({\"Feature\": ols_reg_fitted.feature_names_in_, \"Coef\": ols_reg_fitted.coef_})\n",
    "ols_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3fcb0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,728.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,291.0121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.4258\n",
       "1   MAPE      0.4958\n",
       "2    MAE  7,728.9694\n",
       "3   RMSE 11,291.0121"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "ols_reg_train_pred = ols_reg_fitted.predict(X_train_num[x_variables])\n",
    "ols_reg_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, ols_reg_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, ols_reg_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, ols_reg_train_pred), \n",
    "               metrics.mean_squared_error(y_train, ols_reg_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "ols_reg_train_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02e887",
   "metadata": {},
   "source": [
    "**Generate out of sample fit, along with metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb1a0030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,937.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,719.2742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3869\n",
       "1   MAPE      0.5064\n",
       "2    MAE  7,937.9530\n",
       "3   RMSE 11,719.2742"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "ols_reg_test_pred = ols_reg_fitted.predict(X_test_num[x_variables])\n",
    "ols_reg_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, ols_reg_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, ols_reg_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, ols_reg_test_pred), \n",
    "               metrics.mean_squared_error(y_test, ols_reg_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "ols_reg_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778f523",
   "metadata": {},
   "source": [
    "## Generalized Linear Models\n",
    "\n",
    "Generalized Linear Models specify a functional link between Y and the linear combination of X, as well as an error distribution. A common link function is the 'log' function, such that log(Y) is predicted through a+bX. \n",
    "\n",
    "Read more about GLMs here: https://en.wikipedia.org/wiki/Generalized_linear_model\n",
    "\n",
    "Here we will use sklearn's GammaRegression, which uses a log-link and a Gamma error distribution (errors expected to be larger for larger y-values). sklearn also provides the following methods:\n",
    "* Poisson regression, usually when the y-variable represents a count (frequency)\n",
    "* Tweedie regression, which can represent several types of GLM regression based on a parameter (see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TweedieRegressor.html#sklearn.linear_model.TweedieRegressor)\n",
    "\n",
    "We also have our own implementation of a few GLM regressions that also generate p-values. This code can be extended as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7db65",
   "metadata": {},
   "source": [
    "### Gamma regression\n",
    "\n",
    "We use: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.GammaRegressor.html#sklearn.linear_model.GammaRegressor\n",
    "with no penalty parameter (alpha = 0) and with intercept (fit_intercept=True). \n",
    "\n",
    "If you want to use L1 regularization, the process for selecting an appropriate penalty parameter can be done via cross-validation and is covered in the section on LASSO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd68b18",
   "metadata": {},
   "source": [
    "**Instantiate and calibrate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01806019",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_reg = linear_model.GammaRegressor(fit_intercept=True, alpha=0, max_iter=1000)\n",
    "\n",
    "x_variables = ['Recent', 'Automatic', 'log_Levy', 'log_Mileage', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', 'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded\"\n",
    "               ]\n",
    "\n",
    "gamma_reg_fitted = gamma_reg.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87be689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>0.4631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>-0.1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy</td>\n",
       "      <td>-0.1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage</td>\n",
       "      <td>-0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>0.2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>0.1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>0.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>0.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>-0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>-0.2365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>-0.1829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>-0.1619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_encoded</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>9.8068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature    Coef\n",
       "0                          Recent  0.4631\n",
       "1                       Automatic -0.1709\n",
       "2                        log_Levy -0.1979\n",
       "3                     log_Mileage -0.0145\n",
       "4             Category_clean_Jeep  0.2227\n",
       "5            Category_clean_Other  0.1475\n",
       "6          Cylinders_clean_5 or 6  0.1603\n",
       "7       Cylinders_clean_7 or more  0.3800\n",
       "8         Manufacturer_clean_FORD -0.1371\n",
       "9      Manufacturer_clean_HYUNDAI  0.0120\n",
       "10      Manufacturer_clean_NISSAN -0.2365\n",
       "11  Manufacturer_clean_VOLKSWAGEN -0.1829\n",
       "12       Manufacturer_clean_Other -0.1619\n",
       "13                  Model_encoded  0.0000\n",
       "14                      Intercept  9.8068"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model coefficients\n",
    "\n",
    "if gamma_reg_fitted.fit_intercept:\n",
    "    gamma_coefs = pd.DataFrame({\"Feature\": list(gamma_reg_fitted.feature_names_in_) + [\"Intercept\"], \n",
    "                              \"Coef\": list(gamma_reg_fitted.coef_) + [gamma_reg_fitted.intercept_]})\n",
    "else:\n",
    "    gamma_coefs = pd.DataFrame({\"Feature\": gamma_reg_fitted.feature_names_in_, \"Coef\": gamma_reg_fitted.coef_})\n",
    "gamma_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec9229",
   "metadata": {},
   "source": [
    "**Metrics on training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c754dcd",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,467.1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,309.9778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.4238\n",
       "1   MAPE      0.4718\n",
       "2    MAE  7,467.1234\n",
       "3   RMSE 11,309.9778"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "gamma_reg_train_pred = gamma_reg_fitted.predict(X_train_num[x_variables])\n",
    "gamma_reg_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, gamma_reg_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, gamma_reg_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, gamma_reg_train_pred), \n",
    "               metrics.mean_squared_error(y_train, gamma_reg_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "gamma_reg_train_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7df23c",
   "metadata": {},
   "source": [
    "**Metrics on testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6498d42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,717.0853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,942.2410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3633\n",
       "1   MAPE      0.4845\n",
       "2    MAE  7,717.0853\n",
       "3   RMSE 11,942.2410"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "gamma_reg_test_pred = gamma_reg_fitted.predict(X_test_num[x_variables])\n",
    "gamma_reg_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, gamma_reg_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, gamma_reg_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, gamma_reg_test_pred), \n",
    "               metrics.mean_squared_error(y_test, gamma_reg_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "gamma_reg_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e4e5a",
   "metadata": {},
   "source": [
    "### Experimental GLM regression\n",
    "\n",
    "In the glm_regression.py file, we have created functionality for calibrating generalized linear models (with p-values). These are estimated using Iteratively ReWeighted Least Squares method, e.g. see: https://towardsdatascience.com/iterated-reweighted-least-squares-and-glms-explained-9c0cc0063526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ab4b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "from regression import glm_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1693384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\gryphonrepos\\regressionmodeling\\.venv\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vars</th>\n",
       "      <th>coef</th>\n",
       "      <th>std-err</th>\n",
       "      <th>t-stat</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>8.6565</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>77.9431</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent</td>\n",
       "      <td>0.5285</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>47.9085</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>-0.2508</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>-22.4988</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Levy</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>6.6658</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log_Mileage</td>\n",
       "      <td>-0.0216</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>-4.0165</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>22.4427</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>14.5089</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>6.2516</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>8.0137</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>-0.2095</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>-9.3188</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>-0.8195</td>\n",
       "      <td>0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>-0.3237</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>-7.4329</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>-0.2898</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>-6.9684</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>-0.1292</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>-8.7820</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model_encoded</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>45.8994</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Vars    coef  std-err   t-stat  p-val\n",
       "0                       Intercept  8.6565   0.1111  77.9431 0.0000\n",
       "1                          Recent  0.5285   0.0110  47.9085 0.0000\n",
       "2                       Automatic -0.2508   0.0111 -22.4988 0.0000\n",
       "3                        log_Levy  0.2501   0.0375   6.6658 0.0000\n",
       "4                     log_Mileage -0.0216   0.0054  -4.0165 0.0001\n",
       "5             Category_clean_Jeep  0.2781   0.0124  22.4427 0.0000\n",
       "6            Category_clean_Other  0.2228   0.0154  14.5089 0.0000\n",
       "7          Cylinders_clean_5 or 6  0.0894   0.0143   6.2516 0.0000\n",
       "8       Cylinders_clean_7 or more  0.1556   0.0194   8.0137 0.0000\n",
       "9         Manufacturer_clean_FORD -0.2095   0.0225  -9.3188 0.0000\n",
       "10     Manufacturer_clean_HYUNDAI -0.0105   0.0128  -0.8195 0.4125\n",
       "11      Manufacturer_clean_NISSAN -0.3237   0.0436  -7.4329 0.0000\n",
       "12  Manufacturer_clean_VOLKSWAGEN -0.2898   0.0416  -6.9684 0.0000\n",
       "13       Manufacturer_clean_Other -0.1292   0.0147  -8.7820 0.0000\n",
       "14                  Model_encoded  0.0000   0.0000  45.8994 0.0000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_summary, _, _ = glm_regression.fit_glm(\n",
    "    used_data=pd.concat([X_train_num, y_train],axis=1), \n",
    "    y_var = \"Price\", \n",
    "    x_var = x_variables, \n",
    "    family = glm_regression.LogGaussian(), \n",
    "    weight = None, \n",
    "    tolerance = 0.001, \n",
    "    max_iter = 100,\n",
    "    show_iter = False)\n",
    "\n",
    "glm_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883114e2",
   "metadata": {},
   "source": [
    "**The coefficients above should be used to generate the prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89fbe99",
   "metadata": {},
   "source": [
    "## Quantile regression\n",
    "\n",
    "Quantile regression generates prediction for a quantile (e.g. median, 25th quantile, 75th quantile etc.) of the target variable. As you are likely well aware, the median is much less sensitive to outliers than the average. The other regressions covered here predict the Conditional Average (i.e. E[y|X]), whereas the median regressor would predict the Conditional Median.\n",
    "\n",
    "As with the GammaRegressor, the QuantileRegressor also allows for an L1 penalty parameter. Here we will set the penalty to 0. For more information about calibrating the penalty, see the LASSO section.\n",
    "\n",
    "Syntax information: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.QuantileRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec1d85",
   "metadata": {},
   "source": [
    "**Instantiate and fit the model**\n",
    "\n",
    "quantile = 0.5 yields the median prediction. \n",
    "\n",
    "sklearn's implementation of quantile regression can be slow for larger datasets. For larger datasets, it is recommended to use libraries other than sklearn (e.g. statsmodels quantReg). In our example, 5000 rows is nearly instant, but 10K rows takes forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "501a0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "quantile_reg = linear_model.QuantileRegressor(fit_intercept=True, quantile=0.5, alpha=0, solver=\"highs\")\n",
    "N = 5000 # Number of rows\n",
    "\n",
    "x_variables = ['Recent', 'Automatic', 'log_Levy', 'log_Mileage', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', 'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded\", \n",
    "              ]\n",
    "sample_rows = random.sample(X_train_num.index.tolist(), N)\n",
    "quantile_reg_fitted = quantile_reg.fit(X_train_num.loc[sample_rows,x_variables], y_train[sample_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e45bab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>5,938.7324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>-1,746.3798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy</td>\n",
       "      <td>819.4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage</td>\n",
       "      <td>-21.5630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>2,067.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>914.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>521.6266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>3,307.9160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>-1,608.6787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>-1,513.7606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>-558.1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>-2,461.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>-1,868.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_encoded</td>\n",
       "      <td>0.8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-307.4322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature        Coef\n",
       "0                          Recent  5,938.7324\n",
       "1                       Automatic -1,746.3798\n",
       "2                        log_Levy    819.4269\n",
       "3                     log_Mileage    -21.5630\n",
       "4             Category_clean_Jeep  2,067.7760\n",
       "5            Category_clean_Other    914.9392\n",
       "6          Cylinders_clean_5 or 6    521.6266\n",
       "7       Cylinders_clean_7 or more  3,307.9160\n",
       "8         Manufacturer_clean_FORD -1,608.6787\n",
       "9      Manufacturer_clean_HYUNDAI -1,513.7606\n",
       "10      Manufacturer_clean_NISSAN   -558.1941\n",
       "11  Manufacturer_clean_VOLKSWAGEN -2,461.0318\n",
       "12       Manufacturer_clean_Other -1,868.8957\n",
       "13                  Model_encoded      0.8260\n",
       "14                      Intercept   -307.4322"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model coefficients\n",
    "\n",
    "if quantile_reg_fitted.fit_intercept:\n",
    "    quantile_coefs = pd.DataFrame({\"Feature\": list(quantile_reg_fitted.feature_names_in_) + [\"Intercept\"], \n",
    "                              \"Coef\": list(quantile_reg_fitted.coef_) + [quantile_reg_fitted.intercept_]})\n",
    "else:\n",
    "    quantile_coefs = pd.DataFrame({\"Feature\": quantile_reg_fitted.feature_names_in_, \"Coef\": quantile_reg_fitted.coef_})\n",
    "quantile_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1899ab",
   "metadata": {},
   "source": [
    "**Metrics on training data**\n",
    "\n",
    "Note that we are now comparing a quantile vs. the actual variable. For median, such a comparison is reasonable assuming errors are nearly symmetric, but it would not be reasonable to compare e.g. the 75th quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58b7c52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,402.5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,684.6258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3850\n",
       "1   MAPE      0.4312\n",
       "2    MAE  7,402.5794\n",
       "3   RMSE 11,684.6258"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "quantile_reg_train_pred = quantile_reg_fitted.predict(X_train_num[x_variables])\n",
    "quantile_reg_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, quantile_reg_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, quantile_reg_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, quantile_reg_train_pred), \n",
    "               metrics.mean_squared_error(y_train, quantile_reg_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "quantile_reg_train_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a354e0",
   "metadata": {},
   "source": [
    "**Metrics on testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bdfa3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,714.4745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>12,216.5764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3337\n",
       "1   MAPE      0.4478\n",
       "2    MAE  7,714.4745\n",
       "3   RMSE 12,216.5764"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "quantile_reg_test_pred = quantile_reg_fitted.predict(X_test_num[x_variables])\n",
    "quantile_reg_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, quantile_reg_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, quantile_reg_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, quantile_reg_test_pred), \n",
    "               metrics.mean_squared_error(y_test, quantile_reg_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "quantile_reg_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e78ade0",
   "metadata": {},
   "source": [
    "## LASSO regression with hyperparameter tuning (for penalty parameter)\n",
    "\n",
    "LASSO regression is a linear regression with a penalty added to the usual Least Squares error term. This penalty is a L1 penalty, i.e. 'sum of absolute value of the coefficients'.\n",
    "\n",
    "L2 penalty is the 'sum of squared coefficients', and would result in a so-called Ridge Regression (not covered here since approach is very similar to L1 penalty. The key difference is that all variables are kept in a Ridge Regression, while some variables start getting 0 coefficient in a LASSO).\n",
    "\n",
    "L1 and L2 penalties includes both of the above, and would result in an Elastic Net regression, which is covered in the next section.\n",
    "\n",
    "**We will first do hyperparameter tuning to find suitable values of the penalty parameter 'alpha'.** This is done by using cross-validation on the train dataset, comparing the outcomes of multiple choices of 'alpha.\n",
    "* We use LassoCV for that cross-validation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\n",
    "* Once the alpha parameter has been selected, we use the regular Lasso method: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "**We also use the standardized data here, since penalties are based on coefficient size**\n",
    "\n",
    "We can also consider more models, as the introduction of penalty makes the model more robust against correlations between x-variables, and it also helps filter out less relevant variables automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62792a78",
   "metadata": {},
   "source": [
    "### Lasso Cross-Validation for tuning alpha penalty parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c7e58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let LassoCV consider 100 different alpha values (you can also specify manual list of alpha values to consider if the ones selected automatically are poor)\n",
    "Lasso_CV_model = linear_model.LassoCV(eps=0.0001, n_alphas=100, alphas=None, \n",
    "                                              fit_intercept=True, \n",
    "                                              cv=5, verbose=0, random_state=1000)\n",
    "\n",
    "x_variables = ['Recent', 'Automatic', 'log_Levy_standardized', 'log_Mileage_standardized', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'ColorType_Standard', 'ColorType_Unusual',\n",
    "               'FuelType_clean_Hybrid', 'FuelType_clean_Other',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', \n",
    "               'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded_standardized\"\n",
    "               ]\n",
    "\n",
    "Lasso_CV_outcomes = Lasso_CV_model.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca522d3",
   "metadata": {},
   "source": [
    "**We can now plot the RMSE vs. the alpha values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a90bf26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>2,781.7726</td>\n",
       "      <td>2,534.6476</td>\n",
       "      <td>2,309.4765</td>\n",
       "      <td>2,104.3090</td>\n",
       "      <td>1,917.3680</td>\n",
       "      <td>1,747.0343</td>\n",
       "      <td>1,591.8326</td>\n",
       "      <td>1,450.4185</td>\n",
       "      <td>1,321.5674</td>\n",
       "      <td>1,204.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>0.5855</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean RMSE</th>\n",
       "      <td>14,885.4852</td>\n",
       "      <td>14,725.3896</td>\n",
       "      <td>14,575.6286</td>\n",
       "      <td>14,380.9144</td>\n",
       "      <td>14,152.0044</td>\n",
       "      <td>13,959.1123</td>\n",
       "      <td>13,796.9256</td>\n",
       "      <td>13,660.8165</td>\n",
       "      <td>13,546.7810</td>\n",
       "      <td>13,451.3757</td>\n",
       "      <td>...</td>\n",
       "      <td>11,209.1556</td>\n",
       "      <td>11,209.1570</td>\n",
       "      <td>11,209.1584</td>\n",
       "      <td>11,209.1597</td>\n",
       "      <td>11,209.1611</td>\n",
       "      <td>11,209.1624</td>\n",
       "      <td>11,209.1636</td>\n",
       "      <td>11,209.1648</td>\n",
       "      <td>11,209.1659</td>\n",
       "      <td>11,209.1670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1           2           3           4   \\\n",
       "Alpha      2,781.7726  2,534.6476  2,309.4765  2,104.3090  1,917.3680   \n",
       "Mean RMSE 14,885.4852 14,725.3896 14,575.6286 14,380.9144 14,152.0044   \n",
       "\n",
       "                   5           6           7           8           9   ...  \\\n",
       "Alpha      1,747.0343  1,591.8326  1,450.4185  1,321.5674  1,204.1630  ...   \n",
       "Mean RMSE 13,959.1123 13,796.9256 13,660.8165 13,546.7810 13,451.3757  ...   \n",
       "\n",
       "                   90          91          92          93          94  \\\n",
       "Alpha          0.6426      0.5855      0.5335      0.4861      0.4429   \n",
       "Mean RMSE 11,209.1556 11,209.1570 11,209.1584 11,209.1597 11,209.1611   \n",
       "\n",
       "                   95          96          97          98          99  \n",
       "Alpha          0.4036      0.3677      0.3351      0.3053      0.2782  \n",
       "Mean RMSE 11,209.1624 11,209.1636 11,209.1648 11,209.1659 11,209.1670  \n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, table = sklearn_regression_tools.plot_LassoCV_path(Lasso_CV_outcomes);\n",
    "table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c842d",
   "metadata": {},
   "source": [
    "Note: Alternative methods to LassoCV are covered here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and using the more general GridSearchCV approach: https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a65771",
   "metadata": {},
   "source": [
    "**We can then select one or multiple alpha values to calibrate the LASSO model**\n",
    "\n",
    "Lasso_CV also selects the best alpha value based on cross-validation. Though it is often advisable to review similarly performing models that may be more intuitive without sacrificing model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19236079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1230064068778767"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best alpha value selected by cross-validation\n",
    "Lasso_CV_outcomes.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4709b",
   "metadata": {},
   "source": [
    "### Lasso calibration for a single alpha penalty parameter\n",
    "\n",
    "Here we selected an alpha parameter of 100, which has similar fit as the best alpha value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb539001",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_model = linear_model.Lasso(alpha=100, fit_intercept=True)\n",
    "Lasso_model_fitted = Lasso_model.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05190ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>9,461.9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>-2,938.5784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy_standardized</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage_standardized</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>5,128.7415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>2,119.8709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>2,026.5154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>5,232.2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ColorType_Standard</td>\n",
       "      <td>105.7244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ColorType_Unusual</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FuelType_clean_Hybrid</td>\n",
       "      <td>-771.1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FuelType_clean_Other</td>\n",
       "      <td>-4,185.2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>-457.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>140.9271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>-199.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>-668.1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>-1,864.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model_encoded_standardized</td>\n",
       "      <td>35,018.2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>9,294.8440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature        Coef\n",
       "0                          Recent  9,461.9093\n",
       "1                       Automatic -2,938.5784\n",
       "2           log_Levy_standardized      0.0000\n",
       "3        log_Mileage_standardized     -0.0000\n",
       "4             Category_clean_Jeep  5,128.7415\n",
       "5            Category_clean_Other  2,119.8709\n",
       "6          Cylinders_clean_5 or 6  2,026.5154\n",
       "7       Cylinders_clean_7 or more  5,232.2106\n",
       "8              ColorType_Standard    105.7244\n",
       "9               ColorType_Unusual     -0.0000\n",
       "10          FuelType_clean_Hybrid   -771.1821\n",
       "11           FuelType_clean_Other -4,185.2017\n",
       "12        Manufacturer_clean_FORD   -457.4800\n",
       "13     Manufacturer_clean_HYUNDAI    140.9271\n",
       "14      Manufacturer_clean_NISSAN   -199.7778\n",
       "15  Manufacturer_clean_VOLKSWAGEN   -668.1238\n",
       "16       Manufacturer_clean_Other -1,864.8474\n",
       "17     Model_encoded_standardized 35,018.2521\n",
       "18                      Intercept  9,294.8440"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model coefficients\n",
    "if Lasso_model_fitted.fit_intercept:\n",
    "    model_coefs = pd.DataFrame({\"Feature\": list(Lasso_model_fitted.feature_names_in_) + [\"Intercept\"], \n",
    "                              \"Coef\": list(Lasso_model_fitted.coef_) + [Lasso_model_fitted.intercept_]})\n",
    "else:\n",
    "    model_coefs = pd.DataFrame({\"Feature\": Lasso_model_fitted.feature_names_in_, \"Coef\": Lasso_model_fitted.coef_})\n",
    "model_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5776c97",
   "metadata": {},
   "source": [
    "**Generate metrics on train and test data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0510e928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,594.5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,302.9403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.4246\n",
       "1   MAPE      0.4785\n",
       "2    MAE  7,594.5793\n",
       "3   RMSE 11,302.9403"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "lasso_reg_train_pred = Lasso_model_fitted.predict(X_train_num[x_variables])\n",
    "lasso_reg_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, lasso_reg_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, lasso_reg_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, lasso_reg_train_pred), \n",
    "               metrics.mean_squared_error(y_train, lasso_reg_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "lasso_reg_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a05b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,780.7164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,704.6810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3884\n",
       "1   MAPE      0.4894\n",
       "2    MAE  7,780.7164\n",
       "3   RMSE 11,704.6810"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model test prediction and metrics\n",
    "lasso_reg_test_pred = Lasso_model_fitted.predict(X_test_num[x_variables])\n",
    "lasso_reg_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, lasso_reg_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, lasso_reg_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, lasso_reg_test_pred), \n",
    "               metrics.mean_squared_error(y_test, lasso_reg_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "lasso_reg_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223b008",
   "metadata": {},
   "source": [
    "### Lasso calibration for multiple alpha penalty parameters - TBD\n",
    "\n",
    "This is often done to check which variables are selected in the LASSO model, as a higher penalty results in fewer variables selected.\n",
    "\n",
    "This section will come later. For time being, see the use of LASSO for variable selection in the \"sklearn regression variable selection notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb22b35",
   "metadata": {},
   "source": [
    "## Elastic Net\n",
    "\n",
    "Elastic net uses both L1 and L2 penalties, resulting in two penalty parameters. Some algorithms define the L1 and L2 penalties as two separate parameters, whereas sklearn uses 'alpha' and 'l1_ratio' (between 0 an 1) in the following manner:\n",
    "* L1 penalty = alpha * l1_ratio\n",
    "* L2 penalty = 0.5 * alpha * (1 - l1_ratio)\n",
    "\n",
    "To select alpha and l1_ratio using cross-validation, we consider a 2D grid of alpha and l1_ratio combinations. \n",
    "\n",
    "Since these penalties are based on the size of the coefficients, it is recommended to use standardized data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4be31",
   "metadata": {},
   "source": [
    "### Elastic Net hyperparameter tuning of alpha and l1_ratio parameters\n",
    "\n",
    "Read more about the syntax here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html\n",
    "\n",
    "We have to set the potential l1_ratio values manually. There is a choice whether to set alphas automatically (by specifying n_alphas) or setting them manually:\n",
    "* If alphas are set automatically, the set of alpha values will vary for each l1_ratio, but the L1 penalty will remain the same set\n",
    "* If alphas are set manually, the same set of alpha valus will be used for each l1_ratio\n",
    "\n",
    "We need to take this into account when plotting the model error in the grid vs. penalty values. For simplicity, we set the alphas manually in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ece4b324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let ElasticNetCV consider 100 different alpha values (you can also specify manual list of alpha values to consider if the ones selected automatically are poor) and a set of l1_ratio values\n",
    "ENet_CV_model = linear_model.ElasticNetCV(eps=0.0001, l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99, 1], \n",
    "                                          n_alphas=None, alphas=[0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "                                          fit_intercept=True, \n",
    "                                          cv=5, verbose=0, random_state=1000, max_iter=10000)\n",
    "\n",
    "x_variables = ['Recent', 'Automatic', 'log_Levy_standardized', 'log_Mileage_standardized', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'ColorType_Standard', 'ColorType_Unusual',\n",
    "               'FuelType_clean_Hybrid', 'FuelType_clean_Other',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', \n",
    "               'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded_standardized\"\n",
    "               ]\n",
    "\n",
    "ENet_CV_outcomes = ENet_CV_model.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a51ed",
   "metadata": {},
   "source": [
    "**We can now plot the RMSE vs. the grid of alpha and l1_ratio values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa9cea5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, table = sklearn_regression_tools.plot_ElasticNetCV_path(ENet_CV_outcomes, cmap = ow_colormap('blues'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdbbc77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10,000.0000</th>\n",
       "      <th>1,000.0000</th>\n",
       "      <th>100.0000</th>\n",
       "      <th>10.0000</th>\n",
       "      <th>1.0000</th>\n",
       "      <th>0.1000</th>\n",
       "      <th>0.0100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>14,900.7299</td>\n",
       "      <td>14,899.6272</td>\n",
       "      <td>14,888.4589</td>\n",
       "      <td>14,780.8637</td>\n",
       "      <td>13,997.2282</td>\n",
       "      <td>12,203.8567</td>\n",
       "      <td>11,335.1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3000</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>14,899.5012</td>\n",
       "      <td>14,885.1681</td>\n",
       "      <td>14,748.4134</td>\n",
       "      <td>13,822.6228</td>\n",
       "      <td>12,051.5903</td>\n",
       "      <td>11,299.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>14,899.2397</td>\n",
       "      <td>14,879.2620</td>\n",
       "      <td>14,691.6718</td>\n",
       "      <td>13,563.2764</td>\n",
       "      <td>11,873.3682</td>\n",
       "      <td>11,264.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7000</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>14,898.5749</td>\n",
       "      <td>14,865.5696</td>\n",
       "      <td>14,567.0220</td>\n",
       "      <td>13,135.6130</td>\n",
       "      <td>11,653.3884</td>\n",
       "      <td>11,233.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>14,895.0654</td>\n",
       "      <td>14,798.9185</td>\n",
       "      <td>14,069.7300</td>\n",
       "      <td>12,274.1896</td>\n",
       "      <td>11,353.0776</td>\n",
       "      <td>11,212.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9500</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>14,889.7913</td>\n",
       "      <td>14,704.2632</td>\n",
       "      <td>13,571.0424</td>\n",
       "      <td>11,874.8567</td>\n",
       "      <td>11,264.8636</td>\n",
       "      <td>11,209.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9900</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>14,848.7063</td>\n",
       "      <td>14,119.1521</td>\n",
       "      <td>12,289.0903</td>\n",
       "      <td>11,354.0313</td>\n",
       "      <td>11,212.3737</td>\n",
       "      <td>11,209.1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>14,900.7891</td>\n",
       "      <td>13,305.2929</td>\n",
       "      <td>11,318.2947</td>\n",
       "      <td>11,210.9782</td>\n",
       "      <td>11,209.1504</td>\n",
       "      <td>11,209.1748</td>\n",
       "      <td>11,209.1793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        10,000.0000  1,000.0000   100.0000     10.0000      1.0000       \\\n",
       "0.1000  14,900.7299  14,899.6272  14,888.4589  14,780.8637  13,997.2282   \n",
       "0.3000  14,900.7891  14,899.5012  14,885.1681  14,748.4134  13,822.6228   \n",
       "0.5000  14,900.7891  14,899.2397  14,879.2620  14,691.6718  13,563.2764   \n",
       "0.7000  14,900.7891  14,898.5749  14,865.5696  14,567.0220  13,135.6130   \n",
       "0.9000  14,900.7891  14,895.0654  14,798.9185  14,069.7300  12,274.1896   \n",
       "0.9500  14,900.7891  14,889.7913  14,704.2632  13,571.0424  11,874.8567   \n",
       "0.9900  14,900.7891  14,848.7063  14,119.1521  12,289.0903  11,354.0313   \n",
       "1.0000  14,900.7891  13,305.2929  11,318.2947  11,210.9782  11,209.1504   \n",
       "\n",
       "        0.1000       0.0100       \n",
       "0.1000  12,203.8567  11,335.1958  \n",
       "0.3000  12,051.5903  11,299.5025  \n",
       "0.5000  11,873.3682  11,264.7967  \n",
       "0.7000  11,653.3884  11,233.7742  \n",
       "0.9000  11,353.0776  11,212.3513  \n",
       "0.9500  11,264.8636  11,209.8571  \n",
       "0.9900  11,212.3737  11,209.1446  \n",
       "1.0000  11,209.1748  11,209.1793  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column header = alpha, row name = l1_ratio \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e0506",
   "metadata": {},
   "source": [
    "**We can get the alpha and l1_ratio corresponding to the best fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5abfbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.99)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best alpha and l1_ratio values selected by cross-validation\n",
    "ENet_CV_outcomes.alpha_, ENet_CV_outcomes.l1_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe3a243",
   "metadata": {},
   "source": [
    "**However, the best fit may not be what you want, as there may be many similarly fitting models that are more intuitive** Next section shows how you can explore alpha and l1_ratio penalty pairs further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6f3fc",
   "metadata": {},
   "source": [
    "### Elastic Net calibration for a single alpha and l1_ratio penalty parameter pair\n",
    "\n",
    "Here we select an alpha and l1_ratio that are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c122a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet_model = linear_model.ElasticNet(alpha=0.1, l1_ratio=0.99, fit_intercept=True)\n",
    "ENet_model_fitted = ENet_model.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf143134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>10,084.0546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>-3,830.6305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy_standardized</td>\n",
       "      <td>7,515.2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage_standardized</td>\n",
       "      <td>-2,051.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>5,408.9435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>2,911.3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>2,367.5797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>6,255.1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ColorType_Standard</td>\n",
       "      <td>625.4537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ColorType_Unusual</td>\n",
       "      <td>-427.3046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FuelType_clean_Hybrid</td>\n",
       "      <td>-1,530.6449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FuelType_clean_Other</td>\n",
       "      <td>-5,285.3497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>-2,954.5537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>250.0940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>-3,618.1735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>-4,971.3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>-3,187.6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model_encoded_standardized</td>\n",
       "      <td>34,990.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>7,313.9690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature        Coef\n",
       "0                          Recent 10,084.0546\n",
       "1                       Automatic -3,830.6305\n",
       "2           log_Levy_standardized  7,515.2560\n",
       "3        log_Mileage_standardized -2,051.0581\n",
       "4             Category_clean_Jeep  5,408.9435\n",
       "5            Category_clean_Other  2,911.3278\n",
       "6          Cylinders_clean_5 or 6  2,367.5797\n",
       "7       Cylinders_clean_7 or more  6,255.1043\n",
       "8              ColorType_Standard    625.4537\n",
       "9               ColorType_Unusual   -427.3046\n",
       "10          FuelType_clean_Hybrid -1,530.6449\n",
       "11           FuelType_clean_Other -5,285.3497\n",
       "12        Manufacturer_clean_FORD -2,954.5537\n",
       "13     Manufacturer_clean_HYUNDAI    250.0940\n",
       "14      Manufacturer_clean_NISSAN -3,618.1735\n",
       "15  Manufacturer_clean_VOLKSWAGEN -4,971.3821\n",
       "16       Manufacturer_clean_Other -3,187.6310\n",
       "17     Model_encoded_standardized 34,990.3182\n",
       "18                      Intercept  7,313.9690"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model coefficients\n",
    "if ENet_model_fitted.fit_intercept:\n",
    "    model_coefs = pd.DataFrame({\"Feature\": list(ENet_model_fitted.feature_names_in_) + [\"Intercept\"], \n",
    "                              \"Coef\": list(ENet_model_fitted.coef_) + [ENet_model_fitted.intercept_]})\n",
    "else:\n",
    "    model_coefs = pd.DataFrame({\"Feature\": ENet_model_fitted.feature_names_in_, \"Coef\": ENet_model_fitted.coef_})\n",
    "model_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6fd9e",
   "metadata": {},
   "source": [
    "**Generate metrics on train and test data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0127a7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,604.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,195.5995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.4354\n",
       "1   MAPE      0.4844\n",
       "2    MAE  7,604.0134\n",
       "3   RMSE 11,195.5995"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "ENet_reg_train_pred = ENet_model_fitted.predict(X_train_num[x_variables])\n",
    "ENet_reg_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, ENet_reg_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, ENet_reg_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, ENet_reg_train_pred), \n",
    "               metrics.mean_squared_error(y_train, ENet_reg_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "ENet_reg_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b457ba60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,752.5219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,566.1789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.4028\n",
       "1   MAPE      0.4910\n",
       "2    MAE  7,752.5219\n",
       "3   RMSE 11,566.1789"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model test prediction and metrics\n",
    "ENet_reg_test_pred = ENet_model_fitted.predict(X_test_num[x_variables])\n",
    "ENet_reg_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, ENet_reg_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, ENet_reg_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, ENet_reg_test_pred), \n",
    "               metrics.mean_squared_error(y_test, ENet_reg_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "ENet_reg_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7d70f",
   "metadata": {},
   "source": [
    "# Tree-based methods\n",
    "\n",
    "Tree-based models do not assume a linear relationship between target variable and independent variables. Instead, it defines breakpoints in the data based on the x-variable value. \n",
    "\n",
    "The simplest method is the Binary Decision Tree, where at each internal node, the data is split into two based on the value of the x-variable at the node -- that split point is determined based on a measure of the difference of the target variable value in the corresponding two subsets of data. \n",
    "\n",
    "Splits in the tree-based method is determined in a greedy manner, leading to Decision Trees to quickly start overfitting. To overcome this, a number of techniques are available:\n",
    "* Limiting the complexity of the tree; either upfront, by setting maximum limits on the depth of the tree, minimum number of observations per node to consider a split; or after initial calibration by pruning the tree\n",
    "* Regularization, by setting a penalty on the complexity of the tree, such that the model fit must improve more than said penalty\n",
    "* Randomization, e.g. considering a subset of variables for splitting at each node (rather than all variables) or using a subset of data to determine a split\n",
    "* Ensembling / combining a large number of trees (such as random forest and gradient boosted trees)\n",
    "\n",
    "**This section will cover Binary Decision Trees, Random Forest, and Gradient Boosting methods from sklearn**\n",
    "\n",
    "**Note: sklearn's implementation of these do not handle categorical variables** \n",
    "Ordinal variables can be coded to a numerical variable, e.g. Low -> 1, Medium -> 2, High -> 3. If you have many categorical variables, consider e.g.:\n",
    "- Continue to use Random Forest and Gradient Boosting with One-Hot encoding. The number of trees should mitigate the limitation of not being able to use categorical variables as splits directly.\n",
    "- Using a different ensemble model from sklearn, e.g. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\n",
    "- Using an alternative ensembling library: xgboost, lightgbm or catboost\n",
    "- Use rpart in R (instead of Python) for basic decision trees\n",
    "- Wait until support for categorical variables becomes available for decision trees, see: https://github.com/scikit-learn/scikit-learn/pull/12866"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d7742",
   "metadata": {},
   "source": [
    "\n",
    "## Binary decision tree regressions\n",
    "\n",
    "In the standard decision tree for regression, the prediction for each node is simply the average value of the target variable within that node. If other error metrics are used, the prediction may be different from the average.\n",
    "\n",
    "Common reasons a decision is used include:\n",
    "* Simple model without worrying about non-linearities\n",
    "* Model easily explained to non-technical clients\n",
    "* Offers insights on 'segments' within the data\n",
    "\n",
    "There are certain things to watch out for however, e.g.:\n",
    "* Model predictions will suddenly jump, as the number of different predictions is limited (based on cutoffs in x-variables)\n",
    "* X-variables do not have monotone relationship vs. x-variables\n",
    "* Very easy to overfit the model\n",
    "\n",
    "Read more about the decision tree here (advantages and disadvantages): https://scikit-learn.org/stable/modules/tree.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e2fb5",
   "metadata": {},
   "source": [
    "### Training a single decision tree\n",
    "\n",
    "We need to select the error metric, maximum tree depth, minimum number of observations in a node to be split, minimum samples or proportion in final leafs, maximum number of final leafs, minimum purity decrease to warrant a split, complexity parameter to prune the tree if it gets too large.\n",
    "\n",
    "For details see the syntax: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d985c21",
   "metadata": {},
   "source": [
    "**Start by instantiating the model class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d444e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "decision_tree = tree.DecisionTreeRegressor(criterion='absolute_error',  \n",
    "                                           max_depth=3, min_samples_split=50, min_samples_leaf=20, \n",
    "                                           min_impurity_decrease=0.1, ccp_alpha=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098099e4",
   "metadata": {},
   "source": [
    "**Define variables and fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c10c3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variables = ['Recent', 'Automatic', 'log_Levy', 'log_Mileage', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', 'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded\"]\n",
    "\n",
    "decision_tree_fitted = decision_tree.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca030d4",
   "metadata": {},
   "source": [
    "**Visualize the tree**\n",
    "\n",
    "We use the basic plot_tree method. A more advanced tree can be obtained if you have 'graphviz' available, see e.g. https://mljar.com/blog/visualize-decision-tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5abd96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYEAAAFUCAYAAAByc/M6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzddXQUdxfG8e9EiADBIbi7B3d3dyletC1QrDgtlOJairVoi7u7OwR3d3eJ27x/LF3Im1CchfB8ztkDo787S9jM3rlzxzBNExERERERERERERGJmOxsHYCIiIiIiIiIiIiIfDxKAouIiIiIiIiIiIhEYEoCi4iIiIiIiIiIiERgSgKLiIiIiIiIiIiIRGBKAouIiIiIiIiIiIhEYEoCi4iIiIiIiIiIiERgSgKLiIiIiIiIiIiIRGBKAouIiIiIiIiIiIhEYEoCi4iIiIiIiIiIiERgSgKLiIiIiIiIiIiIRGBKAouIiIiIiIiIiIhEYEoCi4iIiIiIiIiIiERgSgKLiIiIiIiIiIiIRGBKAouIiIiIiIiIiIhEYEoCi4iIiIiIiIiIiERgSgKLiIiIiIiIiIiIRGBKAouIiIiIiIiIiIhEYEoCi4iIiIiIiIiIiERgDrYOQERERETenYuz820/f/94to5Dvg7OTk53fP383G0dh4iIiIi8HcM0TVvHICIiIiLvyDAM0//KEVuHIV8Jp6RZMU3TsHUcIiIiIvJ21A5CREREREREREREJAJTElhEREREREREREQkAlMSWERERERERERERCQCUxJYREREREREREREJAJTElhEREREREREREQkAlMSWERERCSCcUqalSbtu1ung4KCSJi9KFWb/vBW+0lToBz3Hz5673U+lV9HjmfExOlvtU3M9Hk/UjQvbNi+m7wV6uJRugZ5K9Rl88691mUVG7UhZ9laZCtZje97/EpwcDAAvwz7gxxlapKrXG3KN2jFzTt3rdts3e1JrnK1yVayGiVrNws1VnBwMLnL1X7lv/Wov/4ma4lq5ChTkzL1WnDl+k3rMpfk2clVrja5ytWm+rftPuRbICIiIiI25mDrAERERETkw4rs6sKJsxfw9fPDxdmZDdv3kMA9rq3D+uIFBAQSGBRIZFfXt9oudozoLJryOwnixeXEmXNUbNiGS/s2ADBr7FDcokbBNE3qtu7EwpXrqF25HB1bNeGXzpZE7h9TZ/Lb6ImMHdCbx0+e0q7XAJb/PY4kCeNz9/6DUGONmTKTdKlS8NTLK9xYsmVMx+4Vs3B1cWHiP/PoMXAkM8cOBcDF2QnP1fPe9m0RERERkS+AKoFFREREIqCyxQqyeuN2AOYtW02dymWtyx4+fkLNFj+So0xNClVtwLFTZwF48Ogx5Ru0IlvJarT+6RdM07RuM2vRCgpUrk+ucrX5rns/a8Xq67xqu5jp89JnyBhylq1FoaoNuHPPksy8c+8BtVr+SM6ytchZtha79x8GLBWs2UtVJ3up6vw+eYZ1/4PG/EXGopUoVqMxZy9ets6/cOUaFRu1IW+FuhSv2YTT5y8BcOnqdQpXbYhH6Rr8PPSPNzqGU+cu8tOvw8hUrDLnLl55o21eli1TehLEsyThM6RJha+fP/7+AQC4RY0CWKq1AwIDMQwj1HwAHx8/6/w5S1dTtWwJkiSMD0Dc2LGs612/dYfVm7bTtG61V8ZSNH9uXF1cAMiTPTM3bt195boiIiIiEnEoCSwiIiISAdWuVJZ5y9fg5+fPsdPnyJUts3VZvxHjyJYxHQfWLqBfl7Y069gLgP6jJlAgV3YOb1hM5TLFuXrjFmBJgs5fsZYtC6fjuXoe9nb2zF6y6rUx/Nd23j6+5PbIzP418ymYOwdTZi8EoOMvgyiUJyf718xn78o5ZEiTkoPHTvL3/KXsWDqD7UtmMGX2Qg4fP8XBYyeZt3wNnqvnsXTaWPYfOWEd+7tu/RjZtxt7Vs5hUM+OtO/1GwCd+g6hZcPaHFy3EPe4sV8Zu7ePD9PnLaFYjcZ8160v6VOn4MDaBWTLlB6Azv2GWlsnvPwaOm7yf74ni1dtIFum9Dg5RbLOq9CwNYk8ihE1cmSqly9lnd9nyBhS5i3N7CUr+bnjdwCcu3SFR0+eUqrOt+StUJcZC5db1+/cdwgDe3TAzu7NTvGnzl1MmaIFrNN+/gHkq1iPQlUbsHTtpjfah4iIiIh8GdQOQkRERCQCypw+DVeu32TustWULVYw1LJdnoeYM3EEAMUK5OHho8c8febFjn0Hmft8fvkShYkRzQ2AzTv3cujYKfJX/gYAXz8/4saO+doY/mu7SJEcqVCiCAAemdOzcfseALbs8mTKCEvC1t7enmhuUdnpeYgqZYpb2zBULVuCHZ4HCQkxqVKmuLWytWJJy/68vH3Yc+AI9b/rYo3l38rb3fsPM3fCcAC+qV6RnoNGhRt70lwlyZwuNeMH/0K6VMnDLB/Wp0s4W/23k2fP02PQKFbOmBBq/sp/JuDn50/j9t3ZvGsfJQvlA6DfT23p91NbhoydzPjpc+jT8TuCgoI4dPwka2b9ia+fP4WrNSJ39sycu3SFOLFi4pE5A1t3e742llmLVnDw2Ek2zJ1inXdu12oSusfj4tXrlK3XgkzpUpMyaeK3Pk4RERER+fwoCSwiIiISQVUsVYRuv41g/dzJPHj0+J33Y5omDWpWon/X9h9sO0cHB2uLA3s7e4LesL3EmwgJCSG6W9RX9rf9d9z/Mnv8MKbNXUydVh2pXbkMDWpUJmmiBNblnfsNDTfZWrtSGbp8922Y+ddv3aFWyw5MGdE/3MSqs7MTlUoXY/m6zdYk8L/qVi1PlSbf06fjdySKH49YMaIT2dWVyK6uFMrtwbFTZzl0/BQrN2xh7ZYd+Pn78/SZN03ad2fa6IFhxtq4Yw+D/pjEhnmTQ1UkJ3SPB0CKJIkonDcnR46fVhJYREREJIJQOwgRERGRCKpx7Wr0/LEVmdKlDjW/QG4P5ixeCcDW3Z7EihEdt6hRKJjbg7nP2zWs2byDR0+eAlC8QB4WrdpgfQjZw8dPuHL95mvHf5ftihXIzcQZluRtcHAwT54+o2AuD5at24yPry/ePj4sXbuJgrk8KJQ7B8vWbcbXz49nXt6s3LgNsPTTTZY4IQtXrgMsyeijJ88AkC9nNuYtWwPwny0tShXOz8yxQ9m0YCpuUaNSs8WPlK3fksvXbgCWSmDP1fPCvMJLAD9+8pSqTX/gt67tyZ8ru3W+l7cPt+7cAyw9gVdv2kbalJaq43OXXvQeXr5us3V+xVLF2Ol5iKCgIHx8fdl3+BjpUiWnf9f2XNy7nrM7V/PPmMEUzZ8r3ATw4eOn+L77ryycPDpUP+FHT55aq6XvP3zErv2HSZ86xav/oURERETki6JKYBEREZEIKlH8ePzQ9Jsw83t3aEPLLj+To0xNXF2cmTyiPwC9fmxNw7ZdmVuyGvlyZLM+fCx9mpT07fw9FRq2ISQkBEcHB0b/2iNUZWx43mW74T935bvu/Zg2dzH29vaM6d+TvDmy0rBmZQo8byvRtG51a2/eWhXLkLNsLeLGiknOLBmt+5k2egBte/3GwDF/ERgYRO3KZciSIS3Df/6Jxu26M2zCVCqVKvba9zBWjOi0bfYNbZt9g+fhY9jb2792m/83fvocLly+ym+//8lvv/8JwMp/xmOaUKN5e/wDAggJCaFIvly0bFALgF6DRnP24mXs7OxIkjA+fwyw9G1OnzoFpYsUIEeZWtjZGTStW52MaVO/cmyAvsPH4pElI5VKFaXbgJF4+/hYW2UkTuDOosm/c/rcRb7v8St2dnaEhITQpU1T0qdJ+dbHKiIiIiKfJ+Plpz6LiIiIyJfFMAzT/8oRW4chXwmnpFkxTfP1/TRERERE5LOidhAiIiIiIiIiIiIiEZjaQYiIiIjIe3nw6DFl67cMM3/NrD+JFSP6pw9IRERERERCUTsIERERkS+Y2kHIp6R2ECIiIiJfJrWDEBEREfkKxUyf97338ff8pbTvPeA/17l87QZzlqx677E+N6fPX6Jw1YZETZ2TEROnh1q2dstOMhWrTPrCFRk6brJ1fuN23clUrDLZS1WnZec+BAYGAjB78UpylKmJR+kaFKnWiKMnz1i3adm5D4k8ipK9VPW3juXazduUrvMtWUtUI1vJaoyZMtO67Jvvu5CrXG1ylatNmgLlyFWu9nu/JyIiIiLy+VISWEREREQ+mivXbzJn6cdLApumSUhIyCunXyUoKOi9xo0Z3Y0RfbvSoUXjUPODg4Np33sAy6aP48iGxcxdtoZTZy8AULdqeY5tWsrBdQvx9fdnypzFACRLnJAN86ZwcN1CurdryXfd+1n317BWFZZPH/9OsTjY2zO4V2eObFzM9iUzmPD3HGssM8cOxXP1PDxXz6Nq2RJULVv8vd4PEREREfm8KQksIiIiEoHVbPEjeSvUJVvJakyatSDUss79hpKtZDXK1GvBvQcPAfhj6kyylqhGjjI1afDDTwA8fPyEmi1+JEeZmhSq2oBjp86GGad5p94sWrneOv1vpXGvwaPZ6XmIXOVqM3rSPwQHB9PttxHkr1SfHGVq8tfM+f8Z//AJ06zr9hsxDrBUF2cqVplmHXqSvVR1duw7GGr62s3bdPttBNlLVcejdA3mL18DwNbdnhSv2YTq37Yja8lq7/iOWsSNHYucWTPh6Bj6ERueh4+TMlliUiRJRKRIjtSuVJbl67cAUK54IQzDwDAMcmbNxI1bdwDIlzMbMaK5AZDHI4t1PkChPDmIEd3tnWKJHy8O2TOnByBqlMikS5WCG3fuhlrHNE0WrlxH7crl3v5NEBEREZEvhh4MJyIiIhKB/Tm0LzGjR8PXz4/8lepTrVxJYsWIjrePLzkyZ2BYny78NnoC/UdNYPSvPRg2bipndqzCySkSj588BaDfiHFky5iOBX+NYvPOvTTr2AvP1fPeaPz+Xdsz8s/pLJn6BwCTZi0gWtQo7Fo+C3//AIrWaEzJQvlIniRRmG3Xb9vF+ctX2blsJqZpUv3bdmzfe4DECdw5f+kqk4f3J49HFi5fuxFqevGqDRw5eYb9a+Zz/+FjClSuT8HcOQA4dPwUB9ctDHe8b77vwtmLV8LMb9+8IQ1qVHqj4715+y6J47tbpxPGj8u+Q8dCrRMYGMisRSsY/kvXMNtPnbOYMkULvtFYb+PytRscOXGa3Nkyh5q/Y99B4saORerkST/4mCIiIiLy+VASWERERCQCGzt1FkvXbgLg+q07nL90lVgxomNnZ0etSmUAqFetInVadQQgU/rUNG7fncqli1G5jKVFwC7PQ8yZOAKAYgXy8PDRY54+83qneDZs282x02dZtHoDAE+ePuP85avhJmU3bNvNxu27yV2+DgBe3j6cv3SFxAncSZIwPnk8sljXfXl65/5D1KlcFnt7e+LFiUWhPDnYf/QEblEikytrpnDHAkuLhE+hXa8BFMyTg4K5PULN37JrH9PmLmbzwmkfdDwvbx/qtu7EsD5dcIsaJdSyuctWU7ty2Q86noiIiIh8fpQEFhEREYmgtu72ZNOOPWxb/DeuLi6UqvMtfv7+4a5rPP9z6dQ/2L73ACs3bGXQH5M4uG5BuOv/Pwd7e0JMSy/ekJAQAp4/9Oz/mabJyL7dKF2kwGv3aZomXb5rRotvaoWaf/naDSK7uoSa9//Tr+L6H+t9iErgBO5xuXbrtnX6xq27JHSPZ53uP2oC9x4+Yt7A3qG2O3bqLK279mXZ9LHEihH9jcZ6E4GBgdRp3ZG6VctTtVzJUMuCgoJYumYju1fM+WDjiYiIiMjnST2BRURERCKoJ8+8iB7NDVcXF06fv8TeQ0ety0JCQli0ytLDd+6SVeTPlZ2QkBCu3bxN0fy5GdD9R54+88LL24cCuT2Ys3glYEksx4oRPUxFadJECTh47CQAy9dvITDQ8uC1qFEi4+XtY12vVJH8/DljPoHPk8RnL17G28eH8JQqkp/p85ZYt79x+w537z947XEXzJWd+SvWEhwczL0HD9mx7yC5smZ67XYvPyzt5debJoABcmbNyPlLV7l09ToBAYHMW76GiqWKADBl9iLWb93FP2MGYWf34jT86o1b1G7VkakjfyNNimRvPNbrmKZJq59+IV2qFPzYolGY5Rt37CVtyuQkih8vnK1FREREJCJRJbCIiIhIBFWmSAH+mjGfLMWrkiZlMvJkf9E+IbKrC56HjzNwzF/EjRWTGWOHEBwcTNMfe/DkmRemafJ903pEj+ZG7w5taNnlZ3KUqYmrizOTR/QPM1azejWo2aI9OcvWonSR/NbK3MzpUmNvZ0fOsrVoWLMybZt9w5XrN8lToS6maRInZgzm/zUq3PhLFc7P6fOXKFytIQBRXF2ZOnoA9nb/XcdQpWwJ9hw8Ss6ytTAMgwHdf8Q9bmzOXLj0ju9kWLfv3id/pXo89fLGzs6OP6bM4PCGxbhFjcKoft2p2KgNwcEhNKldlQxpUgHwQ8/+JEkYn8LVLAnZqmWL07N9awaMnsjDR49p13sAYKmq3r1iNgAN23Zl2+793H/0mBR5StG7Qxua1q3OnzMsPZlbNqj9yliOnT7LzEUryJQuNbnK1QagX5e2lCteCID5y9eoFYSIiIjIV8IwTdPWMYiIiIjIOzIMw/S/csTWYchXwilpVkzTNF6/poiIiIh8TtQOQkRERERERERERCQCUzsIEREREbGp46fP0bRDz1DznCI5smPpTBtFJCIiIiISsagdhIiIiMgXTO0g5FNSOwgRERGRL5PaQYiIiIjIF6dUnW85cPTEJx2zz5AxpMxbmpjp84aa7+8fwDffdyF94YoUrPINl6/dACAwMJBvO/bCo3QNshSvypCxk63bjJ70D9lKViN7qeo0bNsVPz9/AFp1+ZmcZWuRo0xN6rbuhJe3z6c7QBERERGJsJQEFhERERF5AxVKFgm3RcXUuYuJHs2NU9tW0O7bBvQcNAqAhSvX4x8QwMF1C9mzcjaTZi3g8rUb3Lh9h7FTZ7F7xWwOrV9EcHAI85avAWBony7sXzOfA2sXkDiBO+Onz/6UhygiIiIiEZSSwCIiIiLy3rx9fKjS5Adylq1F9lLVmf88qfnb6Ankr1Sf7KWq06ZbP/5tRVaqzrd07jeUfBXrkaV4VfYfOU7tlh3IUKQSPw/9A4DL126QuXgVGrfrTpbiVanbuhM+vr5hxl6/bReFqzYkT/k61GvT2Vo923PQKLKWqEaOMjXp2n/4ex9jHo8sxI8XJ8z85es307BGZQCqly/F5p37ME0TwzDw9vElKCgIXz9/HB0dcIsaBYDg4GB8/fwJCgrCx9fXut9/l5umia+/P4ahzgsiIiIi8v70YDgREREReW/rtuwiQbw4LJ1mSeA+efoMgDaN69GzfWsAmv7Yg5Ubt1KxZFEAIjk6sHvFbMZMmUnN5j+ye8VsYkaPRvrCFWjXvAEAZy9cZuLgX8ifKzstO/dhwt/z6NiqsXXc+w8fMWjMX6yeNZHIrq4MGz+F0ZP+pnWjuixdu4ljm5ZiGAaPnzwNE/OWXfvo8uuwMPNdnZ3ZuvjvNz72m7fvkiiBOwAODpZE74NHj6leviTL128maa6S+Pj6MrRPF2JGjwZE48eWjUmVrwwuzs6ULJSPUoXzW/fXonNv1mzeQfpUKRjSq9MbxyEiIiIi8iqqBBYRERGR95YxXSo27thDj4Ej2bHvINHcogKwdZcnBat8g0fpGmzZtY9TZy9Yt/k3GZwpbSrSp0lJ/HhxcHKKRPIkibh+8zYAiRO4kz9XdgDqVavArv2HQo2799BRTp27SNEaTchVrjb/LFjO1eu3iBY1Cs5OTrTq8jNLVm/A1cUlTMxF8+fGc/W8MK+3SQD/F8/Dx7G3s+fyvvWc2bGKUX/9zcWr13n05Ckr1m3mzI5VXN63Hm9fX2YtWmHd7q9hv3J53wbSpkrB/OVrP0gsIiIiIvJ1UyWwiIiIiLy3NCmSsWflHNZs2s4vw/6gWIHcdGrVlHa9f2PX8tkkTuDOryPH4+cfYN3GySkSAHZ2djhFcrTOt7OzIyg4GCBMO4T/745gmiYlCuXlnzGDw8S0c+lMNu3cy+JV6xk/fQ5r50wKtfxDVQIncI/L9Zu3SRQ/HkFBQTx95kWsGNGZs3Q1pYvmx9HRkbixY5E/RzYOHj2BYRgkS5yQOLFiAlC1bAl2HzhC/eoVrfu0t7enduWyDJ8wlca1q75xLCIiIiIi4VElsIiIiIi8t5t37uLq7Ez96hXp0Koxh46fxs/fH4DYMaPj5e3DolXr33q/V2/cYs+BIwDMXbqa/Dmzh1qeJ3sWdu8/zPnLVwFLb+KzFy/j5e3Dk2fPKFe8EEP7dOHoqbNh9v2hKoErlizKPwuXAbBo1XqK5s+NYRgkSejOll37rHHtPXSMtCmTkziBO3sPHcXH1xfTNNm8cy/pUiXHNE3rcZimyYr1W0ibMvnbvWEiIiIiIuFQJbCIiIiIvLfjp8/RfcBI7OzscHRwYMxvPYkezY1mdWuQvVQN3OPEJmfWjG+93zQpkzHh7zm07PIz6VOnoFXD2qGWx4kVk7+G9aNR2274B1iqjH/p/ANRI0emZov2+PkHYJomQ3p3fu9j7D5gJHOXrsLH148UeUrRtG51endoQ9M61WjaoSfpC1ckZnQ3/vljCACtG9WlRec+ZCtZDdOERrWqkDl9GsDyALk8FeriYG9PtozpaF6/JqZp0rxjb556eWGaJlnSp2XMbz3fO24REREREePfJzSLiIiIyJfHMAzT/8oRW4fxUVy+doNqzdpyaP0iW4cizzklzYppmsbr1xQRERGRz4naQYiIiIiIiIiIiIhEYKoEFhEREfmCReRKYPn8qBJYRERE5MukSmARERERsamY6fPaZNyWnfuQyKMo2UtVD7Ns7NRZZC5ehWwlq9F9wEgAAgMD+bZjLzxK1yBL8aoMGTsZgDMXLpOrXG3rK3bG/Pw+eQYAR0+eoXDVhniUrkG1Zm15+swr3FjWbtlJpmKVSV+4IkPHTf5IRywiIiIiXys9GE5EREREvkoNa1WhTeN6NOsY+uFrW3btY/n6LexfPR8np0jcvf8AgIUr1+MfEMDBdQvx8fUlW8nq1K5clrQpk+G5eh4AwcHBJM9TiipligPQumtfBvXsSOG8OZk2dzEjJk7jl84/hBovODiY9r0HsGrmRBK5xyN/5fpULFmU9GlSfoJ3QURERES+BqoEFhEREZEPpuegUYyfPsc6/evI8YyYOB0vbx/K1GtBnvJ18Chdg2XrNofZdutuT6o2fZEgbd97AH/PXwrAwWMnKVm7GXkr1KVCw9bcunPvvWMtlCcHMaK7hZn/54z5dPmuGU5OkQCIGzsWAIZh4O3jS1BQEL5+/jg6OuAWNUqobTft3EuKJIlJmigBAOcuXaFQnhwAlCiUj8WrN4YZz/PwcVImS0yKJImIFMmR2pXKsnz9lvc+PhERERGRfykJLCIiIiIfTK2KZVi4cp11esGKddSqVAZnp0jM/3Mke1fNZd2cSXTtP5w3fTZFYGAgHfoMYvb4YexZOYcmtavy89AxYdabvXhlqLYM/77qtu70Vsdw7tIVdu47SMEq31CydjP2HzkOQPXyJYns6kLSXCVJla8MHVo2Jmb0aKG2nb9sDbUrl7VOZ0id0prwXrhyHddv3Q4z3s3bd0kc3906nTB+XG7cvvNWMYuIiIiI/Be1gxARERH5QhiGYQBJgIIvvT4r2TKl5+79h9y8c5f7Dx4RI5obiRO4ExgYSO8hv7Nj30Hs7Oy4efsud+49wD1u7Nfu8+zFy5w4e57yDVoDlvYJ4W1Xr1oF6lWr8N7HEBQUxMPHT9i+ZAb7jxyn/nddOLNjFZ6Hj2NvZ8/lfet59OQpxWs1pXjBvKRIkgiAgIBAVmzYyq9d21v3NXFoXzr+MoiBv/9JxVJFieTo+N7x2ZphGJ2AHcAh0zQDbB2PiIiIiLyeksAiIiIinynDMOyBzEABXiR9HbEk4HYAkwFPmwX4CjUqlGLRqvXcufeAmpVKAzB7ySruP3zEnhWzcXR0JE2Bcvj5+4fazsHBnpCQF9XB/v6W/KJpWipqty355z/Hnb14JSP+nB5mfsqkiZkzYfgbx58wfjyqli2BYRjkypYZOzs77j98xJylqyldND+Ojo7EjR2L/DmycfDoCWsSeM2WHWTLlI54cWJZ95UuVXJWzZgIWJLZqzdtCzNeAve4XHupQvjGrbskdI/3xvHaQHKgIZDSMIz9vPh53GOa5hObRiYiIiIi4VISWEREROQzYRiGK5CbFwnffMBNYCewFugNXDBf6qNgKQ7+vNSqVIY2Xftx/9EjNsydAsCTZ17EiRUTR0dHtuzax5XrN8NslyRhAk6fv4i/fwC+fn5s2rmX/LmykyZFMu49fMSeA0fImyMrgYGBnLt0hQxpUoXa/kNVAlcuXYytuz0pmj83Zy9eJjAwkNgxY5AkoTtbdu3jm+qV8PbxYe+hY7T9toF1u3nLVlOncrlQ+7p7/wFxY8ciJCSEQWP+osU3tcKMlzNrRs5fusqlq9dJ6B6PecvX8PfvA9/7OD4W0zR/ADAMIxqWn9GCQHcgp2EY53mRFN5hmuZ1mwUqIiIiIlZKAouIiIjYiGEYcbFU+f5b6ZsZOIolgTYeaGia5vs/Ae0Ty5AmFc+8vUkYLy7x48UBoF7V8lRv1g6P0jXIkSUDaVMmD7Nd4gTu1KhQmuyla5AscQKyZUwHQKRIjswZP4yOvwzmyTMvgoKCaPttgzBJ4LfVsG1Xtu3ez/1Hj0mRpxS9O7Shad3qNKldjZZd+pC9VHUiOToyafivGIZB60Z1adG5D9lKVsM0oVGtKmROnwYAbx8fNm7fw9gBvUONMXfZGib8bXlQXtWyJWhcuyoAN+/cpfVPfVk2fSwODg6M6tedio3aEBwcQpPaVd/72D6F51W/a56/MAwjEpAdy89yHWCMYRjeWH6edz7/84RpmiG2iVhERETk62W86QM5REREROTdPe/nm4rQ/XzjAbt4UTnpaZqm71vu1/S/cuQDRysSPqekWTFN843Kz5//zKchdDuTOIT9mff7SOGKiIiIyHNKAouIiIh8BIZhOPKiKrIglkSYPy/dKo+lKjL4PcdRElg+mbdJAofHMIx4hE4KZwSO8OL/xC7TNO9/iFhFRERE5AUlgUVEREQ+AMMw3IC8vEhu5QIu8iK5tdM0zasfYVwlgeWTed8k8P8zDCMyoftg5wVuELqFxEVTX1pERERE3ouSwCIiIiLvwDCMhIRu7ZAa2M+LxNVu0zQff4I4lASWT+ZDJ4H/n2EYDlh6Y/9bPV8IsCN0Bf0R0zSDPlYMIiIiIhGRksAiIiIir2EYhh2QgdCtHaISOjF10DTNABvEpiSwfDIfOwn8/573FU5K6AsuSYB9vPi/t8c0Ta9PFZOIiIjIl0hJYBEREZH/YxiGM5CTF0mn/MADXmrtAJz5HG5RVxJYPqVPnQQOj2EYMYF8vPj/mR04TejWK7dsF6GIiIjI50dJYBEREfnqGYYRC0ui99+kUjbgJKGTSrdtFuB/cHF2vu3n7x/P1nHI18HZyemOr5+fu63jeNnzizY5eFGlXwB4TOhK/dOfw0UbEREREVtRElhERES+Ks9vL0/Oi4RRQSAxsIcXCaN9ur1c5Mv0vH1LOkK3kHDjRb/uncAB0zT9bRakiIiIyCemJLCIiIhEaM8fNJWF0AkhgO28SAgd1YOmRCIuwzAS8OKiT0EgLXCQFxd+dpum+ch2EYqIiIh8XEoCi4iISIRiGEYUIA8vKn3zAtcIfWv4Zd0aLvL1MgwjKpbPhn8/J/IAlwn9OXFVnxMiIiISUSgJLCIiIl80wzDcCV3hlwE4jKXSdyewyzTNBzYLUEQ+e4ZhOAJZCX3HQCChHwZ5zDTNYJsFKSIiIvIelAQWERGRL8bzfr5pCZ2oiQns4kWyZr9pmn42C1JEvnjPP2tSEvoCUwJgN6F7h/vYLEgRERGRt6AksIiIiHy2DMOIBOTgxS3bBQAvQt+yfco0zRCbBSkiXwXDMOIA+XmRFM4MHOelB86ZpnnXdhGKiIiIvJqSwCIiIvLZMAwjOpCPF0mWHMBZXtyOvdM0zes2C1BE5DnDMFyAXLz4vMoP3CF0C4lz6issIiIinwMlgUVERMRmDMNIQujWDskBT14kUfaYpvnUdhGKiLwZwzDsgYyEbiHhQug7Fw6ZphlosyBFRETkq6UksIiIiHwSzxMkmQidIHEidILksBIkIhJRPL/Q9fJnXgosF7r+bSGxWxe6RERE5FNQElhEREQ+CsMwXAl9q3Q+4DYvbpPeAZzXrdIi8rV43vImLy8+F3MC53jpYphpmjdsFqCIiIhEWEoCi4iIyAfx/KFJL1e8ZQaO8SK5sUsPTRIReeH5wy89ePG5+e/DL/+9ULYDOKmHX4qIiMj7UhJYRERE3pphGAaQitBJX3dgNy8SF56mafrYLEgRkS/M88/WNITulR4L2MWLz9b9pmn62SxIERER+SIpCSwiIiKvZRiGI5CN0ImJAEL38z1ummawrWIUEYmIDMNwx3LB7d+LbhmBw4S+y+KBzQIUERGRL4KSwCIiIhKGYRhuvOhbWQDIDVwidN/Kq7aLUETk62QYRmQgDy8uyOUFrhG63/ol9VsXERGRlykJLCIiIhiGkZDQrR3SAAd4kfTdbZrmY5sFKCIi4TIMwwFLD/Z/P78LPV/08p0aR03TDLJNhCIiIvI5UBJYRETkK2MYhh2QntCtHaIS+kFEB03T9LdZkCIi8k6e9xVOxos7OQoCSYC9vPiM32uappetYhQREZFPT0lgERGRCM4wDGcgB6GfPv+Q0FViZ3TrsIhIxGQYRkwgPy9+D2QHTvJSCwnTNG/bLkIRERH52JQEFhERiWDC+bKfDTjFiy/7O03TvGWzAEVExKZ0cVBEROTroySwiIjIF+z/bvv994u8bvsVEZE3Fk6boAJY2gTt4sXvkgOmaQbYLEgRERF5L0oCi4iIfEHCeQBQQcBADwASEZEPSA8MFRERiViUBBYREfmMGYYRGcjDiy/heYDrvNTHEbikW3ZFRORjMgzDDcjLi0rh3MAlXroIaZrmVdtFKCIiIv9FSWAREZHPiGEY7li+XP9bfZUROMyLL9m7TNN8YLMARUREAMMwHLH0nH/5zhR/Xvy+2gkcN00z2FYxioiIyAtKAouIiNjI836+aQj9BTo2Lyp8dwD7TdP0s1mQIiIib+D577RUhG4h4Q7s5sXvNE/TNH1sFqSIiMhXTElgERGRT8QwjEiAB6EfvONF6NYOJ03TDLFZkCIiIh+IYRhxeJEULoClp/1xXqoWNk3znu0iFBER+XooCSwiIvKRGIYRHcjHiy/AOYFzhP7ye91mAYqIiHxChmG4Arl4cTE0H3Cb0C0kzqvPvYiIyIenJLCIfFQuLs63/fz849k6DolYnJ2d7vj6+rnbOo7/ZxhGYkK3dkgBePLiy+0e0zSf2i5CERGRz4dhGPZAJl5cLC0EROKlh80Bh03TDLRZkCIiIhGEksAi8lEZhmEG3Llg6zAkgokULyWmaRq2jOH5F9eMhG7t4Ezofr6H9MVVRETkzRmGkYTQF1STA/t48fv1s7mg6hLJ8bZfYJCKHeSDcXZ0uOMbEPjZFTqISMSgJLCIfFRKAsvHYIsksGEYLkBuXlQr5QfuELpaSbewioiIfEAvtVb6NymcAzhL6NZKN2wUm/lgdhdbDC0RVKx6Q21e6CAiEZeDrQMQERH5HBmGEZvQTzjPAhzDUon0F9DENM27totQREQk4jNN8zGw+vkLwzCcePGQ1frAOMMwnhH6ouwpPWRVREQkNCWBRUTkq2cYhgGkJHRrhwTAbixfJrsD+0zT9LFZkCIiIoJpmv5Yfj/vBoY+/x2elhe/w7sAMQ3DeLk90wHTNP1sFLKIiMhnQUlgERH56hiG4QBkI3TPwSBgO5Yvi38Ax0zTDLZVjCIiIvJ6z9swnX7+mgRgGEZ8LBd0CwCjgPSGYRzmRVJ4l2maD20Rr4iIiK3Y2ToAEfn6RIqXksbfdbROBwUFkSBDLqp+0/yt9pM6Z2HuP/jv8/c3WedT6Td0NCPG/fVW28RInvkjRfPCg4ePKFWtPjGSZ6Z991+s8318fKnyzbdkKlCKrIXL0uPXIdZloyZMJkuhMngULU+ZGg24cs3Siu/KtRvkLlmZnMUrkrVwWf6cPsu6zcEjx8hepBzp8xSjQ4++hNc6d+vOPcROlZWcxSuSs3hF+g8f88bHYRiGg2EYvxmGkS+cZVENwyhlGEZfwzA2Ag+BKVgqhxYDeYDEpmnWM01zrGmah5UAFhER+TKZpnnLNM0Fpml2ME0zF+AO/Az4Au2By4ZhHDcMY6JhGA0Nw0j+vKI4FMMw4hqG8b1hGF/c9+Y49YdRpNs0CnSZSv2hi3ji/WkKoVd6nuP09fufZKwrdx9TqtcMcv74F9+OXkZAUNhTt6v3npCw0UiKdJtGkW7T6DRp3SeJTUTkc6RKYBH55CK7unLi9Fl8ff1wcXFmw9YdJHDXg5XfV0BAAIGBQUSO7PpW2zk7OfFLt46cOH2WE6fPhlrWoU1zihbMR0BAAGVqNmTNxi2ULVGUbJkysGftElxdXZg4bSbd+w1i1l9jiB8vDttXzsfJyQkvb2+yFylHxTIlSOAejx9+6sOE4QPInSMbles3Y+2mrZQtUTRMPAXz5GLJzElvdQyGYcQA5gHBwGDDMBIQup9vWuAgluqf4cBu0zQfvdUgIiIi8kUyTdML2Pj89e8dQVmwnCNUAgYDpmEYL/cVPgb4AHWAEoZhNHq+ny+CSyQHtg5qAsB341Yxad0hOlULc538g1u1/xxlPFKSLlHsN97mkZcvMaK4vPVYfWdto035HFTPn55Ok9YxY/NRmpXKHma9ZPGiW98LEZGv2Rd3RVNEIoayJYqyasNmAOYuXk6dapWsyx4+ekyNxq3wKFqeguVqcPTEacBSsVq+dmOyFi5Lqw7dQ1WSzlywhPxlqpGzeEW+69yT4OA3K+J81XYxkmem94Bh5ChWgYLlanDnrqWi4c7d+9Rs0pocxSqQo1gFdnseACyVsdkKlyVb4bL8PnGqdf8DR44lQ74SFK1Um7PnL1rnX7h8hYp1m5CnVGWKVa7D6XMXALh05RqFytcke5Fy9Bk4/I2O4dTZ8/z08wAy5S/F2YuX3mibl0WO7EqBPDlxdooUar6rqwtFC1q+LESKFInsmTNy4+ZtAIoWzIerq+VkPXeObNy4ddu6npOTEwD+/gGEhFieyXLrzl2eenmRJ2d2DMPgm1rVWLZ6/VvHGh7DMP5N8BrAPeAwli9uDYDrQFsglmmahU3T7GGa5iolgEVERL5epmkGmaZ50DTN303TrA0kBAoBK4FMwAzgAbAI2Aw4A7sMw0hqq5jfR67UCbj10JK/vnTnEbUGzqd4j7+p8Msszt54AMDdx940HL6Ywl2nUbjrNPadtdzlNW/7CUr2+oci3abRcdJagp+f2yVpMor+c7dTuOs0Sveewd3H3uw7e4M1By7w88ytFOk2jUt3Xn265RcQxPwdJ6ny6xy6Tdv41sdkmibbT1ylcp60ANQtnJFV+8+/9X5ERL4mSgKLiE3UrlqReUtW4Ofnz7GTZ8jtkdW6rN+QUWTLnJGDW1bxa49ONGvbGYD+w34nf56cHNm2hirlS3P1+k3AkgSdv2QlW1fMY/+mFdjb2zNr4dLXxvBf23n7+JAnR3YObF5JwXy5mDxjDgAdevalcL48HNi8kn0blpEhbRoOHjnG9NkL2Ll6ETtWL2TyzLkcOnaCg0eOMW/JCvZvXMGyWZM5cPiodezvOvVk5ICf2bt+GYN/7k67rn0A6NjrV1o2qc+hrauJHy/uK2P39vZh+uwFFK1UmzadepA+TSoObFlJ9swZAejcu7+1pcLLryG/T3ibfyarx0+esnLdJooVyh9m2bRZ8ylTvIh1+tqNm3gULU8Kj4J0/qEVCdzjcfPWbRLFd7eukyhBfG7euhPuWHsOHCJHsQpUqtc0TGXy/3t+6+ZRIDEQDbgKVAHimKZZxTTNoaZp7nr+EBkRERGRMEyLi6Zp/m2aZivTNDMCKYAxQGQs5xmZgHPP+w1/MYJDQth24grlcqQCoMNf6xjUpCSbBjSib4OidJmyAYDu0zdSIH1itg1uwuaBjUiXKDZnbjxgyZ4zrP6lPlsHNcHOsGP+jpMAePsHkjNVfLYNbkL+dIn4e9NRcqdJSNkcKen7TRG2DmpC8ngxwsRz/Mpduk7dQMGfpuJ57ib9GhRj4g8VATh386G1bcP/v/6/ncXDZ75Ei+yEg70lpZEgVlRrovv/Xb33hKLdplOp72x2n77+Yd5YEZEvkNpBiIhNZMmYjivXrjN38fIwLQF27jvA3MljAShWKD8PHz3i6bNnbN/jybwp4wAoX6oYMaJHA2Dz9l0cOnqcfGWqAeDr50ec2LFeG8N/bRcpUiQqlC4OgEeWTGzcuhOALTv3MPWPYQDY29sTzS0qO/fup0r50tY2DFXLl2bnHk9CQkyqlC9trZitWKYkAF7e3uzef5B6zdtaY/EPCABgt+cB5k2xHPs3taqG6sP7siRZ8pE5Q1omjBhIutQpwywf9muv1x7/mwoKCqJh6/Z837wxKZIlCbVs5oIlHDh8jI1LXvT+TZwwAQe3rOLm7TvUbNya6hXLvfFY2bNk5PyBbUSJHJnVGzZTq0lrTu7Z9Mr1TdM0DcNIDeTHUsFTCUvlb0EsyWERERGRdxEIdAByA6ewJITPA+Ffxf7M+AYEUaTbNG499CJNwlgUzZIUL78APM/epNnoF8US/oGWu+C2n7jKuO/KA2BvZ4ebqxNzt5/g8MXblOz1j3WfcaJZzncjOdhTxsNyDpo1hTtbjl1+bUzjVnrSf+52fqlflH4NiuLkGDodkTpBzA/etiFe9MgcGdOKmFFdOHzxNg2HL2Hn0Ka4uTp90HFERL4ESgKLiM1ULFOSrn0Hsn7RLB4+eve7803TpEHt6vzWq8sH287RwYF/nw9ib29PUHDQO8f3/0JCQoju5sb+TSvCXR7Oc0nCmDP5D6bOnEftZt9Ru2pFGtauTtLECa3LO/fuz5ade8JsV7tqRX5q1/qt4m3TqSepkiejXaumoeZv3LqTQaPGsXHxLGsLiJclcI9HxnRp2LHXk/y5c3D9ecsIgOs3b5Egftg+0G5Ro1r/Xq5kMdp1+5n7Dx4SO1bMV8ZnmuZVLBXAcwAMw4gCeL/VQYqIiIiE5g30BI6bpvnM1sG8rX97Avv4B1Jr4HwmrTtEvcKZiBbZ6Y0TraYJdQtnok+9wmGWOdrbvThXtjMICg557f5qFcxAYHAI0zceYcfJq9QvkomS2VJYq3nP3XxI89+Xhbvtst51iRbZ2TodM6oLT7z9CQoOwcHejpsPnhE/ZpQw2zk5OliTzdlSuJM8XnQu3HpE9pTuYdYVEYno1A5CRGymSb2a9OrUlswZ0oaaXzBPTmYvslQobN25h1gxY+IWNSqF8uZiziLLieGajVt49PgJYKkWXrxiNXfvWfr2Pnz0mCvXbrx2/HfZrljBfEycZql6DQ4O5snTZxTMm4tlq9fj4+OLt7cPS1eto0DeXBTKZ5nv6+vHMy8vVq6z9DtzixqVZEkSsWDZKsCSjD5y4hQA+XLlYO4SS3J49sLwT4IBShUtxKy/xrB56RyiRY1CjcatKFuzIZevWm5xG/ZrL/ZvWhHm9bYJ4D4Dh/Pk2TOG9+8dav6hYyf4vksvFv09kbhxXjz44/rNW/j6Wm7Xe/T4CTv37SdNyhTEjxcXtyhR2Lv/EKZpMnP+YiqVLRlmvNt371l7PXsePEJISAixYoa9lfC/mKbpZb7cMFpERETkLZmmGWya5u4vMQH8MlcnRwY2LsG4lftxdXIkSZxoLN1zBrCcgx6/cheAwpmSMnX9YcDSQuKpjz+FMyVh+b4z3Htiubb+yMuXa/ee/Od4UZwj8cw3INxlcaJFpn3lPOwc2pTW5XKwbO9ZcnecxLiVnsCLSuDwXi8ngMFSNFEwY2KW7bUcy5xtJ6wtL152/6mPtY/x5TuPuXD7EcniRXuTt05EJMJRJbCI2EyiBPH5oUWTMPN7d2lPix+74lG0PK4uLkz+fSgAvTq3o2HrH8lauCz5cmYnSaIEAGRIm5pfunWkfJ0mhISE4OjowO8D+4aqjA3Pu2w3on8f2nTuydRZ87C3t+ePwf3Im8uDRnVrkL+spa1Es2/qWHvz1qpSgRzFKxA3dixyZMti3c/0cSNp27U3A0eOJTAoiNpVK5I1Y3pG9O9NozYdGDZmYrhJ0v8XK2YM2rZsStuWTfE8eAR7+3e7tpc6Z2GePvMiICCQZavXs3LuNNyiRmHQqHGkTZ2S3CUrA/Bds4Y0a1CH7n0H4eXtbW1pkThhAhb/8yenz13gp58HYBgGpmnSsU1za5J/zOC+fNvuJ/z8/ClTooi1Dcif0y1J9ZaN67No+WomTp+Fg709Ls7OzJg4+o0qo0VEREQkfFmSxyNjkjgs3HWKiT9UoPPk9QxfvJvA4BCq50tHpqRxGdCoOB0mrWPGlmPY2xkMa1aKXGkS0qN2IWoOnE9IiImjgz2Dm5YkcZxXJ1Gr50/Hj3+t4681B5naoXK4fYEB8qdPTP70iXnq48/BC7fe6bh+rleE5mOWM2DeDjIni0uDYpkBWL3/PIcv3aZ7rYLsOnWNQfN34uhgh51hMPzbUsSI4vJO44mIfOkMFUuJyMdkGIYZcOeCrcOQCCZSvJSYpqnssIiIiNiMYRjmg9lv145M5L/EqjdU57gi8tGoHYSIiIiIiIiIiIhIBKZ2ECIS4T14+IgyNRuGmb92wT9v3W9WRERERERERORLoySwiER4sWLGYP+mFbYOQ0RERERERETEJpQEFhEREREREfmIkjQZxdVpP77XPmZtPc7hi7cZ0vTVDw++eu8J+87eoGaBDO811ufm7I0HtJ24mqOX7tKzTkF+qJgbAL+AICr2m01AYDBBwSFUzpOGbrUKAtDqjxUcungbR3t7PFK6M6J5aRwd7K37PHjhFmX7zGRSu0pUzpOWa/ee0GjEEkJMk8CgEFqU8aBpqWxhYjl+5S6dJq/D2y+QJHGiMeH7Cri5OnH13hPydZpCqgSWOw1zpkrA8OalAajcbw63H3vhEsmSglnQvRZxokX+mG+ZiEgYSgKLyGcrRvLMPLp07L328fecBRw4cpzRA3955TqXr15nt+dB6tWo/F5jfW6Gj/2T2QuXARAUFMTpcxe4edKTmDGikzpnYaJEjoy9vT0ODvbsWbcUgCMnTvFDl954eXuTNHEi/h4/AreoUQkICOC7Lr04cPgYdnZ2jOjfmyIF8oYZs36Ltpy9cAmAJ0+fEs3Njf2bVuB58AhtOvcEwDRNendpR9XyZQAYPWEKU2bNwwAypU/LpNFDcHZ2+gTvkIiIiEjEcvXeExbuPPXRksCmaWKaYGdnhDv9KkHBITjYv/sjiWJEcWZg4xKs2n8+1HwnR3uW9KpDFOdIBAYFU/6X2ZTIloJcqRNQs0AGJnxfAYCWY1bwz+ajNCuVHYDgkBD6ztpGsSzJrPuKFyMKa/p9g5OjA15+ARTsMpWyOVIRP2aUUGO2/3Mt/b4pSoEMiZm5+Rh/rPCkR21L4jlZvOhsHdQk3GOY+H1Fsqd0f+f3QETkfSkJLCJfvSvXrjN30bKPlgS2nByb2NnZhTv9KkFBQTg4vPvHdKfvW9Lp+5YArFi7kd8nTiFmjOjW5esXzSR2rJihtmndsTuDf+5O4fx5mDZrPsPH/kXfbh2ZPGMuAIe2rubuvftUqt+M3WuXhDmGWX+Nsf79p58H4OYWFYCM6dKwZ90SHBwcuHXnLjmLVaBi6RLcuXefsZOmc2T7WlxcnKnXoi3zliynUd2a73zcIiIiIrbSYPhibj54hl9AEK3K5aBxiazWZT3/3sTmo5eJGz0yk9pVIrabKxPXHGDahiM42BmkTRSbSe0q8cjLl7YT13DlzmNcnBwZ2bw0GZPGDTXO9+NXUcYjJZXzpAVeVBr3m72NszceUKTbNOoWzkTLsh70m72NHSevERAYxLels9OkZLZXxj9m+T6W7DlDQGAQFXKlplutgly994SaA+eTI1V8jly8w9Bmpegwaa11em7XGkxad4gNhy9hGNCpWj6q5UvHjpNXGThvB9EjO3Pu5kP2jWz+zu9rnGiRiRMtMusPXQw13zAMojhHAiAwOISg4GCM5/noUtlTWNfzSBWfmw+9rNN/rTlIpTypOXThtnVepJeqhAMCgwkxzXBjuXDrIfnTJwKgaJak1By4wJoEFhH5nL37pTgRkQ+kRuNW5ClVmayFyzLp79mhlnXu3Z+shctSpkYD7t1/AMAff00jS6EyeBQtzzct2wHw8NFjajRuhUfR8hQsV4OjJ06HGefbdl1YuHy1dTpG8swA9Ow/lB17PclZvCKjJ0whODiYbn0Hkq9MVTyKluevv2f9Z/zDx/5pXbfvkFGApbo4Y/6SNP2hE9mKlGPHHs9Q09du3KJb34FkK1yW7EXKMW+JpWfx1p17KFa5DtUatiRLoTLv9oaGY+7i5dSpVum16527cIlC+Sy315UoUoDFK9cCcOrseYoWzAdA3Dixie7mxoHDr67SNk2TBctWUqdaRQBcXV2sCW0/P38M40W1SFBwEL5+fgQFBeHr40t893jvdpAiIiIiNjamVVk2DWjExgEN+XPNQR4+8wXA2z+QbCnc2TWsGQXSJ2bIwl0AjF66ly0DG7F9SFOGf1sKgEHzd5IlaVy2D2lKrzqF+G78qjcev0+9wuRLl4itg5rQpnxOZmw+RlQXJzb+1pANvzXk701HuXL3cbjbbj56iYu3H7GhfwO2DmrCkUt32HXqGgAXbz+iWans7BrWjMRx3EJNH7p4m2OX77JtcGMW9ajNzzO3cPuRJeF69PJdBjQuHm4C+NvRyyjSbVqY15xtx9/4eMFS1Vuk2zTStRpLkczJyJkqQajlgUHBzNt+ghJZkwNw8+EzVnqeo1nJ7GH2dePBUwr9NJUsP0ygXeXcYaqAAdIlim2tSF665ww3Hjy1Lrt67wlFu02nUt/Z7D59PdR2bSeupki3aQxbtAvzFQlmEZGPSZXAImJzf40aTMwY0fH19SNfmapUq1iWWDFj4O3jg0fWzAz7tRf9h4+h//AxjB74C0PHTOSs5xacnJx4/MRy0tVvyCiyZc7IwukT2bx9F83adn7jh8H91qsLI8dNYsnMSQBM+ns2blGjsnvtEvz9/SlSqTYlixQiedLEYbZdv2U75y9eZteaxZimSfWGLdm+ex+JEybg/MXLTPl9KHlyZufy1euhphetWMOR46c4sHkl9x88In/Zqtbk66GjJzi0dXW4473cbuFl7Vs3o2Ht6uEen4+PL+s2bwvVEsPAoHydJhgGtGhYj+aN6gGQIW1qlq1eT5XypVm4fDXXb9wCIEuGdKxYu5G61Spx7cYtDh49zrWbt8jlkTW8Idmxx5O4cWKTOkVy67x9Bw7TokM3rl67wdSxw3BwcCBhfHc6tGlOSo9CuLg4U7JIQUoVLRTuPkVEREQ+d3+uOchKz3OAJaF44fYjYkZ1wc4wqJYvHQC1Cmag8cglAGRMEodWf6ykfM5UlM+VGoC9Z24wrUMVAApnSsrDZ3489fF/p3g2H73Myav3WL7vDABPfQK4ePsRSeNGD3fdzUcvU7T7dAC8/QK5ePsRiWK7kTh2NHKlfpFcfXl675kb1MifHns7O+JGj0z+9Ik5dOE2UV0j4ZHSPdyxACa3/zB34dnb2bF1UBOeePvRaMQSTl27R/rEcazLu0zZQL50icmXzlK92/PvTfSpXyTcFhYJY7mxfUhTbj30ouGIxVTOnZa40UP37v29VVm6T9/I8MW7KeuR0lpBHC96ZI6MaUXMqC4cvnibhsOXsHNoU9xcnZjwQwUSxIzKM98AmoxcwtztJ6hbONMHOX4RkTelJLCI2Nwfk6azdNU6AK7fvMX5i5eJFTMGdnZ21K5q6eNVv0YVajf7DoDMGdLS6LuOVC5XiirlLBUTO/cdYO7ksQAUK5Sfh48e8fTZs3eKZ/3WHRw7eZpFK9YA8PTpM85fuhxuUnbDlu1s2LqDXCUsVbbe3t6cv3iZxAkTkDRRQvLkfFFh8PL0rr37qVOtEvb29sSLG5tC+fKw/9BR3KJGIVf2LOGOBaHbLbypFes2ki9XjlCtIDYvn0vC+O7cvXefcrUbkzZ1Sgrly82fowbTsWc/Boz8g4plShIpkiMATerX4vS5C+QtXZUkiRKSL5cH9v/RziK8yuPcObJxZNsaTp09z7dtu1C2eFF8/fxYvmYDZz23ED2aG3Wb/8DMBUv4pmbVtz5OEREREVvacfIqW49fYU2/b3B1cqRyvzn4BwaFu66BJQE5p2sNdp26ztqD5xmxZA87hjR9o7Ec7O0ICbFUk4aEmAQEBYe7nonJoCYlKJ41ebjLQ61rwo9V8oRpF3H13hNcnRxDzfv/6Vf5r/W+Hb2M87cehpnfpnzOd0qQRovsTMEMSdh45JI1CTxkwU7uP/Ph7+ZVresdvniHFr8vB+DhM182HL6EvZ0dFZ4n4QHix4xC+kSx2XPmurXlxr/SJIzFwh61ATh/6yHrDltaVDg5OuDkaEmxZEvhTvJ40blw6xHZU7qTIKalRVpUl0jUKJCBgxduKwksIp+cksAiYlNbd+5h07adbF+5AFdXF0pWq4+ff/iVDv+2EFg6czLbd+9j5bpNDBo1jkNb3uwWOQd7B0JCQgAICQkhIDAw3PVM02TUgJ8pXazwa/dpmvBTu9a0aFQ/1PzLV6/j6uoSat7/T79KZFfXVy57l0rgeUtWhEnIJoxveShF3DixqVK+NJ6HjlAoX27SpU7JqnmW6o+zFy6xev1mABwcHBj2ay/r9oUr1CR1yvC/TAQFBbFk5Vr2rF8a7vL0aVIRJbIrJ06f4dLV6yRLkpg4sWMBULVCGfZ4HlQSWERERL44T338iR7ZGVcnR87eeMD+8zety0JMk2V7z1A9f3oW7DxFnrQJCQkxufHgGYUyJiFv2oQs2nUab78A8qZLxIKdJ+lcPT87Tl4lVlQX3FxDPzQ3cexoHL50h6r50rH6wHkCgy3nuFGcI+HlG2Bdr3iW5EzZcJhCGZPg6GDP+VsPiR8jCpGf99F9WfGsyRgwbyc1C2YginMkbj58huMbPMwtb7pETN94hLpFMvLIy4/dp6/T95sinLsZNsH7sg9RCXz/qQ+O9nZEi+yMb0AgW45dpl3lPAD8s+kom45eZnGv2qGqfg/93tL69397K1fIlZobD54RM6ozLpEceezlx94zN2hTPmeYMe898SZOtMiEhJgMX7ybpiWyWWOJEcUZezs7Lt95zIXbj0gWLxpBwSE88fYjlpsrgUHBrDt4gSKZkr73sYuIvC0lgUXEpp48fUb0aNFwdXXh9LkL7D1wyLosJCSEhctXU6daJeYsWkaB3DkICQnh2o1bFC2YjwJ5cjJvyQq8vH0omCcnsxctpWfHtmzduYdYMWPiFjVqqLGSJk7IwaPHqVWlAsvXbCDweRI4apTIPPP2tq5XumghJk6bSbGC+XB0dOTshUskdI9H5Mhhk7OlihXil0EjqVejClEiR+bGrds4vsHD3ArkzcWkv2fTsE51Hj56zI49+xj0czfOnLvwn9u9bSXwk6fP2L57H9PHjrDO8/b2IcQMIWqUKHh7+7Bhy3Z6dmoLwN1794kbJzYhISEMHPkHLRtbkts+Pr6YpknkyK5s2LoDBwcHMqRNHe6YG7ftJG3qlCRKEN8679KVayROGB8HBweuXLvBmfMXSZo4EcHBIew9eBgfH19cXJzZvH0XObJmfqtjFBEREfkclMianGkbjpC302RSJYgZqjdtZCdHDl64xfDFe4jt5srk9pUIDgmh9diVPPXxxzShZdkcRIvsTNea+Wk7cQ2FfpqKi5MjY9uUCzNWo+JZaDB8MYW7TqN41uREfl5xmzFJHOzs7CjcdRr1imSiVdkcXL33hGI9/sY0IbabC/90qhZu/MWyJOfsjYeU7TPTErOzIxO+r/Cfd38BVMyVmv3nblK463QMA36pX4R40aO8Ngn8Nu489qJEz3945huAnWEwYfUBdg1txp1HXnw/fjXBISGEmFA1b1rKeKQEoNPkdSSO7WY9noq50tClRv5XjnH2xgP6zNiMYRiYpsn3FXORIYmlorj9n2toUiIb2VO6s2jXaSavs3xnqZA7NfWLWip6d526xqD5O3F0sMPOMBj+bSliRHHB2y+AWoMWEBgUTHCISZHMSWlUIssHe29ERN6UoYbkIvIxGYZhBtx5dWLT39+fmk1ac/naDdKkTM6Tp8/o3bkdRQrkJUbyzDRvWJf1W7YTN3YsZv75O9GjuVGq+jc8efoM0zSpX7MqP7VrzcNHj2nxY1cuXbmGq4sL44b9RpaM6fh7zgIOHDnO6IG/cOfufWo0boWvnx+lixdmwpQZPLp0jMDAQCrUacKDR49pVKcGbVs2oc/AEaxctxHTNIkTKyYLpk8kmlvUcI9hzJ9TmTJzHgBRIkdm2rjh2NvZU7VBcw5vs7SUuHz1eqhp0zTp3m8QazZuxTAMunf4ntpVK7J1555Q/Ynf199zFrB20zZm/vm7dd7Fy1ep1bQNAEHBwdStVonuHb63Hsv4qTMAqFq+DL/16oJhGFy+ep0KdZtgZ2dHQvd4TBw5iKSJEwLQqkN3WjauR45slpPZb9t1IU+O7NYEMsCM+YsZOmYijg4O2NnZ0bPjD1QpXxqAvkNGMX/pShzs7cmWOSMTRwzAySl0tcv/ixQvJaZphm3kJiIiIvKJGIZhPpjdxdZhSAQSq95QneOKyEejJLCIfFSvSwKLvAslgUVERMTWlASWD01JYBH5mNQOQkREREREROQrcfLqPdqMWxlqXiQHB9b3b2CjiERE5FNQElhE5A0cO3mGpj90CjXPKVIkdq5ZZKOIRERERETeXoYkcdg6qImtwxARkU/s9Y/6FBERMmdIy/5NK0K9/isBXLJafQ4cPvoJI4Q5i5aRvUg5PIqWp2LdJtx/YHkYR7+ho0mWNT85i1ckZ/GKrN6wOdR2V6/fJEbyzIwY9xcA127cpFS1+mQpVIashcsy5s+pn/Q4REREROTzVbnfHA5duP3JxvPxD6Tu4IXk6TSZ/J2n0Hf2VuuyqesPU/CnqRTpNo3yv8zi9PX7oba9fv8pSZqM4o8V+6zz2k5YTdpWYynQRee4IvJ1URJYRCQCCAoKolOvX1m/aCYHt6wiU4Z0jJvyj3V5u1ZNrcnrciWLhdq2y8+/UaZEEeu0g4MDQ/r24Oj2texYtYDxU2dw8sy5T3YsIiIiIiIv+75iLvYO/5Ytgxqz78wNNhy+CECNAunZMaQpWwc1oW3F3PT+J3SxQ69/NlMiW/JQ8+oVycS8bjU/WewiIp8LtYMQka+Ct7cP9Vu25frN2wQHB9Oj4w/UrlqR/sPHsHLdRnx9/ciXy4Nxw37DMAxKVqtPtkwZ2LHXE28fX6aOGcbg38dz4tQZalapQL/unbh89ToV6zXFI0smDh07QYa0qZk6Zhiuri6hxl6/ZTv9hozGPyCAFMmSMGn0YKJEjkyPX4ewYt1GHOztKVW0IIN/6fHOx2eaJibg7eNLrJgmz555kSpZ0tdut3TVOpInSYSrq6t1Xvx4cYkfLy4AUaNEIV3qVNy8fYcMaVO/c3wiIiIi8nF4+wXw7ejl3Hz4jOAQk87V81EtXzqGLtzFmoMX8AsIIneaBIxoXhrDMKjcbw6Zk8Vl9+nr+PgHMu678oxaupdT1+5RNW86etYpxNV7T6g1aAHZksfjyKU7pEsUm3HflcfVyTHU2JuPXmLQgp0EBAaTLF50xrQuRxTnSPSdvZU1By7gYGdQLEsy+jUo9oroX8/VyZFCGZMAEMnBnizJ43HzwTMA3FydrOv5+AdiGC+eqbbS8xxJ40YLE3P+9Im5eu/JO8cjIvKlUhJYRL4KazdvI368uCydORmAJ08tJ47fNWtIr05tAWjyfSdWrttExTIlAHCM5MiedUsZ8+dUajRuxZ71S4kZPRrp8hSnfatmAJw9f5E/Rw4kf+6ctGjflQnTZtDxuxbWce8/eMjAkWNZM/9vIkd2ZeiYiYyaMIU2TRuwdPU6ju9cj2EYPH7yNEzMW3bspnOf38LMd3VxZtvKBaHmOTo6MmZwPzyKlieyqwupUiTj90F9rcvHT/mHGfMWkyNrZob07UGM6NHw8vZm2B9/snr+dEaMmxTu+3b56nWOHD9Bbo+sb/xei4iIiMins/HIJdxjRGFO1xoAPPXxB6B5mex0qZEfgNZjV7L24AXK5kgFgKODPZsGNGLi6gM0GLaYTQMaESOKMzl+/Is25XMCcP7mQ35vWYY8aRPRdsJqpqw/xA8Vc1vHffDUh+GL97CoR20iO0di9LK9jF+5n29LZ2el5zn2Dv8WwzB44u0XJubtJ67S659NYea7RHJkTb9vXnmsT7z9WHvwAq3K5rDOm7TuIONX7icgKIQlveoA4OUXwO/L97KwR23GrvB8q/dTRCSiUhJYRL4KmdKnpesvA+j+62AqlCpOwby5ANiycw/D//gTH19fHj1+Qoa0qa1J4ErP/8yUPi0Z0qa2VscmT5qYazdvEd3NjcQJ45M/t+VEuX7NKvwxaXqoJPDeA4c5dfY8RSrVBiAgMJC8ObITzS0qzk5OtPyxG+VLF6dCqbDVEUUL5mP/phVvdHyBgYH8OW0m+zYuI0XSJPzYoy+DR4+nR8cfaNX4G3p2/AHDMPh50Ah++nkAf40ezK9DR9OuVVOiRI4c7j69vL2p8+13DPu1N25Ro75RHCIiIiLyaWVIEoc+M7bwy6ytlPFISb50iQBLonXMck98AwJ55OVHukSxrUngcjlSApA+cWzSJYqNe4woACSLG50bD54SLbIzCWNFJU9ay75qFczAn2sP8kPFF+PuP3+LM9cfUP6XWQAEBIWQK3UC3FydcHZ0oN3ENZT2SEkZj5RhYi6UMclbP5wuKDiEFmNW0LKMB8niRbfOb17ag+alPViw8yTDF+9m3HflGbJgJ23K5SSKc6S3GkNEJCJTElhEvgppUiZn7/plrN64hZ8HjaBYofx0/r4l7br2Yfe6JSROmIB+Q0fj5+9v3cYpkuWk0c7Ozvr3f6eDg4IAQt1yFt60aZqUKFyAGRNHh4lp15pFbNq+i0XL1zB+8t+sWzQz1PK3qQQ+cvwUACmft4CoWbk8Q8dMACBe3NjW9b5tUJeqDZoDsO/gERatWEOPXwfz+MlT7OzscHZy4rtvGxEYGEidZt9Tr0YVqlUoEyYGEREREfk8pIofk80DG7H+0EUGzN1O4UxJaVspNz9N2cDGAQ1JGMuNwQt24h8YZN0mkoMlFWBnZ+DkaG+db2cYBAWbQDjnuf83rmmaFM2clL/aVQoT0/r+Ddh2/CrL9p5h0tpDLO1dJ9Tyd6kE7vDXWlK4x6D180rl/1c9X3o6T14PwIHzt1i29yy/zNrKEx9/7AwDJ0cHWpTxCHdbEZGvgZLAIvJVuHn7DjGjR+ebmlWJ7ubGlJlzrQnf2DFj4uXtzaLlq6leqdxb7ffq9Zvs8TxI3lwezFm0nAJ5Qp+U5smRjfbdf+b8pcukSp4Mb28fbty+QwL3uPj4+FKuZDHy585J2txFw+z7bSqBE8SPx6mz57l3/wFxYsdiw9YdpEttqfS4deeutYp56ap1ZEyXBoDNy+Zat+83dDRRIrvy3beNME2Tlh26kS51Sn5s/e1bvR8iIiIi8mndeuhFjCjO1C6UkWiRnfln81FrwjdmVBe8/AJYtvcslfOkeav9Xr//FM+zN8iVJiELd50i7/Oq4H/lTJ2An6Zu4OLtR6Rwj4G3XwC3HnnhHiMKvv6BlMqegjxpE+LR/s8w+37bSuDf5m7nqa8/o1uWDTX/wq1HpIwfA4B1hy6Qwt3y95W/1LeuM3jBTiI7OyoBLCJfPSWBReSrcPzUGbr1HYSdnR2Ojg78Mbgf0aO50axBHbIXKUe8uLHJmT3LW+83TaoUjJ86gxYdupE+TSpaNQ5duRAndiwmjR5Cw9Y/4u8fAEDfbh2JGiUyNRq1ws/fH9M0GdL33R8KB5DAPR69OrejeNV6ODo4kCRRQib/PgSA7v0Gc+T4SQzDIGniRIwb1v8/97Vr3wFmzl9CpvRpyVnccs/frz06Ua7kuz/QQ0REREQ+jlPX7vHzzC3Y2Rk42NszrFkpokV2pmHxLBTsMpW40SOTPaX7W+83VYKYTFp3iLYT15A2USyalsoWanlsN1f+aF2OFmNWEPA86dyjdiGiOEeiwfDF+AcEYQK/vsdD4QBuPHjGiCV7SJ0gJsV6TAcsLSAaFs/CpHUH2XrsCo4OdkSP7My4NuVfu78Wvy9n56lrPHjmS6bvx9OtZgEaFHv77wEiIl8awzRNW8cgIhGYYRhmwJ0Ltg7jo7h89TpVGzTn8LY1tg7lqxMpXkpM0/z/uxJFREREPhnDMMwHs7vYOoyP4uq9J9QbsoidQ5vaOpSvSqx6Q3WOKyIfjZ2tAxARERERERERERGRj0eVwCLyUUXkSmCxHVUCi4iIiK1F5EpgsQ1VAovIx6SewCIiIiIiIiJfiSRNRnF12o+fdEy/gCAq9ptNQGAwQcEhVM6Thm61CgLQbuIaDl+8jWmapIwfkz/alCOKcyTGrfTkn83HcLAziOXmyphWZUkcJxrX7j2h0YglhJgmgUEhtCjjYe1XfPjibX6YsBq/gCBKZkvBwMbFMYzQOVXTNOk+fRMbDl/EJZIDf7QpT9bk8T7p+yEiYgtqByEiEo4YyTPbZNwW7buSMEMushUuG+7ykeMnESleSu4/eAjA8LF/krN4RXIWr0i2wmVxjp+ah48eW9cPDg4mV4lKVP2muXXepSvXKFC2OunzFKN+i7YEBASEO9bg0eNJn6cYGfOXZN3mbR/uIEVERETkq+LkaM+SXnXYNrgJWwc1ZuORy3ieuwlA/4bF2Da4CduHNCVR7KhMWnsIgMzJ4rHxt4ZsH9KUynnS8MusrQDEixGFNf2+YeugJqzr34DRy/Zy66EXAJ2nrGdkizJ4jmzOxduP2HjkUphYNhy+xMXbj/Ac2ZwRLcrQefL6T/QuiIjYlpLAIiKfkUZ1a7BiztRwl127cZMNW3aQJFEC67xO37dk/6YV7N+0gv49u1A4X25ixohuXT7mr2mkS50y1H569B9Cu1ZNObV3MzGiR2PqrPlhxjp55hzzlqzg8LY1rJg9lXZdfyY4OPjDHKSIiIiIfBB9Z29l0rqD1unBC3byx4p9ePkFULX/XIp1n07Bn6ayav+5MNvuOHmVekMWWqd/mrqBWVuPA5aK2kp9Z1O8x9/UHDif24+83itOwzCI4hwJgMDgEIKCg/m3QNfN1QmwVOj6BgRZ5xfKmARXJ0cAcqZKwM2HzwCI5GCPk6PlpuaAwGBCnre4vP3Ii2e+AeRKnQDDMKhTKGO4x736wDnqFMqIYRjkSp2AJz5+7318IiJfAiWBRSTC6/HrEMZP+cc63W/oaEaM+wsvb2/K1GhA7pKVyV6kHMtWh60C2LpzT6gq2vbdf+HvOQsAOHjkGCWq1iNPqcpUqNOEW3fuvneshfLlJkb06OEu69znNwb06RrmlrZ/zV28nDrVKlmnr9+8xer1m2n2TW3rPNM02bJjNzUqlQOgYe3q4R738jUbqF21Ik5OTiRPmpiUyZPiefDIexyZiIiIiHxo1fKmY+nuM9bpJXvOUC1fOpwdHfi7Y1U2D2zM0l516DNjC2/6PKDAoGC6TdvI1A5V2DSgEd8Uzcxvc7eHWW/+jpMU6TYtzKvJyKXh7jc4JIQi3aaRrtVYimRORs5ULwobfpiwmvStx3H+5kNalPEIs+2MLccokTWFdfrGg6cU+mkqWX6YQLvKuYkfMwq3HnqRIGYU6zoJYkW1Vgi/7NZDLxLGivpivZjhryciEtGoJ7CIRHi1qlagc+/+tGnWEIAFy1axcs5UnJ2cmD9tPG5Ro3L/wUMKla9BpbIlX5lkfVlgYCA/9ujLwukTiRM7FvOWrKDPgOH8NXpwqPVmLVjKiHF/hdk+ZfKkzJ089o2PYdnq9SR0j0fWjOnDXe7j48u6zdsYPfAX67xOvfszsE9Xnnl5W+c9ePiI6G5RcXCwfPwnTODOjVu3w+zv5u075M6RzTqdML47N27feeN4RUREROTjy5I8Hvee+nDroRcPnvkQPbITCWO5ERgUTP+529l96hp2dga3Hnpx94k38aJHee0+z996yKnr96kxYB4AwSEm8aJHDrNerYIZqFUwwxvHam9nx9ZBTXji7UejEUs4de0e6RPHAeCP1uUIDgmh69SNLN59mm+KvmjNNm/7CQ5fvM3yPnWt8xLGcmP7kKbceuhFwxGLqZw77RvHISLytVISWEQivOyZM3L3/gNu3r7DvQcPiRHNjcQJExAYGEjvAcPZvnsfdnZ23Lh9hzv37uMeN85r93nm/EVOnD5HudqNAUvv3fjx4oZZr37NKtSvWeW94vfx8WXw6PGsmjf9leusWLeRfLlyWFtBrFy3ibixY+GRNTNbd+55r/FFRERE5PNVJW9alu07w93H3lTNlw6A+TtP8eCpD5sGNMLRwZ5sbSfiHxi6tZeDnZ21lQKAf2AQAKYJ6RLFYm2/Bv857vwdJ/ljxb4w85PHi8G0Dq8+/40W2ZmCGZKw8cglaxIYLEni6vnTMWb5PmsSeMuxy4xYsoflfepaW0C8LH7MKKRPFJs9Z66TO01Cbr5U0XvzwTPixwyb9I4fMwo3Hjx7sd7D8NcTEYlolAQWka9CjUrlWLR8Nbfv3qdWlQoAzF64lHv3H7B3/VIcHR1JnbMwfn7+obZzcHAgxAyxTv+73DQhQ9rUbF+14D/H/RCVwBcuX+Xy1WvkLG6J+/rN2+QpVZmdaxZbE9bzlqwI1Qpi174DrFi7kTUbt+Dn589TLy8af9eRaWOH8/jpM4KCgnBwcODGzdskjO8eZswE7vG4fuOWdfrGrdskdNdTk0VEREQ+N9XypuPHv9by8Jkvy55Xyz7z8Se2myuODvZsP3GVa/efhtkucRw3zlx/gH9gEH4BQWw7fpU8aRORKkFMHjz1xfPsDXKlSUhgUDAXbj0iXeLYobZ/m0rg+099cLS3I1pkZ3wDAtly7DLtKufBNE0u3XlMCvcYmKbJmgPnSZ0gJgBHL92h06R1zOtWizjRXlQi33jwjJhRnXGJ5MhjLz/2nrlBm/I5cY8RhagukfA8d5OcqeIzd/uJcFtLlPVIxaR1h6iePx37z9/CzdUJ9xhKAotIxKcksIh8FWpVqUCbTj24//ARG5fMBuDJ02fEjR0LR0dHtuzYzZVrN8JslyRRAk6dPY+/vz++fv5s3r6LAnlykDZVcu4/eMAez4PkzeVBYGAgZy9cImO6NKG2/xCVwJkzpOXGSU/rdOqchdm9dgmxY8W0Hsf23fuYPnaEdZ3fenXht15dAEtf45HjJjF9nGV5kQJ5Wbh8NXWqVeKfeYuoVLZkmDErlilBozYd+LF1M27evsv5i5fJ5ZH1vY5DRERERD68dIlj4+UXQPyYUazJzJoF0lN/2CIK/jSVbCncrYnVlyWM5UbVvGkp+NNUksSJRuZklrvaIjnYM/XHynSfvomnPv4EBYfQulyOMEngt3HnkRffj19NcEgIISZUzZuWMh4pCQkx+X78Kp75BmCakClpHIY2KwXAz7O24O0XSLPRlh7DiWK5MbNLdc7eeECfGZsxDAPTNPm+Yi4yJLEURgxtWoofJqzGLyCQEtlSUDJbcgCmrj8MQNNS2SiVPQXrD18k549/4eLkyJhW5d75uEREviTGmzaHFxF5F4ZhmAF3Ltg6DACyFylH7JgxWL94FgD3HzykWsOWeHl7kyNbZvYeOMzyWVNIliQRMZJn5tGlYwB06zeIZavWkSxJYiJHdqVSmRI0qluTw8dP0rFnP548fUZQcDDtWjTh24Z1/yuE12rQqj3bdu3l/sNHxIsTmz5d2tP0pQe7Qdgk8N9zFrB20zZm/vl7uPv8Nwm8ZOYkAC5evkqDVu159PgxWTNnZPrY4Tg5ObF8zQYOHDnGL107ADBw5Fimz16AvYM9w3/tRdkSRd/r2D6kSPFSYprm65s3i4iIiHwkhmGYD2Z3sXUYEoHEqjdU57gi8tEoCSwiH9XnlASWiENJYBEREbE1JYHlQ1MSWEQ+JjtbByAiIiIiIiIiIiIiH4+SwCIiIiIiIiIiIiIRmJLAIiIiIiIiIiIiIhGYksAiIiIiIiIiIiIiEZgeDCciH5WLi/NtPz//eLaOQyIWZ2enO76+fu62jkNERES+Xi6RHG/7BQbpPFc+GGdHhzu+AYE6xxWRj0JJYBH5bBiG4Qw0BroAd4BBwErTNENsGph8UIZhOAC1gG6AAQwG5pqmGWTTwEREREQ+EsMwMgM/AeWBv4DRpmnesm1U8qEZhpEC6ATUB+YAw0zTvGDbqERELNQOQkRszjCMaIZhdAUuAZWAJqZpFjBNc7kSwBGPaZpBpmnOBrIBXYEWwDnDMH4wDMPVpsGJiIiIfECGYRQ0DGMFsA44AaQ0TbObEsARk2maF03T/B5ICzwA9hqGMdswjGy2jUxERJXAImJDhmHEB9pjSQKuAoaYpnnMtlGJLRiGkQ9LQjgfMAYYa5rmI9tGJSIiIvL2DMOww1Lx2w2IDwwBppum6WfTwOSTMwzDDWgJdACOYbnTcaupRIyI2ICSwCLyyRmGkQpLy4dawExguGmal20alHwWDMPIgOVnowowFRhpmuZ120YlIiIi8nqGYTgCdbFc2A7A0vJqoVpeiWEYTkADLC1BHmNJBi/VXY8i8ikpCSwin4xhGB5YToqLA+OBMaZp3rNtVPI5MgwjMdARS4/oxcBQ0zRP2zYqERERkbAMw4gMfIulF+wFLAm+9ar2lP9nGIY9UBVLlXhULBcKZpqmGWDLuETk66CewCLyURkWxQ3DWAcsA/YCKUzT7KMEsLyKaZrXTNPsAKQGrgDbDMNYZBhGHhuHJiIiIgKAYRixDMPog+W5FkWAWqZpFjdNc50SwBIe0zSDTdNcCOQGvgPqARcNw+hoGEZU20YnIhGdKoFF5KPQVW75kJ5X2DQDOgMXsVTY6AuWiIiIfHK6Y0k+JMMwcmBpE1ECy92Sv6tYRkQ+BiWBReSDUr8r+Zj+r9deIJafL/XaExERkY/OMIz0WM5xqwBTsDy74IZto5KIwjCM1FgKHvTcFBH5KNQOQkQ+CMMwohqG8W+VZi2gFZDXNM3FSgDLh2KaZqBpmv8AWYDeQFvgjGEYrQ3DcLZtdCIiIhIRGYaR1zCMJcAWLD1/U5mm2VkJYPmQTNM8Z5pmKyAj4A0cMAxjhmEYmW0cmohEEKoEFpH3YhhGXKAd0BpYDwwxTfOQbaOSr4lhGAWxVAbnBEYD403TfGLbqERERORLZhiGAZTFco6RFBgGTDVN08emgclXwzCMaFi+Y/0IHAAGmaa5w6ZBicgXTUlgEXknhmEkx3K7Uj1gDpbblS7YNir5mj2vkvgJKA9MAkaZpnnLtlGJiIjIl8QwDAcsd7V1xXLn7CBgnlpPia08v9utMdAFuIPlZ3Kl7rYUkbelJLCIvBXDMLJiOSkuDUzE8uCCO7aNSuQFwzCSYXlYSwNgAZaHtZyzaVAiIiLyWTMMwwVoiqXI4RqWhxqv1kNo5XPx/MHbNbA8eNsJy8/obNM0A20amIh8MZQEFpHXen47XCEsJxzZgJHARNM0n9oyLpH/YhhGHCw9g9sAm4HBpmkesG1UIiIi8jkxDCMG8B2Wc4a9WM4Xdtk2KpFXe/7drBSWwpxUwHBgsmma3jYNTEQ+e0oCi8grGYZhB1TCkvyNBQwB/jFN09+mgYm8BcMwogAtsFQHn8ZyC90mVfaIiIh8vQzDSAB0AJoBy7E81+KkbaMSeTuGYeTGkgwuBIwF/jBN84FtoxKRz5WSwCIShmEYkYD6WPqr+mBJmi02TTPYpoGJvIeXfq67Al5YbqHTz7WIiMhXxDCMtFh6q1YH/gZGmKZ51bZRibwf/VyLyJtQElhErJ5XTDbHUjF5BlVMSgT0vMK9MpYK95iowl1ERCTCMwwjF5YLwYVRxaREUIZhJORFhfsyVOEuIi9RElhEMAwjNi96p25BvVPlK/C8n1phLMngLMAo1OtaREQkwnj+u74klt/1qbH0Tp2k3qkS0b3U67odsAcYZJrmbttGJSK2piSwyFfMMIykWKp+GwILgKGmaZ6zbVQin55hGNmwtD8pDfwJjDZN845NgxIREZF3YhiGPVADS/LXCUsLqNmmaQbaNDCRT8wwDFegKdAZuIrl/8Jq3ekp8nVSEljkK2QYRiYsCa8KwCRglGmat2wblYjtGYaRAstJcj1gNjDMNM2Lto1KRERE3oRhGM5AYyy/y+8BA4GVpmmG2DQwERszDMMBqI3lwoiJJRk8zzTNIJsGJiKflJ2tAxCRT8cwjAKGYSwD1gMngZSmaXZVAljEwjTNi6ZpfgekAx4B+wzDmP28UhiwVFQYhtHERiGKiIh89QzDyGYYRv6XpqMZhtEVuARUwtIPtYBpmsuVABYB0zSDTNOcBWQFugOtgHOGYXz/vFoYAMMwShuGkcpWcYrIx6UksEgEYxhGzP+bNgzDqGAYxnYsT4pdBaQwTXOQaZqPbRGjyOfONM07pmn2BFIAB4GVhmGsNgyjCBAMdDEMo4VNgxQREfkKGYaRAFgJuBqG4W4YxkDgIpAZKGOaZkXTNLfrdneRsEyLVaZpFgG+wdIK7ZJhGD2f9xGOC6wwDMPNpoGKyEehdhAiEcjzNg+bsTz4whuog6XtQzAwCFioW35E3p5hGE5Yemf/BDzEckHlF6CSaZp7bRiaiIjIV8MwjEhYznX3AS5Ybm+fCQw3TfOyDUMT+WIZhpEByzluZWAKlkRwVKCGKulFIhYlgUUiCMMwomM5IR4COGPphXYRS7+ndaqGEHl/zx80UxXLbXTxAFcgq2ma120Zl4iIyNfAMIy5QEEgEjABGGOa5l3bRiUSMRiGkQTogKWvdhAwwzTNjraNSkQ+JCWBRSIAwzDssLR5iA4kB3YAg03T3GfLuEQiGsMw5gPlsHz5dMTyYI2FpmnWsmlgIiIiEZxhGKmB04CB5fevP5Y733KbpnnJlrGJfOkMw8gFrMNSTOSE5f9YCBDVNE0/W8YmIh+OksAiEYBhGH8BzYHLwCHgLnDYNM0JtoxLJKJ5/tRxRyxfPANVYS8iIvLpGYbhgOWCrINpmk9tHY9IRPD8ztIAwN80zWAbhyMiH4GDrQMQkQ9iIuCJpRoiEpart1dtGpFIBOLi7Hzbz98/3v/PNwzDFuHIF8LZyemOr5+fu63jEPlUXJydbvv5B4T5rBT5mD7G72Jnp0h3fP389fktEZJLJPvbfoEh//lZrXNceVvOjnZ3fAOC9bn5mVMlsIiIyGsYhmH6Xz9h6zDkC+OUKCOmaepblHw1DMMwvQ+tsHUYIu8tcvaK+vyWCMswDPP26Oq2DkMiGPf2i/S5+QVQJfAXzMXF5bafn5+qLeStODs73/H19dUVOhERERERERGRr4SSwF8wPz+/eCHBgbYOQ74wdvaOunAgIiIiIiIiIvIVsbN1ACIiIiIiIiIiIiLy8SgJLCIiIiIiIiIiIhKBKQksH4SDoxPZPXKQOUs2KleuyuPHjz/JuEuWLOXkyZOfZKxLly6RN19+UqdJR9269QkICAizzuXLl3GNHJXsHjnI7pGD1m2++ySxiYiIiIiIiIiIvIqSwPJBuLi4cOjgAY4dPUzMmDEYO278Jxl36dKlnDx56q22efjw4TuN1a1bD35s355zZ08TPUZ0Jk+eEu56KVOm5NDBAxw6eIAJ48e901giEvHETJPzg+6vVM0mpMpdAtM0rfNqftvWOs7N23ep2/JHALbu2kfVxhHjolTzDj1Ik680uUpXJ1fp6hw5EfZ3wJETpyhcuT7ZilcmR8lqzF+22rqs8Q8/kalwBbKXqELLTr0IDLT01p+9aAU5SlbDo0RVilT5hqMnT3+yYxKJyG7ff0TjroPJVKk5Beq3p9oPP3Puyo1Xrr9t/1FqtOsLwMotexk2Zf5bjdeyz0gWr9/xXjG/rbLNu3HwxLmPPs6cVZvJW6et9RXFoxJHzlz86ON+KdbtPEC2qq3IXLnFK39u/lm2gaTF6lvfw2mL1n7iKEU+T+7tF/H9357W6aDgEDL0WEGDibveaj85+67hgZf/e6/zqQxdfZJxm86+1TYpuiz9SNG8cPDKQ0oM2UiJIRspPngjq468+L3515bzFBm4gcID1/PnlvNhth2/6Rzu7RdZ3+PHPgE0nbSbYoM2UHb4Zk7dfPLG+wIwTZOeC4+Q99e1FBu0gaPXHn3go5VPSUlg+eDy5s3LjRuWD6kLFy5QrlwFcubKTeEiRTl92vKl+s6dO1SvXpNs2T3Ilt2DXbssv1xmzJhJnrz5yO6Rg1at2xAcHAxAVLfo9OzVm2zZPciXvwB37txh165dLFu+gp+6diO7Rw4uXLjwypj8/PyYOXMWxUuUpH37H9/6mEzTZNPmzdSsWQOAxo0asnTpsrfej4jIhxTNzY1dngcBePzkKbfv3LMuS+Aelzl/jrJRZK/38NHjd952UM9OeK5bhOe6RWTNmD7MchcXFyaPGsjhTctYPmMinX8ZxOMnTwGoW60ix7au4OCGJfj6+TFl9kIAkiVJyIYF0zi4cQnd27fmu59+eef4RMTCNE3qdexPoZyZOb58EjtnjaZv28bcffBmXyArFM1D52a1PmqMQUHBH3X/H1Ld8sXYM3cMe+aOYVL/TiRLGI+saVO8077+Pcf+GN5334+eer3TmB0HjWfxH305sHAc89ds5dSFq+GuW6NMIev72KR6mfeKVSSicI1kz+nbT/ENsPz/3XrmLvGju9g4qi9fQFAI3v5Bb71duvhurO1UjI0/lWB26/x0mXeYoOAQTt18wozdl1ndqSibfirB+hO3uHTvxWfmjUc+bD1zh4QxXvzbjV5/howJo7O5W0nGNMhJ70VHAV67r39tPHmHi/e82N2rNMPqetB1/uG3fyPks+Fg6wAkYgkODmbTps00a9YUgFat2zB+3FhSp07N3r17+f6HtmzcsJ727TtQuEghFi1aQHBwMF5eXpw6dYp58+azY/s2HB0d+e77H5g5cxaNGjXE29ubvHny8Fv/X/mpazf+mjSZXj17ULlSRSpUqGBNzv6/I0eOMGnyFNasWUuZMqUZNnQIHh4eAJw5c4a69eqHu93mTRuJHj26dfrBgwdEjx4dBwfLf5lEiRJx4+bNcLe9dOkSHjly4ubmxq/9+lGoUMF3fTtFJAIyTZPu/Yezdst2DAy6t29FrcrlCAkJoX2v/mzZuY9ECdxxdHCgSZ1qVK/46i+otauUY97S1RTInYMlqzdQtVxJTp61XMW/fO0G1Zp8x6GNoasVvH186NB7ACdOnyMwKIheHb+ncpniXL52g2btu+Ht4wvAqP49yZcz+3/GdfDoCX7qOwQvHx9ixYzOpBEDiB8vzivj9fPzZ/Gq9UydvYAE7vGYNmbwB3hHw0qTIpn17wnc4xInVkzuPXhE9GhulCtR2LosZ7bM3Lh1B4B8ObNb5+fxyGKdLyLvbqvnURwdHGheq7x1XpbnScvmvYZTpUR+KhXLB0DTHkOpUaoQblFdrev+s2wDh06eY0S3NrTsMxK3yK4cPHmOOw8e0b99U6qVKohpmnQaPIFNew6TMF5sIjm++Hpz6OR5ug2fhJevL7GiuzGxbwfix4lJ2ebdyJw2BbsPnaRW2cIkjh+XARNnYW9nR7QokVk3JfzPpuDgYHqNnsb6XQews7OjabUytKlXKdQ6G3Yf5LfxM/EPDCJFIncm9P2RKK4uDJw4m1Xb9uHr70/erOkZ0+sHDMOgbPNu5Myclm2eR3nyzJtxP7ejgEem176389dspWaZwuEu27z3MD1GTiEoOJgcGVMzusf3OEVyJH35ZtQoU4hNew7ToXF1apUtYt2mZZ+RuDhF4siZi9x7+Jjxv7Rn1opN7Dt6mpyZ0vJnvw4AzFu9laFT5mGaJmUL5aJ/e8s5f9z8NWlWoyyb9x5mZPc2XLl5l/GzlxEQGESuzGkZ1b0N9vb2rzyeuw8fM2vFJmYs20DrOhVD/cy8if3Hz5IicXySJ3IHoGaZwqzYsof0KZO81X5EvmYl0sdjw8nbVMqWkMUHr1PVIxF7LzwA4JF3AB1mH+DKfW9cItkzrI4HGRJG46G3P22me3LriS85k8UMdYfaAs+rTNp2gcDgEDySxmBQrezY2xmvjeNV26XospQWRVKx/sRtnB3tmN48H3HcnLn31I+f5h3iygMfAAbXzkau5LGYsPkcs/dcAeCbfMloWTQVAKPWnWbevqvEjuJEghguZEkcHYDL973oPv8wD7wCLMdY14PU8aJy5YE33/3tibd/EGUzx3+j9/Ls7afM3H2ZVUdvMuXbvGROFP1N/xkAcI304neZX1AI/75r5+48wyNpDOvyfKlis/LoTX4okQaAPouP0rtyJhpP2hMqlrYl0wKQOl5Urj304d5Tv9fu619rj9+kdq4kGIZBjmQxeeobyJ0nvsSLposEXyIlgeWD8PX1JbtHDm7cuEn69OkoVaokXl5e7Nq1m9p16lrX8/e39NHdtHkz06dPBcDe3p5o0aLxz4wZHDh4kNx58j7fpx9x48YFIFKkSFSsWAGAHB4erN+w4bUxjRg5kp49ezNkyCCGDR2Ck5NTqOVp06bl0MED73/wL4kfPz5XLl8kVqxYHDhwgGrVa3L82BHc3Nw+6Dgi8uVasmo9R06eZv+6Rdx/+IgCFepQME9Odnse5Mq1mxzZvIy79x+QtVhlmtSp9p/7KlYgL21++png4GDmLVvNuMG/MGD0hP/cZtDvf1I0fx7+HN6fx0+eUqBiXUoUykvc2DFZNWsSzs5OnLt4hUY/dGH3qnksWbU+3LgCAwPp0HsAC6aMIU6smMxftpqfh4zmz+H9w4x59ORppsxayNrN2yldtCCD+/xE9swZADhz4RIN2nQKN9b186cRPVrYz88+Q37nt1ETKFYwD79174iTU6RXHq/noaMEBAaRMlniUPMDAwOZtXA5w/t2D7PN1DmLKFOs0H++jyLyeifPXyFbhlThLmtctTR/zFxKpWL5ePLMm71HTvNXv47sOnzilfu7ff8hG6YO4cyl69Tu8CvVShVk2abdnL18gwMLx3H3wWNy1PiORlVKERgYRKfBE5g7sjdxYkZjwdpt9B37NxN++RGAwMAgdswaBUCuWt+zbFw/EsSNzeNnr65CnbJwLVdv3mHPnDE4ONjz8MmzUMvvP3rCkL/msmLib0R2cWb41AWM+WcJ3VvVo1XdinRvVQ+Ab3sNZ/W2fZQvkgewVCNvmzGSNds9GTBxNisn/vba93bhuu3MHdkrzHw//wBa/TyKlRN/I3XShDTvNZy/5q/ih2+qABAzWlR2zR4d7j4fP/Vi8/RhrNyyl9o//sqGqUPJ0CcJhRp04MiZi8SNEY3ev09jx8xRxHCLQqXverN8824qFcuHt68fuTKnZVCn5py+eI0R0xawcepQHB0d+HHAOOas2sI3lUqEGi8kJIQNuw8xffFaTl+8Ru1yRVg6th8J48UGLO0vRk1fFCbOlInjM3NYj1Dzbt59QKKXLkImjBeb/cfPhHucSzbuYsfBE6ROkoDBnVuQyP3VFy9FviZVPRIzfO0pSmV059TNJ9TLk9SaBB66+iSZEkZnWvN87Dh7l7Yz97PxpxIMX3Oa3Cli0alsetafuMWs50nXs7efsvTQdZb/WARHezu6zjvEwv1XqZ076X/G8F/b+QQEkyNZTLpXzEi/pceYsfsyHcqko+eiI+RLFYepzVMRHGLi7R/EkWuPmLP3Cqs6FgWg3IjN5EsVmxDTZMnB62z4qTjBISalhm6yJoE7zznEkNrZSRE3CgcvP6Tb/MMs/KEQvRcdoXGB5NTOnZQp219997G3fxDLDl23Jp7r5klKl3LpieLsCECfRUfZef5emO2qZk9E21Jpw8w/ePkhP84+wPWHPvzRICcO9naki+/GoJUneejtj7OjPRtP3iHr8/jXHLtJ/GguZEwYPdR+MiaIxqojN8mbMjYHrzzk+iMfbj7x/c99vezWYz8SvFQVHj+aC7ee+CkJ/IVSElg+iH97Avv4+FC2XHnGjhtHk8aNiR49+hsnWk3TpFGjhgwcEPbE19HREcOwXP+yt7cnOOj1t1Q0+OYbAgOD+PPPSWzZvJUmTRpTrlxZazXv21QCx4oVi8ePHxMUFISDgwPXr18nYYIEYbZzcnKyJptz5MhBypQpOHv2LDlzftheoCLy5drpeZA6Vcpjb29PvDixKZQ3F/uPHGOn50FqVCyDnZ0d7nHjUCRf7tfuy97ejvy5szNv6Wr8/PxIljjha7fZsG0XK9ZvZuREy4U4f39/rt64RYJ4cfmx128cOXEae3s7zl28Yo03vLjOXrjMiTPnKF+vOQDBwSG4h1MFPOrPafQZPJqBPTszuHeXMAnbtCmT47ku7Jf8V/m1Wwfc48YmICCQ77r+zLBxk+jZIfx+x7fu3KNp++5MHjkAO7vQHbDa9fiVgnlyUDBPjlDzt+zcy7Q5i9i8+J83jklE3l6hnJnpMHA89x4+YenGnVQpkR8Hh1dXigJULJYXOzs70qdMwt0HjwHYcfA4tcoWxt7envhxY1EkdxYAzl65zskLV6jUxpIoDQ4JwT12TOu+apR+caEnX9b0tOwzihqlC1K5eP5Xjr9572G+rVXOGmfMaFFDLfc8dobTl65RokkXwJJozp0lHQDbPI8ycvpCfPz8efTkGelTJLEmgauUsIyZPUMqrt66+99v3PNxXJydyJgqWZhlZy9fJ1mCeKROavl98E2lEvw5b6U1CVyzdPjVwwDliuTGMAwypk5G3JjRyZTasv/0KZJw9eYdrt28S6EcmYgTMxoAdcsVZceB41Qqlg97ezuqPj+OLfsOc+jkBQo1sFQP+/kHWLd5WZ0O/Tl8+gJj+7SjVH4P67n+v+qWL0bd8sVe+368jfKFc1O7bBGcIjkyecFqWvQZyeo/B3zQMUS+VBkSRuPaQx8WH7hGifTxQi3bd/EBk5tZirUKponLI+8AnvkFsufCfaY8n18qY3yiu1oSntvP3uPotceUHb4ZAL/AYGJHDV2UFZ7/2i6SvR2lMlqq/bMkjsG2M5a7tnacvceYBpbv2/Z2Bm4ujuy78IByWRIQ2cny3b9ClgTsvXCfEBPKZUlgrX4tk8lS2evtH8T+yw9oMW2vNZaAoBAAPC8+tB57rVxJ6L/seLixZ+29igwJojG8nqWC+P/1q57ltcf/Mo9kMdnWvRRnbz+l3cwDFM/gThp3N34okYa643bi6mRPxoTRsLcz8AkIYvT6M8xtE/Yu5Lal0tJr4RFKDNlI+vhuZEoYDXvDeOW+JGJTElg+KFdXV0aPGkm16jX5rk0bkidPxvz5C6hVqyamaXL06FGyZs1KieLFGT9hAj+2b29tB1GieHH+x95dh0WxvQEc/w4NKimK3QkiCAgGCmK32N3d7bW7u7u7O7E7sDsxQJGWzvn9Mbhefoutd43zeR6ey+R5Z9172H3nnXNq16lL7149yZAhA8HBwYSHh5Mjx8fvFqZNl47w8PBUt2XIkIGBA/ozcEB/Tp06zfLly+nVuw9du3amT+/eX1UJLEkS7m5ubN26jUaNGrJq9Rpq1qqhtl9AQADm5uZoa2vz9OlTHj16TO7c3zZWmyAIwpdoULMqDdr1YGifrl+0vyzLbFw8kwJ5cqVYP2baPDJYWnDlyHaSkpIwzlPss+cpnD8vp3av/+R+TTxrkBCfwNJ1mzl57hItGtamsrvrhxtyX1kJ/H64CX19PVo0qMOMRStTPfZdeAS1W3Zm9IAeODsUTbFt7PT5BASHsHnSyBTrb919QKcBI9i9ZiEWZqafvC5BED6vUJ7s7PQ6+9HtjauXY+P+42w9dEpVofsp+rq6qt///chxamRZSV4eXz0t1e1pDA1Uv88e2o3Ltx5w8PRlSjfpxZn1M7Ew/fqnuGRZxt3ZjlUTB6RYHxMbR68JCzizbgZZrSwZt3AdsXFxatelraX1RWMUbzl0igb/GsrhaxgZfjwJ8z4OLS0JPb0Pr7VWcly6Oh//6migp6ca7kGWoWmNcozu0eqTsYzq0ZIV2w/Rb9JCyrnY07xWeRysPzyG/DWVwJkzWPDqX+Pi+/oHksnSQu3Yf/+7tqpTkaGzVnwyRkH421SyycToXbfZ3t2V4Mi4zx/wETLQoHh2htT4/PA2X3qcjrb0oTBMSyIh6dN/B75GkixjbKjL0QEeqW7/ktTo0jbOrL/gQ5tlF6hdLCsNiucgm/mHIY6+thL4vfxWxqTR1+H+63fYZTejSYmcNCmRE4Dxe26TydSQ54GRvAiKotzkowC8Do2m4pRjHOjrTgZjA2Y1VZLksizjNPoQOdKnAUj1XP8vk6kBfqHRquXXYdFkMjFQ20/4PYiJ4YQfzt7eHtsiRdiwYSNr16xm+fIV2NkXw6ZIUXbt3gPAzJnTOXH8JLZF7XB0Ks7du3cpXLgwY0aPolLlKhS1s6dipcq8fv36k201atiAqdOmU8zB8ZMTw5Up48rKlSu4dvUKtkW+7g7cexMnjmfGzJnky1+Q4KBg2rZpA8Du3XsYPmIkAKdOnaaoXTHsizlQv0FDFsyfh7m5+SfOKgjC36Z0cQe27DlAYmIiAUHBnLl4BSe7IpR0KsaO/UdISkrCPyCQU+cvfdn5nB3o3609DWt/2fiJFcqWYv7ydaoEyvXb9wAICw/HKoMlWlparNu2RzWxz8fiyp8nJwFBwVzwvg4owyvcfaA+q3CG9Bb069qOa0d30b1dc3bsO4x1mWrMXLwS+FAJnNpPakNBvE7+ki/LMrsPHcW6gPqj5nFxcdRv14Om9Wqqjam8fP1Wjpw8y5q5U1JUB7/w9aNB+56smDUhxZjCgiB8O7fiRYmNj2f5toOqdbcePuPsVaWKqllND+atU8Yt/9axW0sXs2Hb4dMkJibyOiCYU5eVCW/y58xCYOg7Lt5Q+rj4+ATuPnme6jmevnyNU5ECDOvSjPRmJrzyD0x1v3IudizfekCVqP3/4SCcihTkwo17PHmhzBsRGR3Do+e+xCQnfC1MjYmIimbHJxLjn5OUlMT2w6c/Oh5w/pxZef76rSqGDfuOU9rh65IwH+Ngk58z3rcJDAlThiE6eBJXhyJq+7kVL8pOr7O8DQ4FlNfphZ96hXPhPDmY0r8DV7bNp7SDDSPnrqF4g254nVcmPP33RHj//vn/BDCAg3V+nrzww8f3DXHx8Ww9dIpqbs5q+70OCFb9vu/kRQrkyqa2jyD8zRq75KBv5YIUypyyet85T3q2eSuTLZ59FIB5Gj3SGejikic9271fAnD07htCo+IBcM1vyd7rvgSExwDKmMIvg6M+2/63HOeaPwOrzjwDIDFJ5l10PM55LDh404+ouAQiYxPYf/M1znnS45K8PjoukYiYeA7fVvIN6Qx0yW6eht3XXgHK58w7vqEAOOU2Z+dVZf22Ky8/GodbwYwsbuXMrp5lMDbQpdXS89Sfd5oXQZGAUgl8dICH2k9qCeDnQZEkJCqVyC+Do3jsH65KKL9/bV4FR7H/ph+eDtkolNmEO+OqcWVEZa6MqEwmU0MO9y9HBmMDwqLiVFXN68774JInPemSh6hI7Vz/r6JNJjZffoEsy3j7BJPOQFcMBfEbE5XAwg8R/i40xfLu3TtVvx84sE9t/4wZM7Jzp/qd/YYNG9CwYYNPnr9evbqqieBKlSrFnds3vzhOY2NjypdP/e7e5+TOnZuLF86rra9ZswY1aypVwXXrelK3ruc3nV8QhL9DrSrlueB9A8eKnkhIjB/SF6sMltSpWoFjZy5Q1L0mWTNbYVekMMbG6o+S/T9JkujTqfUXtz+4Zyf6jpyIQ/k6JMlJ5MyWlZ2r5tOxRWMadejFuq27qOhWmjRGyoe7j8Wlp6fHxsUz6DN8AmHvwklITKR72+YUTiUp+56riyOuLo68C4/g8vVbXxzzv7XqPoCAoBBkZIoWLsjcicMB8L5xmyVrNrNw6mi27jnEmYveBIeEsmbzTgCWzhhHUetCdPtnNNmzZqZMLWU4oNpVyjOkdxfGz1hIcGgYPQaPAUBHR4fz+zd/U4yCICgkSWLjtCEMmLqE6Su3YqCnR/bMGZjcrz0AGS3MKJA7GzXcXL65jZrlSnDy8g0c6nYhq5WlavgFPV1d1k75h/6TFhEWEUliYhJdm9akcB71J8yGzFzO4xd+yLKMW/Gi2ObPpbYPQKs6lXj03BfnBt3Q0dGmtWclOjX68GSYpbkJi0b1otU/U4iNVxIhI7o0J1+OLLT2rIRT/a5ktDBLUe36tc5cvU1WK0vVBGj/z0Bfj4Uje9JswETVxHDt6n3dJGsfk8nSnNE9WlGlw2DVxHDV3dX/7Qrlyc7wrs2p2XkYSbKMro42MwZ1JnvmDKmeV09Xl3qVylCvUhle+L0lKPTdV8emo6PNtIGdqNVlOIlJSbSoVUH1bz1m/lqKFc5HNTdnFmzYzf6Tl9DW1sLcJB2LRvX66rYE4U+W2dSIdmXVP8v1q1yI3hu8cZ/ohaGeNrOTK0v7Vi5I51WXKTPhCE65LMhipnx+LGBlzMBq1jRacJakJBldbS0m1LdLURmbmm85bqynLf02XWP9BR+0tSQm1bfDMZcFDZ1zUGXaCUCZGO795Gy1imXFY/JR0qfVxy67meo881o4MWjzNWYefkB8YhK1i2XFOospYzyL0mX1ZeYeffhFE8OZp9GnvVte2rvl5erz4G8aYuHS0yDmeD1AV1sLLQkm1rfDIq3yJEe75RcJjoxTXpt6dpgYfXxuDFAmk+uxzhtJUl7f6Y0/PO33sXOtOvMUgJalc1O+sBVH7/rjMuYwhnrazGzikGo7wu9B+tyjVMKvS5IkOSkxXtNhCL8ZLW1dZFkWg/0IwleQJEmOffXxyYp+lIjISNKmSUNQSCilqjfixI41WGXQ/IQ1v2pcvzr9rNaivxX+KpIkyZHX9n7x/lHRMRRv0I2z62dhki7NT4xMEL5OGvvqov8W/liSJMlvZonCJeHHsuq5XfSbvwFRCSwIgiAIv4g6LbsS+u4dcfHxDO7Z8ZdJtP6qcQmC8Ps6duE6XUbNoluz2iIBLAiCIAiC8B8QSWBBEARB+EUc2bpSbV39tj3wefkqxbpxg/tQ0U199t+fJbW4BEEQvkc5FzvuH/g1J+U6cs6bYbNWpliXM0tGNk4f+le0LwiC8LMFR8ZSf94ZtfVbupbGPM3HJ7AUBOH7iOEgfmNiOAjhW4jhIATh6/1Xw0EIfxYxHITwt/na4SAE4VclhoMQ/mRiOAjhZxDDQfwetD6/i/AnSGds+t3nWLlyFd269/jkPj4+Pqxfv+G72/pVXb58GV09A7Zu3aZat2rVavIXKET+AoVYtWq1ar17OQ8KFrLGvpgD9sUcePtWmRU5NjaWRo2akC9/QVxKlMTHx0etnZiYGJxdSmBnXwybIkUZMXKUatuxY8dxcHSiiK0drVq1JiEhAYCQkBA8PetR1M4eZ5cS3L59+ye9CoIgfIp5fsfvPsfqzTvoOWTsJ/fxeenLxh1/XrJl2oLlOFX0xKmiJ/YetTDMXoTgkFAePHmmWu9U0ZP0BYsze+mHPnfe8nUUKVsdu3I1+WfsVNX6W3cfUKZmE+zK1aSYR21iYmLV2gwOCaVK43YULl2FKo3bERIalmL7leu3MMphy/a9hwB4/soP58r1cKroiV25mixes+knvRqCIHxOhpL1vvsca3Z70Wfigk/u89zPn00HTnx3W7+asPBI6vUchXODbjjW7cLqXUcAOHn5Ji4Nu6t+zJ3rsOe4MkFyh+EzKFytrWrbjQfKBEIb9x+neINuONXvSrmW/biZvP7/dR45C+cG3SjeoBtN+40nIioagNi4eFoMnESRmu0p27wPz/38ATh64RqlmvTEqX5XSjXpyYlLN372yyIIwr/k7r/ru8+x8eJz/tl6/ZP7vAiKZPuVl9/d1q/mkX841WacIHufncw/9jDFtl7rvbEeso+yE7xSrL/jG0q1GSdwm+hF88XnCI9Riv+2XXmBx+Sjqp9MvbZz+1UoADu8X+I20Qv3iV40XnCGoAj1z7zvouNpvvgc5SYdpcyEI2y44KPaNmb3bcpO8KLsBC92Xv3wFOKyU09wGXMIq57bUz2n8HsRw0EIP5SPz3M2bNhIkyaNf8r5ZVlGlmW0tLRSXf6YhIQEdHS+7+2emJjIoH8GU7FCBdW64OBgRo8Zy+VLF5AkCUcnZ2rWrIGZmTLL6No1q3B0TJkQWrZ8OaZmpjx6eJ+NGzcxaNBgNm5cn2IffX19jnodIW3atMTHx+NapixVKleiePHitGrdBq8jh8ifPz/DR4xk1arVtG3bhvETJlLUrijbt2/l/v37dOveA68jh7/rmgVB+HU9f+nLxp37aVSn+k85v6b6276d29C3cxsA9h45zpwlqzE3M8XczJTLh7cDSn+cy9GdWpXLA3Di7EX2HD7GlcPb0dfX421gkCqWVj0GsWL2BGwLFyQoJBRdXfXYpsxbSrlSzvTv1p4pc5cwZd5Sxg/pq2pryPjplC9TUrV/pgzpObVrPfr6ekRERlLMozbVK7iT2SrDN1+3IAi/tud+/mw+cJKGVdx+yvm/vc9NREdH+5vbXbx5HwVzZ2frrBEEBIdhX6cjjaq6UdbJlgub5gAQHBaObc32eLjYq44b16s1dSqkHJYoZ2YrDi2diJlxWg6duUL3sXM5uWa6WpuT+rXHOK0RAAOnLmHhxr30a1OfVTsPY5ouDbd2L2HLwZMMm7WS1ZMGYmFqzNaZw8mUwYI7j32o1WU4jw+vVjuvIAi/t5fBUWz3fomnY7afcn6lXwUtLSnV5Y9JSExCR/vb6ydNjXQZ62nLwVuv1bY1LJ6DNq656b7WO8X6PhuuMqJ2EUrmtWT9BR/mH33IwGrW1HXMTl3H7ADc8wuj1dIL2GQ1JSExiaHbb3Lqn/JYpNVn9K5bLD/9hP5VCqc474rTT8hvZcyaDiUJjIil9LjD1HXMzskH/tx6GcrRAeWITUjCc84pPApnJJ2BLsVzW1DB2grPuae/+TUQfh2iEvgPU6dOXRydimNTpCiLFy9Jsa13n77YFClK+QoVCQgIAGD2nDlY29hS1M6exo2bAkpis06duhS1s6dEyVLcvHlTrZ3WrdukqIZ9X2n8z+DBnD5zBvtiDsyYOZPExET6DxhIcWcXitrZs2jR4k/GP2XqNNW+76tffXx8KFjImpYtW1HE1o7Tp8+kWH758iX9BwykiK0dtkXt2LRpMwAnTpykTFk3atWqg7WN7be9oP8yZ+5cPD3rkOFfEyIdOnSY8uU9MDc3x8zMjPLlPTh48NAnz7N71x5atmgOQL16dTl67Bj/PyyLJEmkTZsWgPj4eOLj45EkiaCgIPT09MifPz8AFcqXZ/v2HQDcu3uPcu7uABQsWBAfn+f4+/t/93ULgpC6em2741KlPnblarJ07eYU2/qNnIhduZpUatiGgKBgAOYuW0tR9xo4lK9Dsy79AKUCtV7b7jiUr4NrjcbcuvtArZ12vQerKlDhQ6Xx0AkzOHvJG6eKnsxaskq5UTVmKiWrNcChfB2W/F9M/2/aguWqfUdPnQso1cU2ZarRpuc/2HvU4sxF7xTLL/3eMGjMVOw9alHMozZbdh8A4OS5S5TzbI5n664Uda/5ja+ous0799OgVlW19cfOXCB3jmzkyJoZgMVrNtG/azv09fUAyJDeAoAjJ89RpFB+bAsXBMDCzBRtbfVkyZ7Dx2lWvzYAzerXZvehY6pt81aso3bVCmRIb65ap6enp2orNi6epKSkH3C1giB8SsPeYynVpCeOdbuwfNvBFNsGTF2CY90uVO04mIBgpZJ//vrdOHh2pniDbrQcOAlQkpkNe4+leINuuLXoy62Hz9Ta6TB8BjuOfBin8n2l8fDZqzh37Q4uDbszZ+1OEhMTGTxjOa5Ne1O8QTeWbT3wyfhnrNqm2nfsgnWAkli2q92RdkOn4VSvK2ev3kmx/OpNIINnLMexXhec6ndl66FTAJy6cpMKbQZQv+doHOp2/sZX9IOIyGhkWSYyOhozk3To/F8/udPrLBVKOWBkaPDJ87jYFcLMWPn8Wty2IL7+ganu9z4BLMsyMbFxSJKSgNl74gJNa3gAUKd8aU5cuoEsy9gVzEOmDEq/XjhPDmJi44iNE0PiCcKP1mrpeSpOOUaZCUdYcy5l/zh8+03KTDhCvbmnCUyuBl168jGu44/gPtGLjisvARASGUerpedxn+hF1enHuesbptZOj3VX2HPdV7X8vtJ43J7bXHwaiMfkoyw6/ojEJJlRu25Raeox3Cd6sfps6k8XvDfv6EPVvpP33wWU6uJS4w7Tbe0Vyk704sLTwBTLvqHRjNp1i7ITvHCb+KEC9uyjAGrNOkmLJeco839Vul/LMp0B9jnM0dFWTzaXyJseUyM9tfVPAyIokSc9AGULZGDvDT+1fXZ4v6R2sawAyCh9alRcIrIsExGTgJWJodoxkiQREROv9PmxCZga6aGjJfHwTTgueS3Q0dYijb4OhTObcOyekksoktWU7BZiAtc/hagE/sMsW7YEc3NzoqOjKe5cgrp1PbGwsCAyMhJHBwdmTJ/G6DFjGTV6DHPnzGbSpCk8ffIIfX19QkNDARgxchR29nbs2LGNY8eO07JVa65d9f50w8kmjB/PtGnT2bNH6cgXL16CiYkJly5eIDY2ltKuZahYsQK5cuVSO/bw4SM8evSIixfOI8sytWrV4dSp02TPno1Hjx6xcsUyXFxc8PHxSbG8bdt2bly/wfVr3gQGBlLcuQRlyrgCcPXqNW7dvJ5qe40aNeHBQ/WES+9evWiRnKR9z9fXl507d3HsqBdtL7f7sN7Pj2zZPtypzJo1K75+HzroNm3boa2tjaenJ0OHDEaSpBTH6OjoYGJiQlBQEOnTp0/RZmJiIo5OxXn8+AldunTG2dkZWZZJSEjgypUrODo6snXbNl6+Uh6ZsS1qy/YdO3B1Lc2lS5d4/vw5r169ImPGjJ/+RxME4ZssnjoGczNToqNjKFm9IXWqVcTCzJTIqGgcbG2YOnIQ42bMZ+z0+cwaN5Sp85fy4Nxh9PX1CA17B8DoafOwsy7E1mVzOH72Am16/aOqdv2csf/0ZsailexcNR+ApWs3Y2KclnP7NhMbG4dbnWaUL1OSXNmzqh175ORZHj97ztm9m5BlGc/W3Th94QrZsmTi8bPnLJsxHmeHovi89E2xvGPfYW7cvc+Vw9sJDA6hVLWGlHZWktLXbt3j6tGdqbbXtHNfHj5RT7b07NCSZvVqpXp9UdHRHD5xhpljh6ht27L7QIrk8KOnPpy96M2ISbMw0Ndn4rB+ONoV4dEzHyRJolrT9gQGhVC/ZhX6dWmrdr63gUFkyqjc4LPKkF5VSez72p/dB45yeMsKOvRNOSHTS7/X1G7RhSc+L5gwtK+oAhaEn2zByJ6Ym6QjOiYW12a9qeVREgtTYyKjYyhWOC+T+7VnwqINTFi8numDOjNtxVbu7luGvp4uoeERAIxbsI6iBXOzacZQTly6Qfth01XVrp8zukdLZq3ewbbZIwBYvu0gJmmNOL1uBrFx8Xi06o9HCXtyZrFSO9br/FWevPDj1NrpyLJM/V5jOON9m2yZLHn8wo/Fo3tT3LYgz/38Uyzv9DrLzQdPubhpDoGh7yjTrA+litkAcP3eEy5vnZdqey0GTuKhzyu19d2b1VYlWd/r1Kg6DXqNIU/FFkRERrN60kC16uMth07Ro1ntFOtGzVvDhCUbcStelDE9WqGvp5ti+6qdh6lY6uPDI3UcMZNDZ65QKHc2JvRR+mW/t0FktVL6Yh0dbYzTGhEU+o70Ziaq43Z6naVowTxq7QmC8P1mNHbALI0e0XGJVJ52nGpFM2OeRp+ouESKZjdltKct0w7eY9rBe0yoZ8ccr4dcGlEJfR1twqLiAJhy4C42WUxZ2a4EZx6+pfu6Kxwd4PGZlhVDatiw4Ngj1nZUnr5ac+4Zxga6HOpXjtiERGrMPEnZghnJkUpC8sR9f54FRHCwrzuyDC2WnOf840CymBnyNCCC2U0dcchpzougyBTLe6/7cudVGMcGehAcEUvlaccpkUe56XTzVSgnBpVPtb0OKy/y5G2E2vqObnlpUDzHF7/mH1PAypiDt15TxTYze6774hcarbbPrmu+rGznAoCuthaTGtjjPtELI31tclumZUJ9O7Vj2rjmpsWS8xQdvp+ImAQWtSqOlpaEdRYTph28Ryf3fETHJXL2cQD5rYy/+zqEX49IAv9hZs+Zy86dOwF4+fIljx49wsLCAi0tLRo2bABAs6ZNqFuvPgC2RYrQrFkLatWqSe3ayhfxs2fPsnWLUkFWrpw7QUHBvHv37pviOXLEi5u3brFtm1I1HBb2jkePHqeeBD5yhCNHvCjmoHxgjIiI5NGjR2TPno0cOXLg4uKi2vffy2fOnqVRo4Zoa2uTMWNGypZx5fLlKxgbG1O8uFOqbQFqQzB8Su/efZk4YfxnH8n7t7VrVpMlSxbCw8OpV68Ba9asVUsuf4q2tjbXrnoTGhqKZ9163L59GxsbGzasX0ufvv2IjY2lQoUKqqq2QQMH0KtXb+yLOVDExgZ7e7tUK94EQfgx5i1fx66DSmXAK783PH76HAsHU7S0tKhfszIAjT1r0LB9TwBsCuanZfcB1KzkQc3K5QA4d/kqGxfPBMC9lAvBIWG8C1f/QPklvE6d49a9h2zfpwwDExYeweNnz1NNynqdOsfRU+coXqkuABGRUTx+9pxsWTKRPWtmnB2Kqvb99/LZy1dpWKuq0t9apsfVxYkrN25hnDYtTnY2qbYFsG7BtK++nn1HTlDCyR5zM9MU6+Pi4th7+DhjBvVSrUtITCQ4NIzTezZw5fotmnTuy4Nzh0hISOTs5auc27cJI0MDKjdsSzFba8qVduFjJElSVaX1GzmRcYP7pNr3Z8ucCW+vHfi9eUv9tt3xrFaRjJbp1fYTBOHHWLBhN7uPKWPS+voH8uSFHxamxmhpaVGvYhkAGlVzp3HfcQDY5M9Jm8FTqO5eghruyv/z567fZf3UwQC4FS9KcFg47yKivimeo+evcvuRDzu8zgLwLiKKxy/8Uk3KHj1/jaPnr1GikTK3RmR0DE9e+JEtkyXZM2WguG1B1b7/Xj53/S71K5dR+lwLM0o72HD1ziPSpTXE0SZ/qm0BrJ408Iuvw+vcVYoUyM3+xeN5+vI1NToPo6S9tapa93VAMHcf+VC+RDHVMaO6t8QqvRlx8Ql0GzOH6Su28k/HD0PBnbx8k9U7D3Nk+eSPtrtoVC8SExPpO2kRWw+fpkWtCh/d9727T54zbPZKds8f88XXJwjCl1t66jEHbipDFviFRvEsIBLzNPpoSVDLXvmMV88xO22WXwCgcGZjuqy+TJUimaliqzyddelpEMvaKH1u6fwZCImMU41n+7VO3Pfnnt879t5QqobfRcfzLCDiI0ngt5x48JbyU5SnuSJjE3gWEEEWM0OymhnhkPPDE13/Xr70NIjaDlnR1pKwNDagRN70XH8RQloDXeyzm6XaFsDiVs7fdE1fakYTB4Zuu8GMQ/epaJMJvf8bjuKqTzCGetoUyqzcJItPTGLVmad4DShHDos0DN52g9lHHtC7UsEUxx2//xabLKZs6+aKT2AkDeafwSVPetwKZuT6ixBqzDyJRRp9HHNaoP2ZYTKE35NIAv9BTpw4ydGjRzl39gxGRka4l/NIdQIc4MNjV3t3c+rUafbs3cv4CRO5eePaF7WlraOjevw1KSmJuLi4VPeTZZnZs2ZSqVLFz55TlmUGDRxAx44dUqz38fEhTZqUne//L39MGqOP7/c1lcBXvL1p3KQZAIGBgew/cBAdHR2yZM7MiZMnVfu9evUKt7JlAciSJQsA6dKlo3HjRly6fJkWLZqTJXNmXr58SdasWUlISCAsLAwLC4uPxmlqaoqbmxsHDx3GxsaGEiVKcOrkCSC5evrhIwCMjY1ZvnwZoLyWufPkI3fu3J97iQRB+AYnz13i2JnznNq9HiNDQyrUa0VM7Kf7212rF3D6whX2eZ1g4pzFXPXa8UVt6WjrkJQ8ZExSUhJx8al/kJZlmRljBlPRrXSq2/9/3/7d2tO+WYMU631e+pLGKOWjY/+//DFGRkYf3fYtlcCbdx2gYSpDQRw8fga7IoVTJFyzWGWkdpXySJKEk70tWlpaBAaHkDVTRlydHUhvrozTXrmcK9du3VVLAmdIb8Fr/wAyZbTktX8AlhbKFwPvm3do3lUZuiMwOISDx06jraNDrcofKloyW2XAumA+zl70xrN6pY++BoIgfLtTV25y/OINjq+aqtzQaTeImI989nzf526fPYIzV++w/+RFpizbxKXN876oLR1t7f/rcxNS3U+WYerAjlQo6fDZc8qyTL829Wlbr0qK9c/9/DEy1E+x7v+XP+ZTQzN8TSXwmt1e9G1dD0mSyJM9MzmyZOShz0scbQoAsP3IaWqUK5FiPPVMlkofqa+nS/Na5Zm1+sPfs1sPn9F19Gx2zB2Fhemnq8i0tbWpV6kMM1Zto0WtCmTOYMGrNwFkyZiehIRE3kVEqc7h6x9I4z7jWDKmD7mzZfrMqyMIwtc6+yiA0w8C2Nu7LEZ6OtSZc4qY+MRU932fGlzbsRTnnwRy5PZrZh15wPGBX1bxq6Ml/auflYlP/MiwWjKMq1sU90Kff7JVlmV6lM9Pi1Ipv/++CIrESC9l2uv/lz/mU/v97ErgfBnTsamL8pn+ydtwvO6+SbF959VX1Cn2ofji/eRwOdMrQ/LUtMvKHC/1XMfGiz50L18ASZLIZZmW7BZpeOQfTrEc5vSqWJBeFZWkcedVl8htmfa7r0P49Ygxgf8gYWFhmJmaYWRkxP3797lw4aJqW1JSkmoM3/UbNlKqVCmSkpJ4+fIl7u5uTJo4gbCwMCIiIihdujTr1m8AlMRy+vQWGBun/BCXM2dOvK9eBWD37j3EJycl0qVLS3hEuGq/ihUrsHDhItX2hw8fEhkZmWr8lSpWZMXKlUREKJ2pr68vb9++/ex1u5YuzebNW0hMTCQgIIBTp89QvLjTZ4/buHE91656q/2kVq379Mkjnj19zLOnj6lX15N5c+dQu3YtKlWqyJEjXoSEhBASEsKRI15UqlSRhIQEAgOVcdDi4+PZt28/NtbWANSoWZ1Vq9cAsHXrNsq5u6u+sLwXEBCgGp4jOjoaLy8vChZQPoy/f01iY2OZPGWKKmkeGhqqSsYvXbqMMq6l1f7dBEH4McLCIzA1McbI0JD7j59y8dqHmcqTkpJU1bibdu6jpFMxpb/1e4NbKWfGD+7Du/BwIiKjKFXcgY079gJKYtnC3BTjdCk/cOXIlpmrN+8Ayti18ckJiXRp0xAR8aE/rVC2FIvXbPrQ3z71ITIq9Qq3CmVLsWrjdiKS+2Pf1/6qIRA+pXRxB7bsOaD0t0HBnLl4BSe7Ip89bt2CaVw+vF3t52MJ4LB34Zy+cJkalcqpbdu8a79acrhmZQ9OnlPGonv41If4uHjSm5tRoWwpbt9/RFR0NAkJCZy6cIVC+fOonbN6BXfWbtkJwNotO6lRURlf/eH5wzy8cISHF47gWa0is8cNpVZlD175vSE6OgaAkNAwzl66Sv48qT91IgjC93sXHoWpcRqMDA148Owll259+GKblJTEDi9lDN/NB05Q0q4wSUlJvPIPpKyTLWN7tiYsPIqI6GhK2Vuzaf9xQEksW5gaqype38uROQPX7j0GYN/Ji8QnJPe5RkZERH54HLd8yWIs3XJA1Sc/eu5LZHK/8P/KlyzG6l1HiIhSjvd7G8jb4NDPXncpe2u2HT6t9LnBYZz1vo2DTf7PHrd60kAubJqj9vP/CWCAbFaWnLik/A3zDwrhkc+rFBXGWw6eon7lsimOeR2gjHUvyzJ7jl+gcB4l4fHy9Vua9BvP0jF9yZcjS6qxybLMkxd+qt/3nbxI/pxKIqNaWWfW7TkKwA6vM5R1skWSJELDI/DsPpLRPVpRwq5wqucVBOH7hMfEY2Kki5GeDo/8w7nqE6zaliSjqsbd7v2S4rktSEqS8Q2JonQ+S4bWtOFddDyRsQk450nPNu8XgJJYNk+jRzqDlMO3ZDNPw82XoQAcuv2a+EQlIZzWQIeI2A833twKZWTV2aeqJPGTt+FExqZ+Y869UEY2XHyu2v46NJqA8NT75H9zzmPB7muvSEySCYyI5fyTQOxzmH/2uMWtnDk6wEPt50ckgAFV7ElJMjMOP6BFqQ+fM5OSZHZff0XtYh+GpcxkashD/3eq8ZpPPfAnX8Z0aufNYmbE6YdKPiHgXQxP3oaTwyINiUkywZHKsXd9w7jr9w63gmKosz+RqAT+g1SuXIlFixZT2LoIBfLnx8XlwyMKadKk4dLly4wbP4EMGSzZuGE9iYmJNG/RkrCwMGQZunfvhqmpKSNHDKdt2/YUtbPHyMiIlSuWq7XVvl1batfxxM6+GJUqVVJV5tra2qKtrY2dfTFatmxBzx498Hn+HAdHJ2QZLC3Ts2P7NrXzgZIwvnf/HiVLKXe80qZNy5rVqz47pEGdOrU5f+ECdvYOSBJMmjgBKysr7t9Xv/P1o5mbmzN0yGCKO5cAYNjQIZibmxMZGUnlKlWJj48nMTEJD49ytG+vjCXctk0bWrRoRb78BTE3N2PDemVyED8/P9q378i+fXt4/fo1rVq3ITExkaQkmfr161G9ejVAmTxv3779JCUl0alTB8qVU5IV9+7do1XrtkiShHXhwixd+ulJ+ARB+HaV3EqzZM0mbN1qkD9PTpztPwyfkMbIkMvXbzFh9iIyWJizdsE0EhMTad1jIGHvIpCR6dq6KaYmxgzr04UO/YbhUL4ORoYGLJsxXq2tNk3qUa9Ndxwr1KGiW2lVZW6RQvnR1tbCsUIdmjeoTfe2zXn+yg/nyvWRkbE0N2PLstTHuqxQthT3Hz2lTE1lQtC0aYxYMXviZ/vbWlXKc8H7Bo4VPZGQGD+kL1YZLHnwWL3K93vsOuhF+bKlSPN/1cWRUVEcPXWOeRNHpFjfqmEdOvQdhr1HLfR0dVk6cxySJGFmakLP9i0pWa0hkiRR2d2Vqh5KMqNTv+G0b94Ah6I29O/Wjiad+rBi43ayZ83M+s8MX3H/8VMGjp6CJCnVgL07tsKm0OcTM4IgfJsKpRxYuvUAxTw7kS9HVooXKaDalsbQgCu3HzJp6SYszU1ZPXEgiYlJtB0yjbCISGRZpnPjGpimS8vgTk3oPHIWxRt0w8hAn8Wje6u11cqzEg17j8W5QTcqlHIgTXLFrU2+nGhpa+HcoBvNapana5OaPPfzp2STnsiyjKWZCRunD1U7H0D5EsV48Owl7i2VJwvSGhqwbFw/tD8z23zNciW4ePM+zg27I0kSY3u1xiq9GQ99Xn7rS6lmUPtGdBgxE6f6XZFlmTE9W6vG4H3u58+rNwG4OtikOKbNkKkEhoQhyzK2BXIze0hXACYs3khw6Dt6TVDGqtfR1ubM+pkA1Ok2gvnDe5AxvRkdhs/gXWQUsixTJH8uZg1Wjm9ZuyLthk6jSM32mBmnZdVEZViLRRv38vTlayYs3sCExUqhyu4FY8hgbvrDXgdB+Nu5F8rIqrPPcB1/hDwZ0lLsX8MnGOlpc+15CDMOPSB9On0WtSpOoizTbc0V3sXEI8vQrkweTIz06Fe5EL03eOM+0QtDPW1mN1UfG7xZiZy0XHqecpOO4l4oI0Z6yufPwplN0NaSKDfpKA2LZ6d92by8DIqkwpRjyDJYpNVjZbsSqcbvVjAjj96EU23GCQDS6Oswr7kjWtKnhzSoapuZKz7BlJt0FEmCYTWLkMHYgEf+4Z887mu8fRdDpanHCI9JQEtLYsmJx5waXIF0Brp0WnWJc48DCI6Iw374fvpXKUyTEjnZ6f2KFWeeqmJs7PwhuXz+SSCZTQ3Jkf7DU89WJob0rVSIOrNPoaMlkdXciFlNlSdVViWfp2Xp3PSpVJCe67xxm+iFLMPQGjZYpNUnJj6RWrOUyUfTGSivnU7y36ilJx8z7+hD3obHUm7SUTwKZ2R6488/BSP8miQ5uQxf+P1IkiQnJYqZcYWvo6WtiyzLYoAfQfgKkiTJsa/uaDoM4Tejn9Va9LfCX0WSJDny2l5NhyEI3y2NfXXRfwt/LEmS5DezPDUdhvCHseq5XfSbvwExHIQgCIIgCIIgCIIgCIIgCMIfTAwHIfznbt26RYuWrVKs09fX58L5c5oJSBAE4Q91+95DWvcclGKdvp4eZ/Zu1FBEgiAIf67bj3xoNzTlcDL6erqcXDNdQxEJgiD8We75hdFt7ZUU6/R0tDjQx11DEQnC70UMB/Eb+1uGg3Av58GUyZNwdFQfT+hnGTJ0GGvWrCUkJITwd6Gq9StXrmLAwEFkyZIZgK5dutCuXVvV9nfv3mFtY0utWjWZO2c24eHhlCnrptr+6pUvTZs2YeYMzX0ZEMNBCMLXE8NBCN9CDAch/G3EcBDCn0IMByH8ycRwEMLPIIaD+D2I4SAEIRU1qlfj4oXUK5MbNKjPtaveXLvqnSIBDDBs+AjKuLqqltOlS6fa99pVb3LkyI5nnTo/NXZBEITvUaFeK7xv3P5P24yLi6PzgBFYu1alSNnq7Nh3GIDnr/yo1LANDuXrUKFeK175vVEdM3jcNOw9amHvUYstuw+o1rfrPZj8JSriVNETp4qe3Lhz7z+9FkEQhG9Rud0grt559J+2ufXQKYo36IZj3S4MnbVCtf6M921KNu6JsWNNdhw5k+KYl6/fUqPzMIp5dsLBszPP/fz/05gFQRC+VZ05p7j+IuQ/bXPC3jsUG3GA3P13pbp973VfrHpuV8V18r4/Faccw22iFxWnHOPMw7eqfevMOUWpcYfxmHwUj8lHCQiP+U+uQfiziCSw8NUiIyOpXr0mdvbFKGJrx6ZNmwEYPWYsxZ1dKGJrR4eOnXhfZe5ezoPeffriVNyZwtZFuHz5MnXr1id/gUIMHTYcAB8fHwoVtqFZs+YUti5C/foNiYqKUmv78OEjlCxVGgdHJxo0aERERAQAg/4ZjLWNLUXt7OnXf8B3X6OLiwuZMmX6qmO8vb156/+WChXKp7r94cOHvH0bgKtr6e+OTxAE4U8ycfZiMqQ3587p/dw4vhvXEk4ADBozhWb1auLttYPBvTsxbOJMAPYfPcm12/e4fGgbZ/ZsYMaiFbwLj/hwviF9uXx4O5cPb6eodSFNXJIgCMIvLSj0HUNmrmDfwnFc2TYf/8AQjl+8DkC2TJYsGtWLBpXLqh3Xfth0erX05Or2hZxcOx1LM5P/OHJBEITfR0WbTBzo45bqtoiYeJaeekyxHGaqdeZp9VndoQQnBpVnVlMHtaEv5jV34ugAD44O8MAyncHPDF34Q4kxgYWvdvDgITJlzsTevbsBCAsLA6Bb1y4MHzYUgBYtWrJ37z5q1KgOgJ6eHpcvXWTW7NnUrlOXK5cvYm5uTt58BejdqycADx48YOmSRZQqVYo2bdsxf8FC+vXto2o3MDCQcePHc+TwIdKkScOkyVOYPmMmXbt0ZufOXdy7extJkggNDVWL+fjxE/Tp21dtvZGREWfPnP6q69++fQenT58mf778TJ8+lWzZspGUlES//gNYs3oVXl5HUz1u46bNNGhQH0kST0gIgvDlIqOiaNKpL76v35CYlMTgnp2oX7MK42bMZ5/XCaJjYnFxsGP+pJFIkkSFeq0oalOQs5euEhkVzfKZ45k8dym37z+kfs3KjBrQE5+XvtRo1pFiRQpz7fY9CufPw/JZEzAyNEzR9pGTZxkzbR6xcXHkzpGNJdPHkjZNGoaMn87eI8fR0dahfNmSTBrW/7uucdWmHdw8uQcALS0t0psrH4bvPXrC5BHKjT23ks7Ub9tDWf/wCa7ODujo6KCjo0ORggU4fOIM9WpU/q44BEEQ3ouMjqH5gIn4+geSmJTEoPaNqFepDBMWbWD/qUtEx8biUrQQc4Z2Q5IkKrcbhG3BPJy7eoeomBiWjOnD1OVbuPPIh7qVyjCia3Oe+/lTu+sI7Arl4cb9JxTKnZ0lY/pgZJjyi7zX+auMW7CO2PgEcme1YuGoXqQ1MmTYrJXsP3kRbR1tPFzsmdCn7Uei/zwf3zfkyZ4JS3MlievubMeuo+dwd7YjR+aMgNIf/9u9Jy9ISEzCw8UegLRGKf9mCIIgfI3I2AQ6rLzI69AYEpNkelcqSO1iWZl28B6Hb78mJj4Jp1zmTGlojyRJ1JlziiJZTLnwNJDouERmN3VgjtdD7vmFUatYVgZVs+ZFUCRNFp7FNpsZt16Fkt8qHXOaOWKklzL1deK+P1MO3CMuIZEc6dMyq4kDafR1GLv7Noduv0ZHS6JswYyMrF3ku67RIaf5R7dN2n+Xrh75mX/sw1MgRbKaqn4vmMmYmPhEYhMS0dfR/q44BOE9kQQWvlqRIjb06z+AgYP+oXq1aqrK1uPHTzBl6lSioqIIDg6hsLW1KglcM/m/RWyKYF24sKrKNnfuXLx8+RJTU1OyZctGqVKlAGjWtClz5sxNkQS+cOEid+/eo7RrGQDi4uJxcXHGxMQEAwN92rZrT/Vq1ahevZpazO7ubly76v3d116jRnUaN26Evr4+ixYtplXrNhz1OsL8BQuoUqUKWbNm/eixmzZtZvWqFR/dLgiCkJrDx8+QOaMlu1YvACDsXTgAnVs1YUjvLgC07jGIfV4nqF5BmRRDT1eX8/s3M2fpGuq17c75/VswNzWhUKnK9GjfEoCHT56xaOpoSjoVo0PfoSxctZE+nVqr2g0MDmHi7EUc2LiUNEZGTJ23lFmLV9GpVRN2HTzKrZN7lRtvYe/UYj5x9iL9R01SW29kaMjJXetSrHt//Mgpczh1/jK5c2Rj5tghZLRMj22hAuzc70X3ds3ZdcCL8IhIgkJCsS1cgHEz5tOrYyuiomM4cf4SBfPnUZ1z+OTZjJu5EPfSzoz7pw/6+nrf/PoLgvB3OnLWm0yW5myfMxKAsPBIADo2qs4/HRsD0HboNA6cukTVss4A6OnqcGb9TOat30WDXmM5s34m5ibpsKnRjm5NawHw0OcV80f0oIRdYTqNnMniLfvp1eLD2JyBIWFMXrKJvYvGkcbQgGkrtjJnzU46NKzGnuPnubZjodL3/uvph/dOXr7JwKlL1NYbGehzbNXUFOtyZ8vMIx9fnvv5kyVDevYev0BcwqfnGnn8wheTdGlo3HccPr7+uDvbMaZHS7S1RXJCEISvd/yeP1YmhqzrqOQA3kUrfVAb1zz0raw8ydVtzWWO3HlDRRslf6Cro8XhfuVYcuIxrZZe4HA/d0zT6OEy+hAd3PIC8PhtBNMbO1A8twW91nuz8sxTupTLr2o3KCKWmYfvs7lLadLo6zDH6wELjz+itWtuDtzy48zgCkiSRFhUnFrMZx4FMGLHTbX1hrra7O3t9sXXfvNlCH4h0VSwzpQiCfxve2/4USSraYoEcK/13mhrSVQrmpneFQuKAjPhq4kksPDV8ufPj/eVS+zff4Bhw4dTrlw5BvTvR9du3bl86QLZsmVj5KjRxMR8GKNGX18fUCoK3v/+fjkhIQFArQP7/2VZlqlQvjzr169Vi+nihfMcPXqMrdu2MW/+fI56HUmx/UdVAltYWKh+b9euLQMH/QPAhfMXOH3mLAsWLCQiIoK4uDjSpk3LxAnjAbhx4wYJCQk4ODh8cVuCIAgA1oXyM3DMFAaPm0bV8m6Udlb6kZPnLjFtwXKiomMICQ2jcP48qiRw9YrKf20K5aNQ/rxkymgJQK4cWXnl9xoTY2OyZbaipFMxABp7Vmfe8nUpksAXr97g3sMnuNVuBkBcfDwuxewwSZcWA309OvYbRlWPslQtr/64sFspZy4f3v5F15eQmMir128o4WDHlBEDmbl4JYPGTGXF7IlMHNafXkPHsWbLTko7O5LFKiPaWlpUKFsK7xu3KVurKektzHEpVhRtbaVibcyg3lhlSE9cXDxdBo5g6vylqmS5IAjCl7LOl5N/pi9j6KwVVHF1olQxGwBOXb7JjFXbiIqJJSQsnEK5s6uSwNWS/2udNyeF8mQnk6VSAZYrixWv/AMxTZeGrFaWlLArDECjqu4s2LAnRRL48q0H3H/2Eo9WyhMW8fEJFLctiEnaNOjr6dJ51CyquBanShkntZjLOtlyYdOcL7o+M+O0zBrchRYDJ6ElSTgXLcSzV28+eUxCQiLnrt3h3IbZZLOypMXASazdfZSWdSp+UZuCIAj/ViizMSN33WLM7ttUsLbCJU96AM4+CmDesYdExyUSGhVHAStjVRK4UvJ/C2U2poCVMRlNlCcScqRPg19INMaGumQxNaR4buV7ez3HbCw99YQu5T606+0TzMM34dScdRKAuIQkHHOaY2ygi76ONr03XKWCtRUVrNWHhyydz5KjAzy+67qTkmRG7LzFrCYfzw3cf/2Osbtvs6lLKdW6+c2dyGRqSERMPG2XX2TL5Rc0KJ7ju2IR/j4iCSx8NT8/P8zNzWnWrCmmpqYsW7ZclfBNnz49ERERbNu2nbp1v27G0RcvXnD+/HlKlCjB+g0bKFW6VIrtLi7OdOveg8ePH5M3b14iIyPx9fUlc+bMREVFUbVqFUqVKkmevPnVzu3u/mMqgV+/fq2qYt69ew+FChUEYO3aNap9Vq5cxRVvb1UCGGDDxk00atTwu9sXBOHvkz93Ti4c2MLBY6cZOXk27qWd6du5LT2GjOXc/k1ky5yJMdPmERP7oVpBX0+pfNWStFS/v19OSEgEUrnxhvqNN48yJVgzL2X1GMDZvZs4duYCO/YfZsHK9RzanPIph6+pBLYwM8XI0JDaVSsAULd6JVZuVBLIma0ysHnpLAAiIiPZuf8IpibGAAzq0ZFBPToC0KJrf/LlygmgSnjr6+vRokEdZixaqRaHIAjC5+TLkYWzG2Zx6MwVRs9bi1vxovRuVZdeExZwZt0MslpZMm7hOmLj/tX36uoCoKUloa+nq1qvpSWR+L7v/b92/r+IS5Zl3J3tWDVRfY6LU2tncPzidXYePcvCTXs5sHh8iu1fUwkMULWssyqBvXzbQdXNtI/JkjE9tvlzkyurFQDV3V24fOsBLT95lCAIQuryZEjHkX7lOHr3DRP33cU1vyVdPfIzaMt1DvVzJ4uZEVMO3CUmuf8E0NNR+ilJklS/v19OSJKTF1K2k1qtbJkCGVjYsrja+gN93Tj9IIC9N3xZfvop27q5ptj+IyqBI2ITePD6HZ5zlWK0gHcxtFxynlXtS2CX3Qy/0CjaLLvAnGaO5EyfVnVcJlMl4Z3WQJc6Dtm49iJEJIGFryaSwMJXu3XrNgMGDkRLSwtdXV3mz5uLqakp7dq1pYitHVZWGXFy/PqK1wIFCjB//gLatutA4UKF6NypY4rtlpaWrFi+jCZNmxEbGwvAmNGjSZcuHbXreBITE4Msy0ybOuW7r3HAwEFs2LCRqKgosmXPSdu2bRg5Yjiz58xlz5696OhoY25uzorly77ofFu2bGVf8hjKgiAIX8PvzVvMTU1oUrcGJibpWLFhGzHJfWB6MzMiIiPZvv8wnlW/rhLrhe9rLnhfx8XBjk079lOyeLEU252LFaXXkLE8fvacvLlyEBkVhe+bt2TOaElUdAxVPMpQ0smegiUrqZ37ayqBJUmiWgU3Tp6/hHspF46fuUChfMrQDoHBIZibmqClpcXkuUtp2bAOAImJiYS+C8fCzJRbdx9w6/5DlpctCcBr/wAyZbRElmV2HzqKdYG8X/W6CIIgALx+G4SZSToaV3PHNF0aVu44TExywtfC1JiIqGh2eJ2lTvlSnzlTSi/fBHDxxj2cixZi84GTqqrg95yKFKT3xIU8eeFHnuyZiYyOwe9tEJkszYmKiaWyqxMl7ApjU6Od2rm/phIY4G1wKBnMTQl5F8HizftYM3nQJ/d3sM5HaHgEAcFhWJqbcPLyTYoVFn2sIAjf5k1YNKZGetRzyo6xoS7rL/gQG68kfM3T6BMZm8De635Ut8v8Vef1DYnmyrMgHHNZsN37JcVzp0+xvVhOc/7Zcp1nARHkskxLZGwCb8KisTIxJCougfLWVhTPbYHz6ENq5/4RlcDGhrrcHV9dtVxnzilG1CqCXXYzwqLiaLboPENqWKuqmQESEpMIi47HIq0+8YlJHLnzmjL5M3xXHMLfSSSBha9WqVJFKlVSTzaMHTOasWNGq60/fuzDRGlubmVxcyurts3HxwcdHR3WrFn9yePLlXPn0sULavtcvHD+6y7iMyZPmsjkSRPV1k8YP44J48d98thWrVrSqlXKmognjx/+0PgEQfh73L7/kH/GTkNLS0JXV4c544djamJMmyZ1sS9fGytLCxyL2nz1efPnycXClRvo0HcYhfLlpmOLlE8rWFqYs2TGOFp0609srDJG28gB3UmXJg312nQjJjYOWZZVE7d9j3GD+9Cm5yD6jZhEegszlkwfC8Cpc5cYOnEmkiTh6uzIrHHK5KPx8QmU82wOgHHatKycPREdHeUjTavuAwgICkFGpmjhgsydOPy74xME4e9z+7EPQ2auQEuS0NXRYdbgLpimS0trz0o41e9KRgszHKzVnz77nPw5s7Jo8z46j5pFwVzZaV+/aortluYmLBrVi1b/TCE2Xul7R3RpTlojQxr2HkNMXDyyLDOhj3oS+Gv1n7yY2w+fATCoQyPy5cgCgPedhzTqM47QdxEcOHWJcQvXc2XbfLS1tRnfpy3VOg1BlmXsC+Wltaf6jUBBEIQvcc/vHaN33UJLS0JHS2JSA3tMjPRoVjInbhO9yGCsj112068+b94MaVlx+im9N1wlf8Z0tCydK8X29Gn1mdXUgU6rLhGXkATAoGqFSauvQ8ulF4iNT0QGRtb5vknhAEbvusUO75dExydiP3w/TUrkpH+Vwh/df/nppzwLjGD6oftMP3QfgI2dS2Gkp0PjBWeJT0wiUZYpkz8DzUrm+uh5BOFjJFmWNR2D8I0kSZKTEj89gcPvwsfHhxo1a3Pr5nVNh/LH09LWRZZlMYK8IHwFSZLk2Fd3NB3GD+Pz0pc6rbpw7eguTYfyR9PPai36W+GvIkmSHHltr6bD+GU99/Onbo9RXNk6X9OhCJ+Rxr666L+FP5YkSfKbWV83dOPv4kVQJM0Xn+fkP+U1Hcpfx6rndtFv/gY+PfCTIPxHcubMKRLAgiAIgiAIgiAIgiAIgvATiCSwIAiCIPxlcmbLIqqABUEQ/mM5MmcUVcCCIAg/UXaLNKIKWBA+QSSBhf9UOmNTjbQ7a/ZsitjaYVOkKDNnzVKt7z9gIIUK21DUzh5Pz3qEhoYCyvAURmnSYV/MAftiDnTq3AWAqKgoqlevSaHCNtgUKcqgfwZ/tM0JEyeRL39BChay5tChwz/1+gRBEN4zz++okXY79B1K1qKu2HvUUts2b/k6ipStjl25mvwz9sMM9ZPnLqFQqcrYlKnG4RNnVOvnLF2DvUct7MrVZPbSD2PFb9t7CLtyNTHIZoP3jdsfjeXQ8dPYlKlGoVKVmTJ3yQ+6QkEQhJQylKz3n7f56k0AVdr/g4NnZxzrdmHe+g839LYfOYNj3S6kLVaDq3ceqdbHxcfTccRMnOp3xblBN05d+TCzfeV2g7Cr3RGXht1xadidt8GhACzdsh+n+l1xadid8q0HcO/Ji1TjOXzWG7vaHSlSsz1Tl2/5ORctCIIA5O7/3xcwxMQnUnnaccpNOkqZCUeYvP+uatuZh2+pMOUoZSd40X3tFRISlfGFzz4KIN/A3XhMPorH5KNMO3gPgMf+4ap1HpOPknfAbhafeAzA7VehVJ1+HI/JR6k49RhXnwenGs+mS88pMeYQJcYcYtOl5z/56oU/kZgYTvjj3b59m6VLl3Pxwjn09PSoUrUa1atVI2/evFQoX54J48eho6PDwEH/MGHiJCZNnABAnjx5uHbVW+18ffv2wd3djbi4OMpXqMiBAwepUqVyin3u3r3Lpk2buH3rBn5+flSoWJkH9++ira39H1yxIAjCf695/dp0btWENr3+SbH+xNmL7Dl8jCuHt6Ovr8fbwCAA7j18zOZd+7l+bDd+/m+p0rgdd07t4/6jpyzfsJWzezeip6tL9WYdqepRlry5clC4QF42LZlFt4GjPhpHYmIiPYeOY//6JWTNlJGS1RpSvaI7hfKLGewFQfj9vZ+czb5QXsIjoyjdpBflnO0plCc7hfPkYP20wfQYOzfFMSu2KzPcX94yj7fBodTpNoLTa2egpaXUAy0f149i1vlSHNOgihvtkiet23fiIoOmL2XXvJQTQCcmJtJn4gL2LBhLlowWuDbtTbWyzhTKk/1nXb4gCMJ/Sl9Hi23dXEmjr0N8YhI1Z53Eo7AV9tnN6LHOmy1dS5MnQzom7b/L5ksvaFIiJwDOudOztmPJFOfKmzEdRwd4AJCYJGM3fD9VbDMDMGb3bfpWLoRHYSu87rxhzO7b7OheJsXxIZFxTDt4j0N9yyFJUHHqMSrZZMLUSO/nvxDCH0NUAgvfbNA/g5k3/8MjbSNHjWbqtOlERERQvkJFHBydsC1qx65du9WOPXHiJDVqfKgW69a9BytXrgLA29sbN/dyODoVp3Llqrx+/fq74rx37z7FizthZGSEjo4OZcqUYfuOnQBUrFhBNaO8i7Mzvq9effJcRkZGuLu7AaCnp4e9vT2vUjlm1+49NGzYEH19fXLlykXePHm4dOnSd12HIAh/nyHjp7Ng5XrV8php85i+cAURkZFUatgG58r1KOZRm92Hjqkde/LcJWq37KJa7jlkLKs37wDg6s07lK/bEpcq9anWtD2v/QO+O1ZXF0fMTE3U1i9es4n+Xduhr698QM2Q3gKAPYeP06BWVfT19ciVPSt5cmbj8vVb3H/8lOJ2thgZGip9tosjOw94AVAoXx4K5Pn0TMiXr98iT85s5M6RDT09PRrUqsqew8e/+/oEQfizDZu1kkWbPkxqN27hOmau3k5EVDRVOw6mZOOeONXvyt7jF9SOPXXlJnV7fLg51WfiAtbsVvqta3cfU6ntIEo16UnNLsN4HZB6ddeXymRpjn0h5aZWujRGFMiVDb8A5eZawdzZyJ8zq9ox95++pKyTLQAZzE0xSZeGq3cfqe33b8ZpjVS/R0bHIKE+18+V2w/JnS0TubJaoaerS71KZdh7Qv31EQRB+H9jd99m+eknquUpB+4y/9hDImMTqDf3NBWmHMVtohcHb/mpHXv2UQDNFp1TLf+z9TobLypVsTdehlB79ikqTjlGowVn8A+L/q44JUkijb6SL4hPTCIhMQkJCI6KQ1dbizwZ0gFQtkAG9t7w/eLznn74lpzp05DN3Ci5HQiPSQAgPCYeK2MDtWNO3PenbIEMmKXRw9RIj7IFMnD8nv93XZ/w9xGVwMI3a9igPr379KVrFyXJsGXLVg4e2IeBgQHbt23F2NiYwMBASpQsTc2aNZCkz08UGR8fT4+evdi5YzuWlpZs2rSZIUOHsXzZ0hT7rVu3nqnTpqkdnzdPXrZs2ZRinY2NNUOHDScoKAhDQ0MOHDiAg4OD2rErVqykQYP6quVnz55RzMERY2Njxowejatr6RT7h4aGsnfvPnr26K52Ll9fX1ycnVXLWbJmwddX/Q+YIAjCp9SvWYV+IybSuVUTALbuPcjedYsx0Ndny9LZGKdLS2BwCK41GlOjovsX97O9h41n6/I5WFqYs2X3AUZMnsXiaWNT7Ldh+16mL1yudnyenNnZuHjmF1/Do6c+nL3ozYhJszDQ12fisH442hXB97U/zsWKqvbLamWF32t/ChfIy/BJswgKCcXQQJ+Dx05TzNb6i9vze+1PtkyZVMtZrDJy6drNTxwhCIIAdSu5MnDKEjo2rA7A9sNn2DV/NAZ6emycNhTjtEYEhoTh3rIf1dycv7C/TaDvpIVsmjEMS3MTth46xah5q1k4sleK/TbuP87MVdvVjs+TLRPrpn586LHnfv7cePAUJ5sCn4yjSP5c7D95kQaVy/LKP4Drd5/w6k0gjsnHdRw5E20tLWp7lGRg+0aqa1u0aS9z1u4kLj6B/YvGqZ3X720QWTNaqpazZEzPldsPPhmLIAgCQK1iWRm2/SZtXPMAsPuaLxs7l0JfR4sV7VxIZ6BLUEQs1WacoJJNpi/rcxOTGLL1BivblyB9Wn12Xn3FhH13mdkk5Xf/bVdeMP+Y+o2wnOnTsKyNi9r6xCSZilOP8SwggtaueSiW0xxZlklISuL6ixDsspux97ovfqEfEs7ePsGUm3SUjCYGjKhVhIKZjFOcc+fVV9Qulk21PLqOLY0XnGX0rlskyTJ7ermpxfE6LJrMph9u0GUyNeT1dya5hb+PSAIL38ze3p63bwPw8/MjICAAMzNTsmXLRnx8PIOHDOX06dNoaWnh6+uLv78/VlZWnz3ngwcPuH37DhUrKcMrJCYmkskqk9p+TZs2oWnTJl8UZ6FChRjQvx+VKlchTZo0FC1aVG1YhnHjJ6Cjo6M6Z6ZMmXju8xQLCwu8vb2p41mP27duYGysdN4JCQk0adKM7t27kjt37i+KQxAE4WvZ2RTibVAwfm/eEhgcjJmJMdkyZyI+Pp5hE2dy5qI3WloSfm/e4h8QiFUGy8+e8+ETH+48eETVxu0ASExMwiqj+nGNPavT2LP6d19DQmIiwaFhnN6zgSvXb9Gkc18enDv00f0L5ctDvy5tqdakPWmMDLG1Loi2tnhwSRCEn8uuYB4CQkJ5/TaIgJAwTI3TktXKkvj4BEbOXcWZq3fQkiT83gbhHxSKVXqzz57z4fNX3H3ynBqdhwKQmJSEVXpztf0aVXWnUVX3r4o3IiqaJv3GM7lf+xRVu6lpUasC95+9pHTTXmTPlAHnoh/61eXj+5E5Q3rCI6No0m8C6/ceo2kN5XHljg2r07FhdTYdOMGkpZtYMqbPV8UoCILwMUWymhIUEcubsGiCImIxNdIli5kR8YlJjN97hwuPA9HSkngTFk1AeCwZUqmM/X+P/cO5//odDecr80wkJslkTOW4uo7Zqev45cPWaGtJHB3gQVhUHK2XXeCeXxiFMpuwqGVxRuy4SWxCEm4FM6CtpSSqbbOZcmVkZdLo6+B15w2tl57n/LBKqvPFJSRx+PZrhlT/UOSw6uwzRtWxpbpdFnZde0WfDd5s6er6xTEKwpcSSWDhu9SrV5et27bx5o2/qop23br1BAYEcuXyJXR1dcmVOy8xMTEpjtPR0SYpKUm1/H67LMtYWxfm3NkzfMrXVAIDtG3bhrZt2wAweMhQsmbNotq2cuUq9u3bh9eRw6o7jPr6+ujr6wPg4OBAnjy5efjwIY6OyoRLHTp2Im++vPTq2TPV+LJkycLLfw0T4fvKlyxZMn/ymgRBEFJTt1pFtu87jH9AIPVqVAFgw469BAaHcOHAZnR1dcnvUoGY2LgUx/1/PxubvF2WZQrnz8up3ev5lB9VCZzFKiO1q5RHkiSc7G3R0tIiMDiELJky8ur1G9V+r968IXOmjAC0blyX1o3rAjBs4kyyJK//EpkzZeTlv4YR8n3j/1XHC4Lw96pTvjQ7vM7iHxRC3YrKl++NB04QGPKOs+tmoqurQ6GqbYiN+7/+Vvv/PtfGxgMgy1Aod3aOr1b/zPpvX1sJHB+fQJN+42lYxY1aHiXVtv8/HR1tJvdrr1ou17IfebMrn4UzZ0gPKENLNKhSFu87D1VJ4PfqVypDr/Hz+X+ZM1jw6l/DCfn6B5LJ0uKz8QiCIABUt8vC3uu+vH0XQy17ZSibbVdeEhQRy+H+5dDV1sJx1EFi4hNTHKejJZEky6rl2H9tL5DJmH293T7Z7tdWAr9nYqRHqXyWHL/vT6HMJjjmsmBXz7KAMlTDk7cRAKQz0FUdU97aikFbrxMUEYtFWiW/cOzeG4pkNcXyXwnqzZeeM9ZTGbanpl0W+m64qtZ+JhNDzj3+0Oe+Do2mZN7PF4AIwr+JJLDwXRo2qE+Hjp0IDAzixPGjAIS9C8MygyW6urocP36C58/VZ63MkSMHd+/dIzY2lujoaI4dO07pUqUoUKAAAQGBnD9/nhIlShAfH8/Dhw+xtk75KPDXVAIDvH37lgwZMvDixQt27NjJ+XNKkvngwUNMmTqNE8ePYmT0oYoiICAAc3NztLW1efr0KY8ePVZV/A4dNpx3Ye9YumTxR9urWaM6TZs1p0/vXvj5+fHo8WOKFy/+xfEKgiC8V79mFToPGEFgcAheW5Wx08PeRWBpYY6uri4nzl7k+Sv14WayZ83M/UdPiI2NIzomhmNnL1CyuD358+QkICiYC97XcXGwIz4+nkdPn1O4QMqJ035UJXDNyh6cPHcJt1LOPHzqQ3xcPOnNzahewZ0W3frTs31L/Pzf8vjZC5zsigDwNjCIDOkteOHrx84DXpz+TML63xyL2vD42QuevXhFFqsMbN61n9Vzp3z3dQiC8OerW8mVbqPnEBT6joNLJwLwLiISSzMTdHV1OHn5Ji9ev1U7LnumDNx/+pLYuHiiY2M5cekGJewLkz9nFgJD33Hxxj2cixYiPj6BRy98KZwnR4rjv6YSWJZlOo+aRYFc2ejRvM4XHRMVHYMMpDE04OiFa+hoa1MoT3YSEhIJDY8gvZkJ8fEJHDx1CXdnOwAeP/clbw4lUXzw9GXyZFMvZnCwzs+TF374+L4hcwYLth46xYoJ/b8oJkEQhFr2Wem38SrBkXHs6K7ceAuPjid9Wn10tbU48yiAV8FRasdlNTfioX84sQmJxMQlcvphAMVzpydPhnQERcRy5VkQjrksiE9M4snbCLWhGL6mEjgwIhZdLQkTIz2i4xI59eAtXT3yAxAQHoNlOgNiExKZ6/WQXhWVIXbevovBMp0+kiRx9XkwcpKMeZoPk7ft8H5F7WIpx2+3MjHk3ONASuWz5MzDAHJbplWLxa1gRsbvvUNolHIj8sT9twyubvNF1yEI74kksPBdrK2tCQ8PJ0uWzGRKHoOxaZMm1KxVG9uidjg6OFCwYEG147Jly0b9+vUoYmtHrpw5sbezA5TJ1rZs3kjPXr0JCwsjISGRnj26qyWBv1a9+g0ICgpGV1eHuXNmY2pqCkD3Hj2JjY1VDT/h7OzMwgXzOXXqNCNGjkJXVwctLS0WzJ+Hubk5r169Yvz4CRQsWBAHRycAunbpQrt2bdm9ew9XvL0ZPWok1tbW1K9fH2sbW3R0lDb/fwgKQRCEL1G4QF7CIyLJYpWBTMnDNjT2rI5nq64U86iNQ1FrCuRVH5YmW+ZM1K1eCXuPWuTMnhU760KA0s9uXDyDPsMnEPYunITERLq3ba6WBP5azbv249T5ywQGh5LbsRzD+naldeO6tGpYhw59h2HvUQs9XV2WzhyHJEkULpCXejUqU7RcTXS0tZk1dqiqn2zUoRdBIaHo6ugwa9xQTE2UD++7DnjRe9h4AoKDqd2yC7bWBdi3bgl+b97Sqf9wdq9ZiI6ODjPHDKF60w4kJiXRqmGd7742QRD+DoXz5CA8KprMGSzIZKkM29Cwihv1e47GqX5XihXOR4Fc6hOvZbWyxLNiaZzqdSFHFiuKFlT6ZD1dXdZO+Yf+kxYRFhFJYmISXZvWVEsCf43z1++yYd9xrPPlxKWhMi/FyG4tqOzqxO5j5+g7aRGBIWF49hiFbYFc7J4/hoCQMGp1GY6WlkQmSwuWju0LQGx8PLW6Dic+IZGkxCTcnIvS2lN5ZHnhpr2cuHgDHR1tzIzTsnhMbwBevw2iy+jZ7Jg7Ch0dbaYN7EStLsNJTEqiRa0K33VtgiD8XQpmMiYiNgErEwMymhgC4OmYjRZLzuM20Yui2UzJlzGd2nFZzIyoaZcFtwleZLdIQ5GspgDo6WixtLUzQ7ff4F10AglJSXQom1ctCfw13obF0GPdFRKTZJJkqGmfhYo2St5j/rFHeN15Q5Is07JUbkrnzwDAnuu+rDr7FB0tLQx0tVjYqrjqiePI2AROPXjLlIb2KdqZ2tCeYdtvkpAko6+rxZRGyvbrL0JYffYp0xs7YJZGj96VClJ5mjLhcZ9KBTH7V3JZEL6EJP+rjF74vUiSJCclxms6DOE3o6WtiyzLnx9ZXxAEFUmS5NhXdzQdhvCb0c9qLfpb4a8iSZIceW2vpsMQhO+Wxr666L+FP5YkSfKbWZ6aDkP4w1j13C76zd+AmGlFEARBEARBEARBEARBEAThDyaSwIIgCIIgCIIgCIIgCIIgCH8wkQQWBEEQBEEQBEEQBEEQBEH4g4kksCAIgiAIgiAIgiAIgiAIwh9MR9MBCN/OwMDAX0tbN6Om4xB+LwYGBv6ajkEQBEEQBEEQBEEQBEH470iyLGs6BuEPJElSMWAf8I8syys1HM5PJ0mSB7ABaC3L8j5NxyMIwo9laGDwJiY2Vtx0E76Kgb6+f3RMjJWm4xCE/4qhgf6bmNg40VcKvz0DfT3/6JhY0X8LfyRDPe03MfFJoq8WfigDXS3/6LhE0W/+4kQSWPjhJElyBbYBnWRZ3q7peP4rkiQ5A7uA3rIsb9B0PIIg/B0kSeoJ9AUqyrJ8X9Px/FckSeoIDAcqy7J8S9PxCILw55MkSQ9YDWQAasmyHK7hkP4TkiTpAMuAPEB1WZZDNRuRIAh/A0mSMgOHUYrLBsl/SfJKkqQMwCHgNNBLluUkDYck/EHEmMDCDyVJUlVgO9D0b0oAA8iyfBEoD0yRJKmTpuMRBOHPJilGAl0B178pAQwgy/IilOS3lyRJLpqORxCEP5skSUbATsAQqPq3JIABZFlOAFoD3sBxSZJEBaEgCD+VJEm5UZKg62RZHvi3JIABZFl+C7gB9sDK5BtxgvBDiCSw8MNIktQQWAHUlGX5iKbj0QRZlm8DZYEBkiQN0nQ8giD8mSRJ0gJmALVREsDPNRuRZsiyvBElMbFHkqTymo5HEIQ/kyRJJihVWUFAPVmWYzQc0n8uuRKtF8pTb6clScqu2YgEQfhTSZJkA5wCpsqyPEHT8WiCLMthQCXAEtgqSZKBhkMS/hAiCSz8EJIktQemAxVkWT6v6Xg0SZblJ4Ar0FySpImSJEmajkkQhD/Hvx7LdQLcZFn+qyd7lGV5P1AXWC9JUh1NxyMIwp9FkiRL4DhwA2gpy3K8hkPSGFkxEpiPkgguoOGQBEH4w0iSVBzwAgbIsrxA0/FokizLUUAtIA7YJ0lSOg2HJPwBRBJY+G6SJA0ABgNlZVm+qel4fgWyLPsCZYBywAJJkrQ1HJIgCH8ASZL0gc1AZpQxgEM1G9GvQZblU0AVYL4kSS01HY8gCH8GSZKyoTyOvA/oLsZlVMiyPBMYCZyQJMles9EIgvCnkCSpHLAXaCfL8npNx/MrkGU5DmgMPEUZAs1cwyEJvzmRBBa+WfJ4lBOAVkBpWZYfazikX4osy0GAB5AfWJc8mYggCMI3kSQpLcoH40SUYXciNRzSL0WWZW/AHRgjSVIPTccjCMLvTZKk/CgJ4MWyLA/7m8aj/BKyLK9AGZP+UPKk0IIgCN9MkqRawEagvizLezUdz69EluVEoANwEjiVPGGeIHwTkQQWvknyeJTzgQpAmeTKV+H/JE8aUhUwAnYkTyoiCILwVZLv+h8BXgCNZFmO1XBIv6TkyfFcge6SJA0Xw/EIgvAtJEmyA04AY2RZnq7ZaH5dyZNANwW2S5JUWdPxCILwe5IkqTmwCGXSzZOajudXlHwjciCwDmU4nlwaDkn4TYkksPDVJEnSBdYAhYFysiwHajikX1ry5CF1gRDgYPLkIoIgCF9EkiQrlGTEOZTH4xI1G9GvLXmSPFeUfnd68k1LQRCELyJJUimUSeB6yLK8TNPx/OqSJ4OuBaySJKmBpuMRBOH3IklSN2A8Sl7hiqbj+ZUlj8s+AZiGkgi21nRMwu9HfDESvookSYbAdsAEqCzL8jsNh/RbSJ5EpAVwEziWPMmIIAjCJ0mSlBM4gzIOcD/xOPKXkWX5DeAGOAPLkifTEwRB+CRJkioBO4EWsixv1XA4vw1Zls+hPB04I3myaEEQhE9KHlpyKNAL5cniuxoO6bchy/J8lKrgo5IkOWk6HuH3IpLAwheTJMkYOAC8A+rIshyt4ZB+K8mTiXRHeQ1PJU82IgiCkCpJkgqjjEc5U5blsSIB/HVkWQ5BSUpkBjYlT6onCIKQKkmS6gGrgdqyLB/SdDy/m+TJod2AwZIk9ddwOIIg/MKSh+uaCjQAXGVZfqbhkH47siyvA9oD+yRJctd0PMLvQySBhS8iSVJ64BhwD2ieXNkqfKXkRziGAstQHuHIp+mYBEH49UiS5IjS5w6WZXmupuP5XSVPnlcTkIE9kiSl0XBIgiD8giRJagPMBirJsnxW0/H8rmRZfoQyHE8bSZLGiXHZBUH4f5IkaQNLgJKAmyzLrzUc0m9LluU9KIn0zZIk1dR0PMLvQSSBhc+SJCkLcAo4DHRJrmgVvoMsy1OBscAJSZKKajoeQRB+HZIklQX2Ax1lWV6j6Xh+d8mT6DUCXgFHJEky03BIgiD8QiRJ6gMMR0lGXNdwOL89WZZfAWWAysBcMS67IAjvJT+VtRHICVSQZTlYsxH9/mRZPoEyEf1iSZKaaTgc4Tcg/igLnyRJUl6U8ShXyrI8WDyO/OPIsrwUZQykw5IkldRwOIIg/AIkSaoObAEaybK8S9Px/ClkWU4A2gEXUG6+WWk4JEEQNCx5PMoxQAeUx5EfajqmP4UsywFAOcAGWJ08qbQgCH+x5KexdgPaQDVZliM0HNIfQ5bly4AHMEGSpK6ajkf4tYkksPBRkiTZAieBCbIsT9Z0PH8iWZa3AC2BXZIkVdR0PIIgaI4kSU2ApUB1WZaPaTqeP03yUyx9ga0ow/Hk1GxEgiBoSnJ16mygGsqERC81HNIfR5blMJRqYFNgW/Lk0oIg/IUkSTJFear4NdAg+Skt4QeSZfkOylMYvSVJGiKG4xE+RiSBhVRJkuQCHAH6yLK8WNPx/MlkWT4I1AHWSpJUV9PxCILw35MkqTMwGSgvy/IlTcfzp0oel30MSvLnlCRJhTQdkyAI/y1JknSAVYAd4C7L8lvNRvTnSp5Eug4QCeyXJCmdhkMSBOE/JklSRuAEcAVok/x0lvATJE+w54oyDNpkkQgWUiOSwIIaSZLKozyq0VqW5U2ajudvIMvyGaASMEeSpNaajkcQhP+OJEmDgP5AWVmWb2s6nr+BLMtzgKHAMUmSHDQdjyAI/w1JkgxQngZIjzIJXJiGQ/rjJU8m3Qx4gNLnptdwSIIg/EckScoOnAZ2Ar3E3EI/X/JEe2VRksGLkyfiEwQVkQQWUpAkqQ6wHqgry/J+TcfzN5Fl+RrgDoyUJKm3puMRBOHnSh6PchLQHCgty/ITTcf0N5FleTXQGTggSVIZTccjCMLPlVyFug+IBWrJshyl4ZD+GrIsJ6L0t17AyeRJpwVB+INJklQQJQE8T5blkWJuof9O8oR75YFcwAZJkvQ0HJLwCxFJYEFFkqRWwHygsizLpzUczl9JluUHKHftOkmSNFo8wiEIf6bku/ILUW78lJFl2U/DIf2VZFneCTQGtkqSVE3D4QiC8JNIkmSBkoB8AjSRZTlOwyH9dZKH4/kHWI0yLnseTcckCMLPIUlSMeA4MEKW5VmajudvlDzxXnVAF9idPDGfIIgksKCQJKknMBplbLSrmo7nbybL8guURHANYFby5CWCIPwhku/GrwPyAR6yLAdpOKS/mizLR1H62+WSJDXWdDyCIPxYkiRlRpno+CTQMbkqVdAQWZYnAZNQxmUvoul4BEH4sSRJcgUOAl1lWV6p4XD+arIsxwD1AX/gUPIEfcJfTiSX/nLJjyOPALoCrrIs39d0TAIkT1LiDhQDViRPYiIIwm9OkiQjlHHRDIGqsiyHazYiAUCW5Ysoj81NkSSpo6bjEQThx5AkKTfK48jrgIHiceRfgyzLi4B+gJckSc6ajkcQhB9DkqQqwHagqSzL2zUdjwDJE/G1Bq4CxyVJyqDhkAQNE0ngv1hyhekMlFl7XWVZfq7hkIR/kWU5FKgIZAC2JE9mIgjCb0qSJBOUyoggoF7y3XnhFyHL8i2UiTQGJk/WJwjCb0ySJGvgFDBVluUJIgH8a5FleQPQBtgjSZKHpuMRBOH7SJLUEFgJ1JRl+YiGwxH+JXlCvp7AbpTheLJrOCRBg0QS+C+VXFm6DHAC3GRZ9tdwSEIqkictqQXEA/uSJzURBOE3I0mSJcrYaDeBlsmzpQu/mOTJ+VyB5pIkTRTjsgvC70mSpOLAUWCALMsLNB2PkDpZlvcB9VAmLqqj6XgEQfg2kiS1B6YDFWRZPq/peAR1yeOyjwAWoCSCC2g6JkEzRBL4LyRJkj6wGcgMVEyuOBV+UcmTlzQGngJHJEky13BIgiB8BUmSsqE8jrwP6J58N174Rcmy7AuUATyABcmT+AmC8JuQJMkdpb9tL8vyek3HI3yaLMungCrAfEmSWmg6HkEQvo4kSf2BwUBZWZZvajoe4dNkWZ4JjAROSJJkr9loBE0QSeC/gCRJ2smTYiBJUlpgD5CE8qhGpEaDE75I8iQmHVASSSclScoEymzXkiQZajQ4QRBSkCTJRJIk4+Tf86H8f7tEluVh4nHk30PyZH0eQAFgrSRJugCSJGUV1cGC8GuRJCnz+5s1kiTVBDYB9WVZ3qPZyIQvJcuyN1AOGCtJUvf36yVJyqq5qARBSM37/y+T5xYajzKsi6ssy481G5nwpWRZXgF0Q5ksrjQohYJivOC/g0gC/x3aAOMlSTIDjgAvgUayLMdqNizhayQnjwYAG4AzkiTlAjoCozUamCAI/28+4ClJUlGU2ejHyLI8TcMxCV9JluV3QFUgDbAzeVK/5cnrBEH4BSQnfy8C2SRJagYsRpl084RGAxO+mizL91CewughSdLw5H/b2+IJOEH4dUiSlB84lTy30DyU+WvKyLL8SrORCV9LluVtQDNghyRJlQEHlKdohD+cSAL/HVqhjIt2EjgHtEueJVL4zSSP5TMemIZSXXgTaJo8xrMgCBqWPPlbNcAfOAz0kGV5mWajEr6VLMvRQF0gBGVSv/1AS40GJQjCv5UD3gLVgQlAOVmWr2g2JOFbybLsgzIue11gKkq/20iTMQmCkEJLYBewBrBG6XMDNBuS8K1kWT6MMv/QKiAbkFmSpMKajUr42STxZOqfLflR5HNAKLAa5cPUM1mWAzUZl/DtJElKA9gBeYFJQCDQX5blA5qMSxAEkCSpHcqNtwIoT2GEAefFRHC/L0mSsgCWQHugFJALyCnLcohGAxMEAUmS1gKmQEGgAaAry/JFjQYlfBdJkmxRhq1bDIQDprIsO2s2KkEQkqt/nwNPgAhgIBAvy/JDjQYmfJfk4SBkYAtwA7gpy/JAzUYl/EyiEvjP1wcwBoJQxn1ZAeTTaETC97IEZgAzgcco/579NRmQIAgqfQFH4AGwDmW4lrQajUj4XnbANqAmkAgYoAzFIwiCBiWPvd4QcAaCgeMoN9+E31sN4ATK3878gKMkSUU0GpEgCKA86WYFZEQpRvIC3DUakfBdkhP7fVAKBX2A0kAnMSnyn01UAv/hJEl6BESj3E3fJ8vyMw2HJPwgkiRZocym3BooIsuymYZDEoS/WvIHpgiURMQa4JAsy8GajUr4EZIngyuA8sh5JyBYluXimo1KEP5ukiQ1QBmnex3KjZqTYr6LP0Py31MXlMeU26FMrioq0wRBgyRJWo8yae4ClInmr8mynKTZqIQfIflJYw+UG6ueQClZlq9qNirhZxFJYEEQBEEQBEEQBEEQBEEQhD+YGA5CEARBEARBEARBEARBEAThD6bzM09uaGj4JiYmJuPPbEP4MxkYGPhHR0dbaap9QwODNzGxseK9K3wVA319/+iYGPG+FX4rGn/fGhq8iYkR71vh6xkY6PtHR2uyz9V/ExMbJ967wlcx0Nfzj46J/U/ft4Z6Om9i4hPFe1X4YQx0tf2j4xLE+1j45WnivWqgq/UmNkEW71Xhh9DXkfxj4pN+2Hv4pw4HIUmSLIabEL6FJEnIsixpsH05zu++ppoXflN6mQtq/H0b88xbU80LvymDXA4af98mhPhqqnnhN6ZjlkXj792om4c01bzwmzKyrfSfv28lSZLfLmr5XzYp/OEydFylkfdxwMrO/2WTwh/AstUCjbxXfUeV+C+bFP5gWUac/6HvYTEchCAIgiAIgiAIgiAIgiAIwh9MJIEFQRAEQRAEQRAEQRAEQRD+YCIJLAiCIAiCIAiCIAiCIAiC8AcTSWBBEARBEARBEARBEARBEIQ/2C+TBE6bNu13n2PlypV069btk/v4+Piwfv36727rV7Nu3TpsbW0pUqQIJUuW5MaNGwA8ePAAOzs71Y+xsTEzZ84EIDg4mAoVKpAvXz4qVKhASEgIAPfv36dEiRLo6+szderUj7bZqlUrcuXKpTr39evXAThx4gQmJiaq9aNHj1YdM2PGDKytrbGxsaFx48bExMT8nBfkP2SWt9h3n2P1pu30HDz6k/v4vHzFhu17vrutX03Yu3Bqt+iEQ/laFHWrzqqN21JsfxceQS6Hsilen7i4ODr3H0bh0pWwca3C9n0pJ+bZvu8QepkL4n3jVqptzlq8kqJu1bFzr0Gzzn2IiYkF4NmLV5Sq1oBCJSvSpGNv4uLiADh94TLFK3pimM2abXsP/sjL1xgL69LffY7VW3fTa/ikT+7j88qPjbsOfHdbv5qwd+F4tu2FU5VG2Fesz6otuwG4cfcBZT1bYV+xPo6VG7Jl72HVMcfPXcKlehOKVWpA277DSUhIAECWZfqMnExht1o4Vm7Itdv3Ptl23Xa9KVapgWp5zMxF5HapTPGqjSletTEHj58BwOv0BUrUaIpD5QaUqNGU4+cu/eiX4T9nkjXfd59j1fpN9Og/5JP7+Lx4yYYtO767rV/NiTPnMM9eEAfXCji4VmDM5BmqbTPnL8a2hDtFS5Sjadsuqr/P8xavoECxUuiYZSEwKFi1/9TZC1TnKVqiHHoW2QhO/hzxb8+ev6BE+eoUKFaKxm06qfpVgC07dlPExQ3bEu40a9dVtf7FS18qezbGxrksRVzc8Hnx8me8HP8pS+da332ONbsO03v83E/u89z3DZv2Hfvutn41M1Zswbl+Z5zrd8axTgfS2lUhOOwdAAUrt8DJsyPO9TtTqtGH7wHBYe+o3mEQRaq3pnqHQYS8CwfgwbMXuDXrhalDdWau3PLRNo9fuEaJBl1xrt8Zj5Z9ePJCmcBy9uptFKvdnuJ1O1G13UBe+PmnOO5dRCR5yzf97L/Vrypnj3XffY6N5x4zaMOFT+7zIjCCbZeefndbv5pHb8KoMnE/WbuuYd7h2ym29Vx1lsL9NlFm1K4U69svPon7mN24j9mNw+CtuI9RPlNsvfhUtd59zG4ydlrFrZdKP3zjeRBlR+2i+NDtDN54kY9Nxn72wRvcx+zGdeROak398Bk2LCqONotOUHL4DkqN2MnlJ28BuP0ymCoT91N21C6azT1KeHRcquf91eXouOS7z7Hh9H0Grjn9yX1eBLxj2/mH393WryY0MpaWsw9SdugmKo7axr1XQaptiw7fxHXIRkoP3sjCQzfUjp1/4DqWrRYQFB4NwNZzDyk7dBNlhm6i6tjt3H4RmGqb3ZYcw6HfWtyGbcZt2GZuPVf2O3D1GWWHbsJt2GbKj9zKhYevAXgZGE65EVtwG7aZ0oM3svLYnR/9Mvwn8o27+N3n2HTtLUP2fbo/fRkSw46bAd/d1q/mcUA0NZbcItfoCyw866da7xsWS70Vd3Cbex33uddZev61alunzQ+psOAGFRbcwHnGVSos+PA+nnPKl1KzruI6+xonHod+9lz/du5ZGAXHX1Kde8aJD59fnWdcxWPedSosuEGVRTdV6++8iaTGklt4zLtOy3X3CY9J+FEvzUfp/PQWfjHvk8BNmjT5KeeXZRlZltHS0kp1+WMSEhLQ0fn2f45cuXJx8uRJzMzMOHDgAB06dODixYsUKFBAlZxNTEwkS5Ys1KlTB4CJEyfi4eHBoEGDmDhxIhMnTmTSpEmYm5sze/Zsdu7c+dl2p0yZQr169dTWu7q6snfv3hTrfH19mT17Nnfv3sXQ0JAGDRqwceNGWrVq9c3X/Td5/tKXTTv30tizxk85v6beuwtWrqNQ/rzsXL2QgKBgbFyr0NizBnp6egCMnDyL0s6OKY6ZMGshluktuHvmEElJSQSHhKm2hUdEMHfpGooXK5pqe76v/Zm3bA03TuzD0NCAxh17sXnXPlo09GTwuKn0aN+ShrWr0XXgCFZs2EbHlo3JliUTS2dOYMbC5d98nX+r56/82LT7II1qVfkp59fU+3bhmi0Uypeb7ctmEhAUgq2HJ41rVcHIwIBl00aTN1d2/PwDKFmjKRXKlMA4bRra9RvJwbULyJc7B6OmL2DNtr20blibQyfO8tjnJXeO7+TS9dv0GDqB0ztXp9ruzoPHSJPGUG199zZN6N2hRYp16c1N2bZ0JpkzWnLnwWNqtOzG0wt/xk2Mn83nxUs2bN1B4/p1fsr5NfW+BShdoji7N6V8f/n6vWbuouXcunAcQ0NDGrXuyKbtu2jZpCElXZyoVrk8HtVT/q3v16Mz/Xoos7TvOXCYWQuWYG5mptbePyPH0atzexrWrUWX3gNZvmYDndq25NGTp0yaMZdTB3diZmrK24APXwpbde7JP317UMG9DBERkZ99XYQPnvv5s+nAcRpWK/dTzv/t791EdHS0v7nd3q3r07t1fQD2nbjA3DXbMTcxVm0/sGwy6c1MUhwzbdlm3Jzt6de2IVOXbWLask2M7d0OM2Njpg7qzJ5j5z7ZZs9xc9g8ayQFc2dn0cY9TFq8gcVj+1G0YB7ObJiDkaEBizftYciMpayZ8uHG0ui5qyntYPPN1/q3eBkUwfZLz6hbPPdPOb/y3gQtLSnV5Y9JSExCR/vb+xxTIz3GNyrOgesv1LY1KpGHtu4F6bbiTIr1SzqUVf0+fMtljA2Vz8D1nHNTz1l5fe76htBy/jGKZDMHYMD680xrXhKHXOlpPOcox+744mGTNcV5w6LiGLjhAht7lCereVoC3kWrtg3ZdIly1plZ3tGNuIREouMSAeiz5hwj6zlSMr8V688+Yt7hOwyqZf/Nr8ef7mVgONsuPKZuifw/5fyaeh/P3OONTXYLVvWozCO/EAauOc32gTW59yqItSfvcmh4XfR0tGk4bS8V7XKSO6PS//oGRXD8ziuyWnwo8Mtuacyuf2pjmkYfr5vP6bvyJIeG10213RENS1DTKU+Kda6Fs1LZPieSJHHnZRDt5h3m/MTGZDQ14sBQT/R1tYmIiafMkE1Uts+JlVmab77uP9nL0Fh23Aqkjq3lTzn/t79XZXS0P73Pp5ga6jCmai4O3gtOsV5HS2JEpRwUyZyWiNhEKi+6SZk8JuTPYMTCBh/+fx110AdjA+XzycO3Uey6Hcixrnb4h8fRaNVdTvew/+S5/l/xHOlY3bRQqrFuaWWNeRrdFOv673rCsEo5KJHThI1X37LgrB8DPLJ/8+vxJf7zT9W1a9fGwcEBa2trFi9enGJb7969sba2xsPDg4AA5S7F7NmzKVy4MLa2tjRq1AhQKlhr166Nra0tLi4u3Lx5U62dVq1asXXrVtXy+0rjQYMGcfr0aezs7JgxYwaJiYn0798fJycnbG1tWbRo0SfjnzJlimrfESNGAEpiuUCBArRo0QIbGxtOnz6dYvnly5f0798fGxsbihQpwqZNmwClYtbV1ZWaNWtSuHDhb3xFFSVLlsQs+cuXi4sLr169Utvn6NGj5MmThxw5cgCwa9cuWrZsCUDLli1VSd8MGTLg5OSErq6u2jm+V0JCAtHR0SQkJBAVFUXmzJl/eBs/S93WXXGu5ElRt+osXbspxbZ+IyZQ1K06lRq0IiC5Umru0tXYlq1GMY+aNO3UB4DgkFDqtu5KMY+alK7ekJt3H6i107bXoBTVpu8rjYeMn86Zi944lq/NrMUrSUxMZNDoyZSoUo9iHjVZsmbjJ+OfNn+Zat9RU2YDSnWxdenKtO4xEDv3Gpy5eCXF8ku/1wwaPRk79xrYl6vB5l37ATh57iLutZtSp2VnbN2qfeMrqpAkiYjISGRZJiIyCnNTE1WS4+rN2/gHBFGhbKkUx6zauJ2B3TsAoKWlRXqLD4mHkZNn069rOwz09T7aZkJCItExMar3Y6aMGZBlmRNnLlC3eiUAmtevze6DXgDkzJYV28IFPvtH7FdUv0MfStRoin3F+ixdvz3Ftv5jpmFfsT6Vm3YiIEip4Ju3YgN2FerhWLkhzbv/A0BwaBj1O/TBsXJDytRpya17j9TaaddvBNv3e6mW31caD5s0h7OXr1G8amNmL1tHYmIi/4yfSalazXGs3JAl67epnevfpi9ardp39IyFgFJdXKScJ236DKdYpQacuXQtxfJLP3/+GT+TYpUa4FC5gaoa9+SFK5Sr35a67XpjV6H+N76iCkmC8Pfv26gozEyN0dHRJl/uHOTNpfzhzpzREksLcwKDQggKCUNPV4d8uZX+16O0CzsPKtV6e46cpKlnNSRJwtm+CKHvInj9Vv1OfURkFLOWreWfbu2+KEY764Jkzqh80CucPw/RMbHExv4eFT2eTdtQ3K0ytiXcWbJybYptfQaPwLaEOxVqNSAgUKlMmbNoGUVc3LAvVZ4mbZTEZHBICJ5N22BfqjwlK1Tn5u27au206dKLbbs+3LB8X2k8eNR4zpy/hINrBWbOX0xiYiIDho3BpVxV7EuVZ/GKNZ+Mf+rsBap9R05QnqjxefGSwk6utOrUg6Ily3H6/MUUyy9f+TFg2BiKliiHXUkPNm9XKsVOnDlH2Sp1qN24FUVc3L7tBf0CCQkJqn4xKiqaTFZWANjb2pAze7ZPHrtp2y4a1a2ttl6WZY6fOkvdWsrfieaN67Nrv/LkxtJV6+ncrhVmpqYAZLBMD8Dd+w9JSEiggnsZANKmTYORkfqNj19Vg54jKdmwKw512rNs6/4U2wZMXohDnfZUbTeQgOBQAOav26mqKm0xYDygVLA26DmS4nU7UbZpT249VK/u6TB0KjsOf6hQe19pPGzmcs5dvY1z/c7MWbOdxMREBk9bQunG3SletxNLt+z7ZPwzVmxR7TtmnnKz4LnvG4rWaEu7wZNx9OzA2au3Uyy/ehPA4GlLcKzTASfPjmw9eAKAU5dvUL5lH+p1H0GxOu2/6fVMzZYDx6lfxe2z++09fp6mNcsD0LRmefYcOw9ABgtTHG0KoPuZGyoSEu8iogClutfKUkm+lS1uh5GhAQDFbQvh6//hBsbVu494GxyCR0mHr76u/1qL+ccoP24PriN3svpUykrGYZsv4TpyJ3WnHyIwXHkqYMmxe5QeuZOyo3fTYclJAEIiY2kx/xhlR++mysR93HkVrNZO95Vn2OPto1p+X2k8doc3Fx754z5mNwu97pCYlMTIrVeoOH4vZUfvZtUp9c/I/zb30G3VvpN2XweU6uISw3fQdcVpyozaxYXH/imWfUMiGbn1CmVG7aLsqF3svPwMUKpla0w5QPN5Ryk9ctcnWv08S2ND7HOmTzUBVyK/FaZG+h89VpZldnv74OmUS23bjkvPqJO83j8sivDoeBxzWyJJEg1ccrP/uvoTE9suPaWaXXaymqdVxQbwLjqOC4/8aVpK+Zunp6ONiZHyufmJ/ztK5MsIQNlCmdl77fnXXP5/rsWsA3iM2ELpwRtZfSLl3/mh689SevBGPCftJjA5Ab74yE1KDd5I2aGbaD//CAAhETG0mHWAskM3UXn0Nu68DFJrp9uSY+y+/ES1/L7SeMyWC1x4+Bq3YZtZeOiG8j7eeI4Ko7ZSdugmVh3/dHXq3P3XVPtO2qE8sfUi4B0ug9bTdfFRXIds4vzD1ymWfYMjGLnxHK5DNlJm6CZ2XHwMwNl7vlQfv4NmM/dTavCnvxd+zgO/EEoXygJAvsxmvAwM521YFA/9QimWOyNG+rroaGtRskBm9nl/+Bs1dMNZRjRwQeLDd6bi+awwTaO87x3zWOEXHPlVsaQ10EWSlPNFxcaT/Ct6Otro6yrJu7iERJI+Ug3/q2iz4T6VF97Efe511l5J+QTJiAM+uM+9ToOVdwiKjAdg2YXXuM29Tvn5N+i8RemjQ6LiabPhPuXn36D6klvcfaP+Wvba8Zi9dz68h99XGo/3esGl5+FUWHCDxef8SEySGXPIh6qLblJ+/g3WXPZXO9e/LTjjq9p36jGlv3kZEoPr7Gv02P6IcvNucPHFuxTLfu/iGHPIh3LzruMx7zq7bit/L889C6POstu0Wn8ft3nXv+0FTZY+rS52WdKi+3+J5Izp9CiSWen70uprky+9IW/CU34PkmWZPXeCqFVE+Qx66H4ItWzSo6+jRXYzA3KaG3DNN+KLzvWtngbF4JJDuantmseE/ffU/47+aP95JfDy5csxNzcnOjoaJycn6tati4WFBZGRkTg6OjJjxgxGjx7NqFGjmDt3LhMnTuTZs2fo6+sTGhoKwIgRI7C3t2fnzp0cO3aMFi1aqKpdP2fixIlMnTpVVaW6ePFiTExMuHz5MrGxsZQqVYqKFSuSK5f6H9/Dhw/z6NEjLl26hCzL1KxZk1OnTpE9e3YePXrEqlWrcHFxwcfHJ8Xytm3buH79Ojdu3CAwMBAnJyfKlFG+3Fy9epXbt2+n2l7Dhg158ED9A1CfPn1o0aKF2vr3li1bRpUq6lV3GzdupHHjxqplf39/MmXKBICVlRX+/p/+Hz81Q4YMYfTo0Xh4eDBx4kT09ZUO/vz58xQtWpTMmTMzdepUrK2tyZIlC/369SN79uwYGhpSsWJFKlas+NVtasqS6eMwNzMlOjqGElXrU6dqRSzMzYiMiqJYURumjvqHsdPnMXbaXGaNH86UeUt4eOEo+vp6hCY/sjh66hzsbAqxbcU8jp+5QJseA7nitfOL2h83uA8zFi5n52rlRsXStZswNk7H+QNbiY2No2ytxpQvW5pc2bOqHXvkxBkeP/Ph3P4tyLKMZ6vOnL5wmWxZMvH42XOWz5qIs4MdPi9fpVjevu8QN+7cx9trJ4HBIZSsUh9XF6Uq99qtu1w7vifV9pp07M3DJ8/U1vfs2Irm9WunWNeldVM8W3Uhh30ZwiMiWbdwOlpaWiQlJTFg1CRWzpnCsdMfqnXev5YjJ8/i5LnL5M6ZjVnjhpHRMj3Xbt7hpd9rqpZ3Y/qCZam+jlkyZaR35zbkcSqHoYE+5cuWooJbaQKDQjA1MVYloLNkssL3zdsv+Jf5tS2aPAJzUxOiY2IoVasFdaqUw8LMlMioaIoVKcSUYX0ZN3sx42YtZubogUxduJL7p/Yo79vkR2fHzFhEUeuCbFk8nePnLtG273Au7d/wRe2PGdidmUvWsGPZLACWrt+Ocbq0nN21htjYONzrt6G8qwu5smVRO/bIqfM89nnBmZ2rkWWZuu17c/riVbJlseKxzwuWThuFs30RfF75pVjeceAoN+4+5PL+DQQGh1KqdnNKF1eqWK7fuY/3oc2pttes2yAePlX/stOjbVOa1a2eYl3nFg2p2743uZwrER4Zxdo5E9Qq4S5fv01cfDy5c2RFkiQSEhLxvnkXB9vC7DjgxavXbwDw839L1kwZVcdlyZQBvzcBZMqQ8k79qOkL6NWuGYbJyYd/W7B6M+u276OYbWEmDemN2b8q5AB2HDiKnU1B9D9xc+RXsnTuNMzNzIiOjsalXDU8a1bFwtycyMgoHO2KMn38KMZMnsGYSdOZPWUck2fO4/H188pnhTDlyYBRE6ZhZ2vD9nXLOXbqDK0798T79JEvan/8iMFMn7NQVTG7ZOVaTEzSceHYfmJjYylTuTYVypUlVw71O/WHj53k8dNnnD+6D1mWqd24FafOXiB7tiw8evKM5fNn4uLkgM+LlymWt+/ex43bd7h65giBQcG4lKuKa0kXAK7dvMWNc8dSba9xm048fPREbX2vrh1o3kj9ZseFy94UK12eTFZWTB4zDOtCBciSORN9unciV5HiGBoYUMG9LBXLlVU7NjVRUdEcOnqC2VPGqm0LCg7B1OTDjb2smTPh56e87x89Ub40ulaqRWJSIsMH9qVyeXcePXmKqYkx9Zq3w+f5C8qVdWXCyMFoa397Fel/aeHoPpibGBMdE4tr4+7ULl8aC1NjIqNjKGadn8kDOjF+4VrGL1zLjMHdmLp8E/cOrEJfT4/QdxEAjJ2/hqIF87J51khOXLxOuyFTuLhlwRe1P6ZXG2au2sr2uWMAWLZ1P8bp0nBmwxxi4+Io16IP5Us4kDOrldqxXue8efzCl9PrZyPLMvV6jODMlVtky2TJ4xe+LBnbj+JFC/Hc902K5Z1HTnPzwRMubl1AYOj/2rvrsCqy/4Hj70t3g4SAKIKCgYBioGJhd3d3rrl259oda7t2d2MrdhcqBqWAdMf9/TF68e7FVb7r6q6/83oeHpm5M3POXA9z537OZ86Jp2Lr/lTwKg7A7UfPuL57Za7ltR82lacvVZMWBrRvQtsGNXI9v+SUVE5cvM7cUTnDh8iA+j1HIZNB1+Z16dqsDgDv3sdgY2kOgLWFGe/eqw5X8leWThhEk75j0NHWxshAjzOb5qtss37PUfx9SwOQnZ3NyNkrWT1tOAGBt/JU1o+woGMFTPW1SUnPpOb0Q9TzdMDMQIfktExKOlowuUUZZh+8w+yDt5nRuiwLj97j+tSmaGuqE5csffmdtf82xe3N2NCnKucfh9Nv7QUCxjb4qvLHNPZi6YkH/NGvGgAbzj3FSFeT46PqkZaRRb1ZR/Bzs8XRwlBl34CHoQS/i+fYyLrI5dB+6WkuP43AzsyAF+/iWdTJF++ClryOSlRaPnDzFfdD3hMwtj7RiWnUnHaIci7S5++91+85O75BruV1X3mWZ2/jVNb3qu5Oy3KFVNb/r64EvcXSUJeC+YxUXtt7PZgNfaQM//CYZGw+yXa0NdUnIjZZZZ8Xb+PJyMqm0ZyjJKZm0L2qGy3LFeJVVCLmhtoMWH+RByExlHQwZ0rL0uhra+Jqa8KRO2+o4+HA/hsvCc1jwO57W9C1CqYGOqSkZ+I/cSf1vAsq2rFHAUumtKnA7H3X+W3fdWa2r8jCQ7e48Vs7qR0nScPBzdxzjeKOFmwYWJvzD0Pou/IUZya3+ELJkrHNy7Lk6B02/yJddzaceYihnjYnxjcjLSOLulP34FfMHkdL1f/TgPtvePE2juPjmiKXQ7sFR7j0JIz8Zga8eBvH4m5V8Xa25nVkvNLygWvPuf8mmjOTWxCdkIr/xF2Uc5W+0997GcW5qS1zLa/b0uM8C49VWd+7VklaVnBVWufuYM6hG8GUc7Xl5ou3vIlOIDwmiaL5zZi2K5D3ianoaKpz8u5rShaQ7leP3AzGxlSfYg4Wn32//jj3iGolPt+xPG1XIHP2XaeiW37GNi+rCPIeuvGCKTsCiUpIUbzXIGUet5l3iOB38YxvUe5fnQU8p2EhTPU0ScnIou7Ke9RxM8NMT5Pk9GxK2ukzsXYB5p15w9wzb5hatyBLLoRyeZAn2hpqxKVIQwTMCQihmLU+a1oX4cKLOAbuecaJ3rk//fpno6o7sPxSmCJLddP1txjqaHC4ZwnSMrNptPo+lZ2NcTBV/Z5x9lkswe9TOdSjOHI5dNrymCsv47Ez1iL4fSrzGzvjZW/Im5hUpeVDD6N5EJHMid4leZ+cQZ2V9xQBz3vhSZzuWzLX8nptf8rz6BSV9T3K2dLcI++ZzG9iUrkfkUQpO+UhaANfJWBpoElBc6mDLCIhDc/8OZ8BNkZaRMSnf9WxPrrxJpHqS+9gbajF2JqOuH7IFpYBrTc+Qga0885HO2/ps8fFSpdjj2OoVdSMgw+iCYtLy/P55dV3DwIvXLiQPXukcfbevHlDUFAQ5ubmqKmp0bJlSwDatWtHkyZNAChRogRt27alUaNGNGrUCIALFy6wa5eUPVa1alWio6OJj4//n+pz/Phx7t69q8gajouLIygo6LNB4OPHj1OqlBRMSExMJCgoCAcHBxwdHSlbtqxi20+XL1y4QOvWrVFXVydfvnxUrlyZa9euYWRkRJkyZXItC1BkDOdFQEAAq1ev5sIF5ceM0tPT2b9/P9OnT891P5lMpuhh+1rTp0/H2tqa9PR0evTowcyZMxk3bhyenp68evUKAwMDDh8+TKNGjQgKCiImJoZ9+/YRHByMiYkJzZs3Z9OmTbRr1y7P5/kjLF69kX0fMkNDwsJ5FvwKczNT1NTUaNFACrq3adqAFl37A1C8qCsd+g2lQa3qNKwl3eBevHqTbb9LWbhVfMvyPiaW+ITE/6k+J85e5N6jJ+w+KGVVxSck8OzFy1yDsifPXuTk2YuUriE92pyUnMyzF6+wt7PBMb8tPl4eim0/Xb509SYtG9WV2q6lBRXLleb67fsYGepTulTxXMsC2LxiXq7rc3P8zAVKuhfl+I71PH/5mjqtuuDr482mHXupVbUy+W2VvzhmZmYREh5BWe9S/DZhJPNXrGXEpFmsWTCDYRNn8Pv83Nv4RzGxcRw4doqngScxMTKkVY9B/LFrPzX9Kn51nf9Llqzbyv5jAQCEhEfw7OUbzE1NUFNTo3k9qROmdaM6tOo1DIBiRQrTadAY6vv70cDfD4BL12+zZdksAKqUL0N0bNz/3G5Pnb/CvcdB7DlyCoC4hESeBb/ONSh76vwVTp6/gk9dafiexORknr18jb2dNQ52NviUKq7Y9tPlS9dv06JBzQ/t1pyKZby4cechhob6eJd0z7UsgE2LZ3z1eZw4d5mSbq4c27yCF69CqNO+DxVKl8LIULohCH8XSZfB4/h9zkRFcHjjoukMmzyH9PQMqlUsi7ra1we17jx8wotXIfw2dggvQ8KUXuvRthmj+ndDJpMxYc4yRkydx8pZ4xWvP3z6nNEzF3Jww5KvLu9HW7RiDfsOSmNJvwkNI+h5MOZmZtL1tokUYGjbognN20tZ0cXdi9K+Rz8a1qlFw7q1ALh45SrbN0iZOlUr+RL9Pob4Dx0beXUi4Cz3Hjxi9z4pizIuPoGg58G5BmVPBJzlxOmzeFeS/r4Sk5J59iIYB3s7HO3zU7Z0Tobgp8sXrlylVdNGUru1sqRShbJcv3kHQyMDSnt65FoWwJY1y7/6PDxLFOfF3asYGOhzcbO88QAAbJNJREFU+PgpmrbrwuMbF4mJjWX/4WM8u30FE2MjWnbqyR/bdtG2Ze6Pa37q4NHjlPfxznUoiL+SmZnJsxfBnD64k5CwcKrUacLtS6fIzMzkwuWrXD93DIf8drTu0pv1m7fTpX3rLx/0X2DpH/s4cPoiACFvI3n+KhRzEyPU1NRoVlMKrLeuV41Wv0jj3Bcr7ETnX2dSv2p56lctD8ClWw/YMncsAH4+HryPjSc+8X8LxJy6dIP7QcHsOSFlDccnJPHsdWiuQdlTl25w6vJNyrboA0BScgrPXodib2OJg40VZUrmPN746fKlWw9oXruK1HbNTanoXYIb959iZKCHd3HXXMsClIZQ+FqHz16hrIe70lAQJ9fPxS6fBe+iY6nf81dcC9jj611caT+ZTKaUmfY1Fm3aw+4lUyhTogjz1u5gxG8rWTbxF8XrWw6e4uaDII6v/Q2AFdsOUNO3NPmt/5lHbb+1VacfcfjDkAWh75N48S4BMwMd1GQyGnkXAKThCDovl+4h3OxM6b3mPLVL2lPbQ7oeBT5/x5qefgBULGJDTFLa/zyG7JlHYTwMieHATakzNiElgxfv4nMNyp55GMaZR2FUnSLNlZGUlsmLdwnYmRlgb2aAd8Gc/4NPl68+e0uT0k6oq6lhZaRLOZd83HoZhaGOFqUKWORaFigP1/BP2n0tmMZlVL8X3giORE9Lg6J2ebzOZmdz93U0O3/xJzUjizozD+Nd0IKsrGzuvn7PtFY+eDlZMnrbVRYdvc+vDUuxoGMFRm0NZO6hO9QsYY/W3xjG5XtYdeIeh29KiSeh75N4ERGLmbO11I59nAFoVs6FToukpyzd8pvTa8VJ6ng6UdtTeq8DgyJY2096ErCiW35iklL/53YccP8ND99Ec+BD1nBCSjov3sblGpQ9c/8NZ+6HUGWcNDZ5UloGLyLiyG9mgL25Id7OOdfOT5cDgyJo7OMstWNjPcq72nI7+J3Ujgta5VoWwO99vj75amBdT0b9cQG/sdtxy29OcUcL1GQyXGxN6V+nFM1/O4CetibFHMxRV5ORnJbB/IM32TG03mePeeFRKH+ce8TB0bkPtTWmuQ/5jPVIz8xm8LozLDp8i6ENpeSjul4FqetVkEtPwpix+yq7hkv3gnbmBpyd0pKImCQ6LDxK/dIFsTJWfUT/32BNYARHPmR5hsWlExydipmeJmoyaOAuBc6blLCk2zYpCbBoPj367QqiVhEzahWRnkS5+jqeVS2lgL1vQWNikjP/5zFkzz6P5dHbZA49lLKGE1KzCI5OzT0I/DyWs8/j8F8uPYGfnJ5FcHQKdsZa5DfWxss+59r56fLVVwk0Km6BupoMSwMtyjoacSc0EQNtdTzsDHItC1AaruHvSkrLovu2p0ysVQBDHeXw5957UTQs9vlOi7wcC6C4jT5Xf/FEX1udU09j6LLlCRcHSrHDPV3dsTHSJioxg1YbHuJsoUvZAkbMbejM2CPBzD8bgr+rKZp/YxiXr/Vdg8Bnzpzh5MmTXL58GT09Pfz8/D47MdjHgOShQ4c4d+4cBw4cYOrUqdy7l/tET3+moaFBdnY2IPXMfzoRyafkcjmLFi2iZs2aXzymXC5n5MiR9OzZU2n9y5cv0ddX7nX68/Ln/NV2ec0Evnv3Lt26dePIkSOYm5srvXbkyBE8PT3Jly8n2yxfvnyEh4djY2NDeHg4VlZWX1Xnjz5mEWtra9O5c2fFJHJGRjkfPHXq1KFPnz5ERUUREBCAk5MTlpbSjViTJk24dOnSfyIIfPZSIKfPX+b8/q3o6elSvWl7UtNy76X52Hb3bVzB+SvXOHQigBkLlnPr9P6vKktDXYPsbOlxluzsbNIzMnLdTi6XM3/KGPy/IngpR87w/j3o3r6V0vqXb0LQ01P+oPzz8ufo/8XjuXnJBN6wbQ/D+nVHJpPh7ORIAYf8PHn2gis3bnMx8AYr1m8mMSmZ9IwM9PX1mTpqMHq6ujSuI93INK1Xi7VbdpGQmMSDx0HUaCr9bURERtGkUx92r1uKV8mcL4Onzl+mgH1+LM2lD9NGdWpw5fot2jSpT2xcvGLMzdDwCOys8/Y38W9z9sp1Tl8M5Ozutejp6lKjVY8vttu9axZw/upNDp86z8wlq7lx9Os6ozTU1ZWvuZ9rt8iZN2EYNSqX/+Ix5XI5w/p0pnsb5UDUy5Awlfb3V+3xa7fLSybwhp37GdqrMzKZjEIF7Clgb8uT5y8p7VGM+IREGncZyMShfZQC1WU9S3B6h5ShfuLcZZ4FS2XZ5rMiJDznSYzQ8HfY/imIEHjzLjfvPcTFtx5ZWVm8i35PjVY9OLF1Jfksc673XVo3pknXQYrlkPC3tOg5lNVzJlHI8a8f6f+3OHPhEqfOnOfC8QPo6elStV6zL7bbA9s2cO7SFQ4ePcH0uQu5ffHUV5Wleq/wuestzJ85hZrV/L54TLlczohf+tGjc3ul9S9fv0H/T9fXPy9/zl9tl5dMYCOjnJv0Ov7V6D90FFHR7zlz/iJOjg5YWkhtqXH92ly+ev2rgsDbdu/PdSgIAHMzU2Lj4hTX1ZCwcGw/dOzlt7WhjLcnmpqaODk6UNi5IEHPg7GztaFkcXcKFpCGTmlYpyaB12/CfyAIfO7aHQICbxGwcT56ujrU7DKM1M/cf35su3uWTObCjXscPhvIrFVbuLbrr4cl+0hdXZ1s+afX3Ny/BMrlcub82ocaFbxzfV1pW+QM7dqSbs2Vh3l6FRqB/p+eQPjz8ufo/cV2/0sm8I6jZ2nxp6Eg7PJJX+CszE2oX7UC1+8/xte7OFZmpoRHRmNjaU54ZDSWZiZfVWeAyPex3HvygjIligDQrFZlGvbOCVqfvnKTWau2cGzNbLQ/zGFw9c4jLt68z8rtB0lKTiE9IxMDPV0mD+r61eV+LxefRHDuUTiHR9RBT0uDRnOOkpaRleu2H9vq5v7VuBz0lmN3Qph/5B5nx31dxq+GmhofbmvJzpaTkZmd63ZyuZxprcpQ1T33jlrlbWFAreJ0rKScvfg6KhE9beWvt39e/py/2u57ZAJnZmVz6NZrTo5WDaLtvZYzFASAjake4TE5HUNhMUlYm6h+Ttia6mOqr4O+tib62pqUK5yPByEx+Djnw9ZUDy8n6V6jvqcjC49K37ELWxuzY5B0j/38bRwn76v+jf5bXHwUytmHIRwe0xg9bU0aTt/3xXa8ZXAdLj8J59jtl8w7cINzU1p+VVka6jLFcANfasfT2/lStfiXx/SUy2FgvVJ0rOKutP51ZPzfaMefH84xL5nAhrpaLOpW9UM95XgN/YMCVtJ3/HaVi9KustQJOGXnFWxNDXj5Lp7XkfH4jZUC2mExiVQbv5Nj45qSz0SPB2+i+WXNGbYOqYuZQe6fC9YmUlxEW1OdNr5FWHJUddK58q62DIiMJzohBXPDnHt6a1N9iuQ348rTcJUxhf8NLgXHcf5FHAe6FUNXS51max+Q9pk29LG7ckPbolx5Fc+JJzEsPBfKqT5fl/Grofantpr1mWEy5DCljhN+ziZfPKZcDv187WhfOp/S+jcxqehpKQct/7z8OX+13bfKBM7Iyqb7tic0LmFBHTfl+Fhmlpwjj95zpGfOdzVrQ23C4nLu28Lj07E20vrisT76NDBczcWUUYeCeZ+UgZm+JjZG0hPzFgaa1C5qxu3QRMoWMMLZUpctHaShYZ9HpXAqKG9PLf0vvuuYwHFxcZiamqKnp8fjx4+5ciVn1tjs7GxFNu7mzZvx9fUlOzubN2/eUKVKFWbOnElcXByJiYlUrFiRP/6QxpM6c+YMFhYWSoFHgAIFCnDjxg0A9u/fT8aHgIShoSEJCTmZQDVr1mTZsmWK158+fUpSUu7ZFjVr1mTNmjUkJkoZcKGhobx79+XHxStWrMi2bdvIysoiMjKSc+fOUaZMmS/ut23bNm7fvq3yk1sA+PXr1zRp0oSNGzfi4qLac7JlyxaloSAAGjRowPr16wFYv349DRvmbebq8HBpVkS5XM7evXspVkyaBCMiIkIxQ+3Vq1fJzs7G3NwcBwcHrly5QnJyMnK5nFOnTlG0aO6DZv/bxMUnYmJshJ6eLo+DXhB4M+dDKTs7m10fsnG37jlIhTKeUtsNC8evQlmmjR5KfEICiUnJ+Pp4sWW3lLVw9lIg5mamiszBjxzt7bh5Vxo/6sCx0zlt10CfhE8ygfz9fFmxfmtO230eTFKy6qNgADUq+7Ju624SP7Tt0PC3vItSHe/qzyr4eLFj/2Gp7Ua/58KV65QuVfyL+21eMY/rJ/eq/Pw5AAxgb2fD6fPSOH1vI6N4+jwYJwd7NiyZzfPrAQRdPc3MccNp16wh00YPQSaTUbdGFc5eksbNCrhwmaIuhTA2MiT8wRWCrp4m6OppfDxLqgSAQcoYDbx5h+TkFGm8yguXKeJcEJlMRuUKPor/y4079lK/ZrUvnuu/WXx8IqZGRujp6vLkeTBXb+V0omVnZ7P7Qzbutn1HKe/tIbXb8Lf4lSvN1BH9iU9IJDE5hQqlPdi6V8rKPHvlOhamJqrtNr8tt+4/BuDgybNkfAhIGOrrk5CY0y6rVyzHyj92Ktpt0ItXJCWrfsgDVK9Ujg3b95GYJO0fGvGOd1FfHiepQulS7Dx4/EO7jeHC1Zt4e7h/cb9Ni2dw9fAWlZ8/B4AB7G2tCfjQBt9GRhP04hVODnakp2fQotdQ2japR5M61ZX2+Vj3tLR05qxYT7e2UoCtXvVK/LFbGjog8NY9jA0NVIaC6NGuOcGBx3h64SCndqymsJMjJ7ZK4+p/On7w/mMBuLtIN7+x8Qk07jKQKSP6U97b44vn/28RH5+AqYmxdL19+kwKAH6QnZ3Nrg/ZuFt27qFC2TJSuw0No0rFCsyYMJq4+AQSk5LwLefD5h3SONhnLlzCwtxMKQgK4OiQnxu3pb+LA0eOf3K9NVC+3latzIo1G3Kut8+ek5SU+/XWv6ofa//YRuKH/UPDwpUmPfuciuV82L5nv9Ruo6I5fymQ0p88pfE5W9Ys58b5Eyo/uQ0FEfH2Xc7n841b0uezmSn2+e0IvH5TcV08ffYCRVwLf7HsuLh4zl28QoM6uXeky2Qy/CqWV/yfbdyygwa1peBCg7q1OHtBGuonKvo9Qc9eULCAA6U9PYiLi1OM9xxw/iJFXf+ZCXe+tbjEJEwMDdDT1eFJ8Guu3n2keC07O1uRjbvtcADlS7mTnZ1NSEQklct4MGVQV+ISk6Rrrmcxth6Sxgw/d+0O5qbGGBkoJw042uXj1kNpfPaDZ66QkSldcw309UhMyrmmVq/gzartBxXX5KCXISQl556AUb28Nxv2HCPxwzU59G0U76Jjv3je5T2LsevYWantvo/lwo17eBd3/eJ+G38bTeCOZSo/nwsAxyUkceH6XepVyelETEpOJeHD32JSciqnLt/AzbkAAHX9yvLHfukJrj/2n6RelXJfrNNHpkaGxCcmEfQhSH3q8k1cnaSOtNuPntF/0kJ2LJyIlbmJYp+1M37l6fFNPD66gWlDutOmfrV/ZQAYpDFhTfS00NPSICgijhsvcj5HsuVyRTbu7qsv8ClkRXa2nND3yfi62jCuqRfxKekkpWVS1tmKXVeloV0uPonAzEAHQ13lYYfszfW580r6ez569w0ZWVLgw0BHk8TUnI63Km52rDv7RPH687dxJKXl3jFXxd2WLRefKfYPj0lSmvTsc3yc87H3+kuysrOJSkjlStBbShX4ckBhVY/KBIxtoPLzLYeCOPconMLWxtj+6XH27Gw5+268pNEnQeB8xnoY6mpy/UUkcrmc7VdeULukakdvrZL2XH32lsysbJLTM7kZHEVha2PyGetia6rPswgpsH3ucTguNiYAivcxO1vO3MN3VQLt/yZSO9ZGT1uToLAYbjzP6VDPlssV2bi7rgThU9haasfRifgWtWNc87JSO07NoKyLDbsuS2OuXnwUipmBrmo7tjDi7kvp7+TorZc57VhXi8TUnKBR1eIOrDv9gIxMKRj9PCL28+24uD2bzz/+pB0nEhmf+73Fp8q62LD36nOpHcencPlpGKWc8n1xv9/7+HNmcguVnz8HgAHiktJI/3AOm84+opyrjeI9+VjHkOgEDl0PpmnZwrjZm/NoUWduzmnHzTntsDU14NTEZuQz0SMkOoFOi46ypEc1ClmbfLZ+EbHSfZNcLufwzWCK2EkJOy/exinuXe68jCQtIxszAx3C3ieSki59tsUmpRH4NBznvzj+j5SQloWxjga6Wuo8i0zhZkhOPCpbjiIbd8+9KMo4GJGdLScsLo0KTsaMruFAQlomSelZ+Dgasftuzri6ZnoaKhmp+U20uRcmvZfHn8QogsAG2uokpeV0klR2NmHDtYica25UCsnpuXei+DmbsO3WO8X+4fFpRCXm3q4/5eNoyP77UWRly4lOyiDwVTwenxlG4VPLW7hwondJlZ+8BIDlcjlD9j3H2VKXnuVV56E6/yIWZwsdbI1zxmn3L2LKvvtRpGVm8/rD0Bal7Ay+eKyP3iWkK9rqrZAEsuVyTPU0SE7PIvHDe5ecnsXZ57G4WkmdGB/fx+xsOQvOhdDeO/enp76l75oJXKtWLZYvX07RokVxdXVVGj5BX1+fq1evMmXKFKysrBRB03bt2hEXJ/3hDxgwABMTEyZMmECXLl0oUaIEenp6ikDmp7p3707Dhg0pWbIktWrVUmTclihRAnV1dUqWLEmnTp0YOHAgL1++xNPTE7lcjqWlpWKCtD/z9/fn0aNHlCsn3UQaGBiwadOmL45T17hxY8UYuTKZjFmzZmFtbc3jx4//x3dS1aRJk4iOjqZPH+kRPg0NDa5fvw5AUlISJ06cUJn07tdff6VFixasXr0aR0dHtm/fDkhBXG9vb+Lj41FTU2P+/Pk8fPgQIyMj6tSpw++//46trS1t27YlMlK6+fDw8GD5cumR1J07d7Js2TI0NDTQ1dVl69at0oRHPj40a9YMT09PNDQ0KFWqFD169Phm78E/qWaViqzauJXilergUsgJH8+cnjh9PT2u377L9AXLsbIw44/l0oSDnfoNJy4hAbkc+nZpj4mxEWOH9KP74NF4VmuAnq4uqxeoPn7etW1zmnbui1f1hvj7VVRkgBUv6oq6ujpe1RvSoUVj+nfrwMs3oZSp2QS5HCzNTdm5JvfHvWv4+fL42Qsq1pcygQ309Vi36DfUv/C4QaPaNQi8fhuv6o2QyWDamKFYW1ny5JnqJDX/q1GDetNt0EhKVa2PXA5TRw9VmugtN9PGDKFz/xEMGT8NS3MzVs2d9pfbh0W8pdfQsezftJIyniVpUtefMjWboKGhgUexonRrJ2UBTBs9lHa9BzNh1gJKFitK59bNALh++x7Nu/YjJjaeQycCmDR7MXfOHPyrIv8V/CuXZ9XmXZSs3hSXgo6U+SSAr6+ny/U7D5ixeDWW5qZsWjSDrKwsOv8yhviERORy6NOpFSZGhowZ1JOewyfiXaslero6/D57okpZXVo1pnmPwZSu3Qr/yuUVGbfFizijrq5G6dqtaN+sPv06t+ZVaBhl67dFLgcLMxN2rJiTa/1rVCrHk+fBVG7aCQADPT3WzJv8xWtuw5pVCLx5l9J1WkvtduRArC0tePL85f/2RuZiZP/udB86Hq9aLZDLYcqIAViYmbJ5z2EuXL3J+5g4Nu6UOnxWzZ5ASTdX5q3cwOHT58nOltOjXTOqlJc6A2tV8eVowEXc/BpKs83PmqAop0yd1l8cf3nU9IXcffQEGTIc89uyeNooAJat38bzV2+YtnAV0xZKwyIc3LAEKwuzb/Y+/BNqVvNjxZqNFPOpjItzIXy8PRWv6evrcfXmLabNXoClpTlb1iwnKyuLDj36Ex+fgFwup1+PLpgYGzPu18F06zeEUhWqo6unw5ql81XK6tahLY3bdsbTtzr+1aqgry9db0u4F0VdXQ1P3+p0aNOCAb268fL1G0pXroVcLsfCwozdm9bkWn//qpV5/DQIX38pS07fQI8NKxZ9sd02qleby1dv4OlbA5lMxoyJo7HOZ8XjoGf/4zupate+Q6xYuwENdXV0dHX4Y/VS6fPZ25MmDepS2q8mGuoaeJRwp3vHtoA06d7shUuJeBtJKd/q1K5RlZULpSd/9h46Qo0qlRTv20f1mrdn5cLfsLWxZvqE0bTp2odxU2fhUcJdMaxDzWp+nAg4S/GyfqirqTNz0ljMzaS2OXPyOPwbtkQul+PpUZxuHdt8s/fgn+RfwZvftx+iVMNuFC6QnzIlcjq69XV1uH7/CTNXbsbSzIQNv40iKyubLqNmEZ8gTTLZp00jTIwMGN27Hb3GzaVM017o6mizaspQlbI6N61NiwET8GnWixoVvBWZucULS4+6+zTrRbuG/vRt24hXoRGUb9lXartmxmybPyHX+lcv78WTF6+p0m6QVGc9XdZMH4662l/fKzSsVoGrdx7h06w3MpmMqb90xdrCjKfBqhNV/R37T1+kWnkv9PVyssjevY+h1SDpMykzK4sWtasoxugd0rUl7YdOZf2eozjYWLFxtpTJGxH1Ht9W/UlISkZNTcbiTXu5uXclRgb6NOozhqUTfsHWypzF4wfRZvBk1NRkmBgZsnySNMnv6LmrSEpOoe1QaRxse2srdi5S/Vz8N6vqbsf6c0+pMH4vhfIZ4fXJ8Al62hrcDI5i3uG7WBjqsLJ7ZbLkcvqsOU9CSjpyoHvVohjraTGsvgcD11+k8qT96Gmps6hTBZWy2lV0oePS0/hN3k9VNztFRqNbflPU1WT4Td5Pq3KF6FHVjTfRiVSfcgA5YG6gw/o+VXKtfxU3O4LC46g78/CHOmuytKsv6rK/bqt1Szlw/UUkVSYfQAaMa+JFPmNdRTD0W3gbl4L/tIMkpGagJoOVpx5xYUJDDHW16Pn7WS4+ecv7xFRKjtjB8PoetPWVOtz2XFfO9v3octBb7Ez1KWCp3Ik5s3VZBqy/SEp6JtWK2VGtmJRBve6s9BRpp8quuNiYUMXdDr/J+1GTyWhbobBiSIlprXzovfo86VnZOFoYsLCj9H+351owa848Ubxfrcs7f7P35lurWtyBdQEPKD9yC87WJngVygmESu34HXMP3MDCSJdVvf3Jys6m98pTUjuWy+levTjG+toMb+TNwNUBVB6zDV0tDRZ3r6pSVvvKRemw4Ah+Y7dTtbj9J+3YTGrHY7fTyteVHjVK8DoqnmoTdiKXyzE31GXDgFq51r9KMXuehsVQZ4rUYa2vrcnSntVQ/8IQjXW9nLj+LAK/sduRyWSMa1GOfCZ6PAv/dhmET8Nj6LfqNDIZFLEzY36XnL/FzouPEZOYhqa6GjM7VMRY//OTHQLM3nedmMRUhm84B4CGuhonJ0jfsVrNPcT8zn5Ym+rTe8VJohNSkcvlFHOw4LeO0jAsB6+/YPvFJ2ioq6GrpcGqPtJ90tOwGMZvvYRMJkMul9O3tgdu9rlnaP5ofs4mbLz2lsqLblPIQkdp3Fk9LTVuhSay4FwI5vqaLG/uQpZcTv/dz0hIzUQOdPGxwVhXg8F++Rmy7znVl95BR1ON+Y1V/z7belnRecsTqi+9QxVnE0XGbdF8eqipyai+9A4tPCzpVtaGN7Fp1Fp+FzlgpqfJmta5d/pUdjYhKDKFBr/f+1BndRY1LYz6XzdVahc148YbaTI6GTDa3xErQy2eRX250+5rvUtIp/bKeySmZaEmg1VXwjnTtySP3iaz604URfPpUWOZlMD3azUHqrlI18B993MmhPvI1UqP+u7mVFl8G3U1GVPrOqGuJuPqq/jPHmvDNWmuiw6lrTn0MJoN196iriZDR1ONpc1ckMlkRCZm0HWrdF3NypbTqLgFVQpL9dh7L4p1H45Rp6gZLUv980NKyT5Gqv+Rg8tk8n/y+MLP68PFPG+Dt33b8uXpYd8uSC/8/6BlW+SHt9vU4Bs/qnjhP0rHyeuHt9vMmNAfVbzwH6ZhavfD227y3WM/qnjhP0qvRM3v3m5lMpn83YqO37NI4Sdn1XP9D2nHket6f88ihZ+AZadlP6Sthk78+qdPBOGv2I2//E3b8HcdDkIQBEEQBEEQBEEQBEEQBEH4vr7rcBD/Fffu3aN9e+UJXbS1tQkMDPxBNRKEr3Pv0RM69x+htE5bW4uLh7b/oBoJwpfdfxxEl8HjlNZpa2lyfu+GH1QjQfiyew8e0anXAKV1WtraXD757x8qRvj/7f7TYLqOnqW0TltTk3ObF/6gGglC7h6GxtB3zXmlddoa6hwdWfczewjCv8/DN9H0Wak8Ya22pjrHxn158lVB+J4evU1iwG7lYci01dU42OPLcwIJ/x1iOAjhX0kMByH8F4nhIIT/IjEchPBfJYaDEP6LxHAQws9ADAch/FeI4SCE/zoxHMS/lJ+fn2Iitu9l9OjR2NvbY2CgPMPi3LlzcXNzo0SJElSrVo1Xr14pXhs+fDju7u4ULVqUAQMGKGYvTE9Pp0ePHri4uFCkSBF27dr1Xc9F+PGqN23PjTv3vlt5yckpNGzfk2IVa1PSrx6jpipPDrZj/xFKVK5LSb96tO8zRLG+XptuWBYpTaMOPb9bXYV/lxqtenDj7sMfUnbTbr/gWbOFYvnOwydUatyRMnVaU75BO67dvg9ATFw8LXoOwbtWS3wbduDBE6lX/enzl5Sp01rxY1m8EovWbP4h5yJ8f1XrNeP6rTvfrbzk5BTqt2iPe5lKlChXhZETcibRTEtLo3WXXrh6VqBc9Xq8fC1N4pWenk7Xvr/gUb4anr7VOXPhkmKfrTv34lG+GqUqVKdOs7ZERb//buci/DvU7DKMGw+efrfyEpKS8WneW/FjX6k5w2YuA+BN+DtqdR1G2RZ9KNO0F0fPX1Xsd+/pC/zaDcKrcXdKN+lJalr6d6uz8O/UaM5Rbr+M+q5lTtt7E49fd1BgwB9K69edfULlifuoMnk/9WYd4UlYrOK1BUfuUWbMbsqN28PpB6KD9P+7htP3cTv43XcrLzElHb+x2xU/rv3WMvqPCwC8iUqgycz9VB6zjYbT9xH2PhGAe6+iqD15N76jtlJ5zDb2BH67CW2F/65max9wJzTxu5aZnpnN8P3P8V14i0qLbnHoYTQAG65FUG3JbWosu0Oj1fd5+i4ZgFsh0qR1NZbdofrSOxx5FP1d6/ujiOEg/sPq169Pv379KFy4sNL6UqVKcf36dfT09Fi2bBnDhw9n27ZtXLp0iYsXL3L37l0AfH19OXv2LH5+fkydOhUrKyuePn1KdnY279+LL3bCP++XXp3xq1CW9PR0arbozNHT56hVtRJBL14ya9FKzu7bjKmJMe+ici7Ig3t3JTklhd83bfuBNRf+P9p79DT6+rpK60ZNX8DogT2o6VeBowEXGDVjISe2rmTWkjWUcHNl+4o5PHkezMBxMzn6x3JcChXg6uEtAGRlZVGwbG0a+Oc++7kgfAuD+/eiSsUKpKenU6NhS46cOE3tGlVZs3ELpsbGPLl5kW279jFywlS2rFnO7+ulTonbl07xLjKKes3bceX0YbKzs/ll5DjuXTmDhbkZI8ZNYcmqtYz/dcgXaiAI/ztDfT0CdyxTLJdv2ZeG1XwBmLFyM038K9GjZX0ePX9F475jeXx0A5mZWXQdOYvfpw2jhGshomPj0dRQ/1GnIPw/5l/Cnq5ViuAzdo/S+qZlnOhU2RWAo3deM27HNbYNrMGTsFj2XA/m/PiGRMQl02zeca5Mboy6msjbEr4PA10tzkzOSXaoNn4Hdb0LAjB+6yVaVHChlW8Rzj8MYcqOQJb2rIaetgaLu1elkLUJETFJVJuwk6rF7DHW1/5RpyH8P7XwXCjm+ppcGFCK7Gw5sSmZADQubkGH0tYAHH/8nonHXvJHezeKWOlxpEcJNNRlvE1IlwLCLmZoqP+wh8y+i582CJyUlESLFi0ICQkhKyuLsWPH0rJlSyZNmsSBAwdISUmhfPnyrFixAplMhp+fH6VKleL8+fMkJSWxYcMGpk+fzr1792jZsiVTpkzh5cuX1KpVCy8vL27evIm7uzsbNmxAT09Pqezjx48zfvx40tLSKFSoEGvXrsXAwIBff/2V/fv3o6Ghgb+/P7Nnz/5b51i2bNlc11epUkVpm02bNgHSEAupqamkp6cjl8vJyMggX758AKxZs4bHj6XhD9TU1LCwsPhbdRP+vqTkZNr0/IWQ8AiysrIZNag3LRrWYcrcJRw6EUBKahrlvD1YOmsSMpmM6k3b41HMjQuB10lKTmHtwpnMXLSSB4+f0qxBbSaNGMTLNyHUa9MdzxLu3Lr3EDdXZ9YumImennJg68SZC0yas4i0tAwKFrDn93nTMNDXZ9TUORw8fhoNDXVqVKrAzPEjPlP7L9PT08WvgtSGtbS0KFXcjdDwCABW/7GD3p3aYGpiDICVhbliv6oVy3H2khif+98kKTmFtv1GEBr+jqzsbEb270bzev5MXbiSw6fOk5KaRlnPEiyZNhqZTEaNVj3wcHfl4rVbJCWnsHrOJH5btpb7T57RrK4/E4f24WVIGA069qNU8aLcvv8Yt8KFWD13Inq6f2qr5y4zZf4K0tLTKeiQn5W/TcBAX48xMxdy8OQ5NNTVqV6xLDNG//K3zjExKZkFqzexdNoY2vb7VbFeJpMRn5gEQFxCIjb5pGvno2cvGNqrMwCuhZx4FRLG28ho8lnmtOXTF6/i5Jgfx/w2f6tuwv8uKSmZVp17EhoWTlZWNqOHDaRFk4ZMnjWPQ0dPkJKSSjkfb5bNm4lMJqNqvWZ4lHDn4uWrJCUns3bZAmbOW8z9h49o3rgBk8eM4OXrN9Rt1hbPkiW4dfcebkVcWLdsocp19vjps0ycMZv0tHQKOjmyevE8DAz0GTlhGgePHkdDXYPqVSvx2+Rxn6n9l+np6VKlYgVAus56lixOaFg4APuPHGfciMEANG1YlwHDRyOXy3n05KliHytLC4yNjbh+6w6lShRDLpeTlJSMuZkpCQkJOBcs8D/XTfg2kpJTaTdsKmFvI8nKyubXnm1oVsuPacs3cfhsIKmpafh4uLF43EBkMhk1uwyjZJFCXLx5n+SUVFZNHcbs1dt4EBRM05qVmdC/E69CI2jYezSl3Apz+9EzihZy5Pepw9DT1VEq++SlG0xZupG09AwK2tuwYvIQDPR0GTt/NYfOXEFDXZ1q5TyZPrTHNznXoJchRL6PpYJXMUC6/iYkSdk88YlJ2FiaSfW6fINiLk6UcC0EgLmJ0TcpX/i2ktIy6L7yLGGxyWRnyxlcpwSNSjsx++Adjt99Q2pGFqULWjK7XTlkMhmN5hyluL0ZV4LekZyeyeLOviw4co9HYTE08irAyEaevI5KpNXCE5RwNOfe6/e42pqwuLMvelrKX3kDHoYya/8d0jOzKGBpyIKOFTDQ0WTy7hscu/sGdTU1/NxsmNis9N86R++ClrmuN9TVUvyenJaJTCYFHI7eeUNjbye0NdVxtDDEycqIm8FRlC5k9bfqIXw7SWkZdFtynPCYJLKysxncwJvGPs7M3nedY7dfkpqeSWlna+Z0qoxMJqPh9H0Ud7TgytNwktMyWNK9GgsO3eRhyHsalSnEqKY+vI6Mp+WcQ5QsYMndV5G42pmxpHtV9LQ1lcoOuP+GWXuukZaZRQFLIxZ2q4qBjiaTtl/h2O2XaKjJ8Ctmz8RW5b/JuT6PiCUqIYVyLtJ96tOwGCa3lu4PfIva0WHhUQAKWZso9rE21cfSSJeohBQRBP6XSU7Pouf2p4THp5MtlzOwcn4aFrNg3pk3nHgSQ2pmNt72hsysXxCZTEaztQ9wt9bn6ut4ktOzWdDEmcXnQ3n0NpkGxcwZUc2BNzGptN30iBI2BtwLT8LFSpeFjZ3R1VLueD37LJbZAW9Iz5LjaKrNvEbO6GurM+3EK44/iUFDTUalQsaMq1ngb53j1lvvONffAwA1NRlm+tLfkKFOzmdAckY2MqRr7qf1TMvMWf+z+2mDwEePHsXW1pZDhw4BEBcXB0C/fv0YN076QtW+fXsOHjxI/fr1AekL0vXr11mwYAENGzbkxo0bmJmZUahQIX75RQogPHnyhNWrV1OhQgW6dOnC0qVLGTp0qKLcqKgopkyZwsmTJ9HX12fmzJnMnTuXvn37smfPHh4/foxMJiM2NlalzgEBAYpyPqWnp8elS5dU1n+N1atXU7t2bQDKlStHlSpVsLGxQS6X069fP4oWLaqoy9ixYzlz5gyFChVi8eLFigCx8GMcCziPTT4r9m1cAUBcfAIAfTq3ZczgvgB06j+cQycCqOdfFQBNTU2uHN3Fot830LRzH64c3YWZiQlFytdgYHdpLLinz4NZOWcq5ct40v2XUSxfv5nBvbsqyo2KjmH6guUc3bYWfT09flu8ivkr1tG7Uxv2HTnB/fNHpDYcF69S5zMXrzB0/AyV9Xq6Opw7sPWz5xobF8+hEwH069YBgKAXLwGo3KA1WdnZjB3Sj5pVKub1LRS+k+NnL2FjZcneNdKkQh/bau8OLRk9QPry3/mXsRw+dZ661SsBoKWpyaX9m1i8djPNewzm0oFNmBkb4+bXkAFd2wDw9MUrls8cR3lvD3oMn8iKjTv4pUcHRblR72OYsXg1hzctQ19Pl9nL17Fg9SZ6tW/BvmNnuHtql9RWP9TnU2cuX2P45Lkq6/V0dTiza63K+olzlzGoWzt0/xQEmT1uKPU69uXXafORZ2cTsFPat3hRF/YdO41vmVJcu32f16ERhEa8UwoC7zh4nJb1a379Gy18c8dOBWBrY82B7RsBiPtwXevbvRNjh0ufxx179ufg0RPUr+0PgJamFoEBR1i4/HeatO3C1YAjmJma4OJZnkF9ugPwJOg5KxfOoULZ0nTrN5hlq9czpH8vRblR0e+ZNnsBx/dsQ19fj1nzlzBv6Ur6dOvIvkNHeHD13IfrbJxKnQPOX2ToqAkq63V1dblwfP9nzzU2Lo6DR0/Qv5d0vQ8Li8DezhYADQ0NjI2MiH4fQ4libhw4epxWzRrxJjSMm7fvERIaRhmvUiyZMx0P32ro6+nhXNCJRbOnfbY84fs4cfEaNpZm7FkyGYC4BKlTqlfrBozq1Q6ArqNmcfhsIHX9PnS8ampwcetilmzaQ4uBE7i4dTFmxoa41+lM//ZNAHj6MoRlEwdTrpQ7PcfNYeW2Awzq1FxRblRMHDNXbubQyhno6+kwZ802Fm7YRc9WDdh/6hK39//+4fqr+ijo2au3Gf7bCpX1ejraBGyc/9lz3XH0DM1qVlYEzEb3bkeDnqNYtnk/ySmpHFwl3X88exmCTCajQa9RRL6Po3mtygzu0uKzxxV+jNMPwrA20WNz/+oAxKdIQ3Z0rVKEofVKAtBnzXmO3w2hZkl7ADTV1Tkxuh4rTz2kw9LTnBxdDxM9bcqM2U3P6m4APHsbz7wOFfBxtmLg+ousPfOYvv7FFOVGJ6Yy79Bddv5SA31tTRYevcfykw/p4ufK4duvuTSxETKZjLhk1SFELjwJZ+z2ayrrdbU0ODyiTp7Of3XAY5affEBGVja7f5HuBcJjk/Byygkc25rqERGbnKfjCv+s03dfY22iz5bB0uSE8clpAHStVoyhDb0B6LPiFMdvv6JmqQIAaGmocXJCM1Ycv0v7hUc4OaEZpvo6lB7+B71qSm39WUQs87v64VPYhgGrA1h7+gF9a3soyo1OSGHu/hvsHF5fareHbrH82B26VCvG4ZsvuDy9tdRuk9JU6nzhUShjNl9UWa+nrcHhMU0+e657Ap/RqIyz4prr7mDOwRsv6OlfgkM3gklMzeB9YipmBjn3xjdfvCU9MwsnK+M8vKvC9xDwLBZrQy02tisKQHyqlCXbqYw1v/hJ19j+u4I48TQGf1epU1VLXcaRniX4/XI4XbY85kjPEpjoalB+wS26l5M6B55HpTKnYSFKOxgxeO8z1l97S68Ktopy3ydlsOBcCNs6uqGnpc6S86GsvBxGxzLWHHn0nnP9PaS2+yFr91MXg+OYcPSlynpdTTX2d1OerO7j/rNOv+Hyy3gcTbWZWtcJSwOp021dYAQrL4eRniVneyc3xX43QxIYsvc5IXFpLGzi/NNnAcNPHAQuXrw4Q4YMYcSIEdSrV4+KFaUAUkBAALNmzSI5OZn379/j7u6uCAI3aNBAsa+7uzs2NlLDLliwIG/evMHExAR7e3sqVJB6wNq1a8fChQuVgsBXrlzh4cOHim3S09MpV64cxsbG6Ojo0LVrV+rVq0e9evVU6lylShVu3779zd6DTZs2cf36dc6ePQvAs2fPePToESEhIQDUqFGD8+fPU7RoUUJCQihfvjxz585l7ty5DB06lI0bN36zugh5V6yICyMmzmTklNnUreGHr490Y3HmUiBzlq4mOSWFmNg43FycFUHg+h/+LVbEBTeXwtjkkzIHnBzseRMWgYmxIfa2NpQv4wlAm6YNWLx6o1IQOPDmbR49fUblBlIgLj0jg7JeHhgbGaKjo02PwaOpU8OPutX9VOrsV6Es10/uzdN5ZmZm0r7PEPp2bU9BR+kDKCsrk2fBrzi5awMh4W+p1rgdN0/vx8RYZPP8GxVzdWbE1HmMnrGQ2lUr4lumFABnL19n7or1JKemEhMbj5tLQUUQ+OO/7q7OFC1cCBsr6UtPAXs7QsLfYmxkSH7bfJT39gCgdaPaLF23VSkIfPXWPR4/e0GVZl0Aqa36eJbA2NAAHW0teo6YRJ2qFalTVbUDwa9cacWwDF9y5+ETXrwK4bexQ3gZEqb02spNO/htzBAa167GzoPH6fXrJI5sWsawXp0YMmk2Zeq0xt3VGQ93V9TVcx7nTE/P4NDJs0we1u+r6iD8M4q5FWHYmEn8On4qdWtWp2J5HwDOnL/EbwuXkZKcwvvYWNyKuCqCwB//LeZWBLciLthYSx2mTo6OvAkNw8TYGHs7WyqUlTLI2rRowuIVa5SCwFeu3eDRk6dUqtUQ+HCdLe2FsZEROtradO8/hLo1q1O3ZnWVOlepWIEb50/k6TwzMzNp27Uv/Xp2oWABx7/ctnO7Vjx6GoRPldo42OenXBlv1NXVycjIYPmaDVw/e4yCBRwZOHwMM+YtYvTQQXmqi/BtuRd24tc5qxgz73dqV/Khgpf0pejc1TvMXbuDlNQ03scnULSQoyIIXNevnGJft0KO2HzonHLKb01IRCQmhvrkt7akXCl3AFrXrcbSzXuVgsBX7z7i8YvXVO0odZZkZGRSpmRRjA300dHWpNf4udSu5EOdyj4qda5cxkNpiIevtfPoWX6fNlyxvOPIGdo1rMHAjs0IvPOQbqNmcX33CjKzsrh08z7ntyxCT0ebOt1/pZRbYaqULZXnMoV/jpudCRN2XmPSrhv4l8hP2cLStfTCkwiWHLtPSnomMclpFLE1UQSBP/5b1M4UV1sT8hlLT2M6WhgQGpOMsa4Wdqb6+DhL97/NfAqy6vQj+vrnlHvjRSRPw+OoN+sIABlZ2XgXtMRIVwttTXUGbbhEjeL58S+RX6XOvq42BIxt8E3Ov2uVInStUoRdV18w9/BdFnf2/SbHFf5ZbvbmjN96mUnbL1OjpCPlXKVg14VHoSw+cltqt4lpuNqZKoLAH/91y29GETszrE30AXC0NCI0OhFjPS3szAzwKSzFHpqXK8yqE/eUgsA3nr/laVgMdadIQ4tkZGXjXSgfRrpa6GhqMHDNGfxLOuLvofoZ71vUTmmIh6+1J/AZS3tUUyxPbFmeXzedZ+uFJ5RztcHGVB91WU7ALCI2iT4rT7G4W1XU1H7+QNp/TRErPSYde8XU46+o7mqKj6P0vfrSy3iWXQgjJSOL2JRMXK308JdGq8G/iKm0bz49XCz1yGcoBVQdTbUJi0vHWEcdW2MtSjtIx2pSwpI1geFKQeAbIYk8jUyh4Wpp3pSMLDle+Q0w0tZAW0ONIfueU93FlOoupip1ruBkzIneJb/q/LKy5YTHp+Ntb8iEWgVYcSmMScdesaipNHRqJx9rOvlYs+duJAvOhrKgiTMAnvkNCejnQVBkMoP2PKOKsyk6mj/3EDw/bRDYxcWFmzdvcvjwYcaMGUO1atUYPnw4ffr04fr169jb2zNhwgRSU1MV+2hrS48sqKmpKX7/uJyZKfUsyGTKF7Q/L8vlcmrUqMGWLarBhatXr3Lq1Cl27tzJ4sWLOX36tNLr3zIT+OTJk0ydOpWzZ88qzmXPnj2ULVtWMZFc7dq1uXz5Mr6+vujp6dGkidQT2Lx5c1avXp2n8oRvz6WQE4HHdnPk9DnGz5xPFd9yDO3TjQEjJ3H5yE7s7WyYNHsRqWk5Pb7aHx4bUlOTKX7/uJyV9fVtuFql8mxappoleenQDk5fuMzug8dYtvYPju9Yr/T6/5IJ3HvYOJydHBnQPWfWajsba8qUKoGmpiZODvkpXKgAz4Jf4e1RPNdjCD9W4YKOXDn4B0cDLjJhzlKqVCjNkJ4dGTh2Bhf3b8Te1prJ81coTcyjrSXdREjX20/bqhqZmVkAKo/kqLZVqOpblo0LVbMRL+zdQMClq+w+coplG7ZxbLNy1lleMoEDb97l5r2HuPjWIysri3fR76nRqgcntq5k0+6DzBk/DICmdWvQe+QUAIwMDVj124QP9ZTjWrE+TvZ2imMeO3MRD/ciSpnBwvfn4lyIa2ePcuT4acZNnUXVyr4MG9CbfkNHEXj6MPb57Zg4Y86frrOftF2tnEd6ldruV1xnq/tV4o/VS1XqdPnUIU6dvcDu/YdYsmotJ/fvUHr9f8kE7jVoOIULOTGwd3fFOltba96EhpHfzpbMzEzi4uMxNzNFJpMxd9pExXa+/g0oXKggt+89AKCQUwEAmjWqz6z5S3ItT/h+ChfIz6Vtizl2/hoTF6/Hz8eDwZ1bMGjqYi5sXUR+ayumLN2odP3V0sq5V/j4u7SsRmbW17ZhqFrWk/WzRqrU6dzmhQQE3mbPifOs2LKfI6tnKb3+v2QC333ynMysLDzdcubBWL/nKPuWTQXAp6QbqWnpRMXEY5fPEl+v4liYSploNSuW5vajZyII/C9TKJ8xJ0fX5+S9EKbvu0XFIjb0q1mMEZuvcGJUPezM9Jl14DapGVmKfbQ1pC/majIZ2p+M8yzd52YD8KemqrIsl0NlNxtWdKusUqdjv9bl/ONwDtx8xZozj9k9WPlpnW+ZCfxRY28nhv9xBQAbE33CYnIyf8NikrE20fvcrsIPUMjahFMTm3Hy7mum775KJbf89KvtwYiN5zkxvhl25gbSkA1K7VZqq2oyGVqftluZjKzsz7Vb1WtuZff8rOxdQ6VOx8Y15dzDEA5cf8HqU/fYM6Kh0uv/Sybw/ddRZGZlU7JATma6tak+6/rXAiAxNYOD118ohnxISEmnzbzDjGrqg7ezda7HFH6sQha6HO1ZnNNBscw69Rrfgsb0rmDHqIPBHO5ZHDtjbeYEvCEtM1uxj5b6x2suaGnktEmp7coBVAZQ+POyHDmVChqztLmLSp0O9SjOhRdxHHoYzdqrEezo5K70el4ygU31NNDVVKNOUSmLuZ67OVtvqk6q2LCYBSMPBqusL2yph56WOk/eJVPSzkDl9Z/JTxsEDgsLw8zMjHbt2mFiYsLvv/+uCPhaWFiQmJjIzp07adasWZ6O+/r1ay5fvky5cuXYvHkzvr7KvbZly5alb9++PHv2DGdnZ5KSkggNDcXW1pbk5GTq1KlDhQoVKFiwoMqxv1Um8K1bt+jZsydHjx7FyipnDCkHBwdWrVrFyJEjkcvlnD17lkGDBiGTyahfvz5nzpyhatWqnDp1Cjc3t78oQfgewiLeYmZiQtumDTAxMmTN5p2KQISFmSmJSUnsPnScJnX9v3AkZa9Dw7hy/RZlvUuxdc9BKnzICv7Ix8uDgaMm8yz4Fc5OjiQlJxMa/hZbayuSU1KpXa0y5Ut74lpONUMtr5nA42bOJy4hgRVzpiitb1CrOtv2HqRjq6ZERccQ9PwlTg6qGRnCv0PY20jMTIxo07gOJkYGrN22VxFwsDAzITEpmT1HTtG4drUvHEnZm7AIrty8S1nPEmzbd1SRFfxRmVLFGTh+Bs9fvqFQAXuSklMIi3iHTT5LklNSqVXFl3JeJSlauaHKsfOSCdyjXXN6tJMy4F6GhNGk6yBObF0JgI2VJecCb1C5rDcBl67hXEDKUoqNT0BPRwctLU3WbN2DbxlPjAxzbii2HzhGiwa18vR+CN9eWHgEZqYmtG3ZFGNjI9Zs3JJznTU3IzExid37DtGkYd08Hfd1SCiXr16nXBlvtu7cq8gK/qhsaS8GDBvNsxfBOBd0IikpmdDwcGytrUlOSaGOfzUq+JSmcKlyKsfOaybw2CkziYtPYOVC5XkI6tfyZ+OWHZQr482ufYeoUqkCMpmM5OQU5HI5+vp6nAg4h4aGBm5FXAgLj+DRkyAio6KxtDDn5JlzFHF1ztP7Inx7Ye+iMTM2pHW9ahgb6rNu91HF9dfcxJjE5BT2njhPoxp5G1LpTfg7Au88xKekG9sOB1C+lPIXszIlivDLtMU8fx1KIQc7kpJTCXsXhY2VOckpadSqWIZyHu641+mocuz/JRN4x5EzNK/lp7Quv7UVAYG3ad/Qn8cvXpOano6lmTHVK3gxd+0OklNS0dLU5ML1u/Rr//lHnoUfIyI2GRN9bZqXLYSxnhabLgQpAmdmBtpSkOnmK+p5/vXTC38W8j6Ja8/fUbqQFbuvBuPjrDy8nVdBS37dEsiLd/EUtDIiKS2DiNhk8hnrkZKeSfXi+SnjbEXp0btVjv2tMoFfvI2nYD4pc+7EvRAKWkm/1yyZn16rz9OruhsRccm8eBePp5OYp+XfJCImSWq35V2kdnv2UU67NdQhMTWDA9efU9+7UJ6OGxKdyLVnEZR2tmbXlSB8CisHUr0K5WPExvO8eBtHwXzGUruNSSKfiT4p6RnUKOmIT2FrvIf9oXLs/yUTePeVZzQpq/wZH52Qgqm+DmpqMhYcvEmbikUASM/MouPCo7Qo70KD0nk7b+H7iYhPx0RXg6YlLTHS0WDLzbeKgK+ZngZJaVkcehhNXbe8JaiExqVz/U0C3vaG7L0XpcgK/sgrvyGjDwUTHJ2Ck7kuyelZhMenY22oRUpGNtVcTCntYEi5+bdUjp2XTGCZTEYNV1MuvYzHt6AxF17EUdhSmo/jRXQKBc2l308GxeBkLg1h8jomFVsjbTTUZYTEpvE8KgV7k59/LOufNgh87949hg0bhpqaGpqamixbtgwTExO6d+9OsWLFsLa2pnTpvA/27+rqypIlS+jSpQtubm707t1b6XVLS0vWrVtH69atSfvwRXLKlCkYGhrSsGFDUlNTkcvlzJ2rmoGWV8OHD2fz5s0kJyeTP39+unXrxoQJExg2bBiJiYk0by4FLRwcHNi/fz/NmjXj9OnTFC9eHJlMRq1atRRDYcycOZP27dszaNAgLC0tWbtWdUxM4fu6//gpv07+DTWZGpqaGiyeMR4TYyO6tG1Oqar1yWdpgXfJYl8+0J+4FHJi2brNdB88mqIuhejZobXS65bmZvw+fzrt+wwhLV36Ijlx+CAMDfRp2rkvqWlpyOVyZo3/NbfDf7WQsAhmLFiOq3NByvhLX876dG5Ll7bN8ffz5eTZC5SoXBd1dTWmjx2GuZn0iEiVRm158uwFicnJOHlVZsWcKfj7ifGCf6QHj4MYOX3Bh+utBgsnj8TEyJDOrRrjWbMF+Swt8CqR944ll4KOLN+wnZ7DJ1K0cEF6tFPutLM0N2XVbxPoMHAUaR+CHhOG9MHAQI/m3YdIbRU5M8f8vUnh/srS6WMYOmk2mZlZ6GhrsWTaGAAePwum25DxyGQy3FwKsnxmzuReSckpnLoQyOKpo/6xeglf597Dx/w6bgpqajI0NTVZPGc6JsbGdO3QhpLlq5HPyhJvz6+7+fyUa+FCLPt9Pd37D6Goqwu9uigHwiwtzFm9dB7tuvVVtN1Jo4djaGBA47ZdSEuVrrOzp47/W+cXEhrG9DkLKeLiTOnKUkZbn+6d6dqhDV3at6JjrwG4elbA1NSEzR+ykt9FRVGnaRvU1NSwtbFm/XJprG9bG2vGDv+FKnWboKmhiYO9HWuWzvtb9RP+vgdBwYye+zsyNRmaGhosGNMfEyMDOjWtjXeTnuSzMMWzmGr2zZe4FMjPiq0H6DVuLkUKOtC9hfIwZpZmJqycPJSOI2aQnp4BwLh+HTHQ16XFwAmkpWUgl8uZMbTnNznPXcfOsWfpZKV1M4b2oO/E+SzeuBtkMlZOHopMJsPUyJABHZpQsU1/ZMioWbEMtSupDksh/FgPQ2OYuOsGajLQVFdjVpuyGOtp0d63MJUm7sPKWBcPx7w/LeOcz4g1Z54waMMlXGyM6VTZVel1C0MdFnaqQK/fzykCICMbemCgo0mHpadJzcgGuZyJzb3/9jlO3HWd3VeDSUnPpOSIHbT1Lczw+h6sPvOYc4/C0FBXw0RPm0WdpWEEi9ia0tCrAL4T9qKhrsbM1j6oq/3cjyX/1zwMiWbitsvIZDI0NdT4rUMljPW1aVe5KJVGb8PSWA8Pp7xP5OdsbcKaU/cZuDoAF1tTOlVV7nizMNJlUbcq9Fx+gvQPQeeRTcugr6NJhwVHScvIRA5Mav1tJoXbf+0ZW35R7gC/+DiMKTsDkQHlXG2Y2V4a2m3f1edcfhrO+8RUtl54AsCiblUp7ig6MP5NHr9LZsrxV8hkoKkmY3q9ghjratDGy4pqS+5gaaBFSdu8Z8AWstBh/dUIhux9joulLh1LK3e8metrMq+RM313BpGeJWUPD69qj4G2Ol22PCYtU45cLmd8rbx1+OVmdA1HBuwOYsLRl5jpaTCvkdSRsS4wgvMv4tBQl2Gso8H8xtL6q68TWHL+MRrqMtRkMqbVLaiYTO5nJpPL5f/cwWUy+T95/O/t5cuX1KtXj/v37//oqvz0ZDIZcrn8hw0mJJPJ5Olhj39U8f+Yl29CaNShN7cDDvzoqvyUtGyL/PB2mxp840cV/019zLi9eWz7j67KT0/HyeuHt9vMmNAfVfw39/L1Gxq27Midy6e/vLHwt2iY2v3wtpt899iPKv4f8yo0gqb9xnF9z8ofXZWfkl6Jmt+93cpkMvm7FapZ2T+b11GJtFtyinPjVZ8AEr4tq57rf0g7jlzX+8sb/se8joyn7fzDnJ/a6kdX5adk2WnZD2mroRNVn+b62byJSaXj5sec7uvxo6vyU7Mbf/mbtmHRtSgIgiAIgiAIgiAIgiAIgvATE5nAwr+SyAQW/otEJrDwXyQygYX/KpEJLPwXiUxg4WcgMoGF/wqRCSz814lMYEEQBEEQBEEQBEEQBEEQBOGriSBwLgwM8j4g9rcwb9483N3dKVasGK1btyY1NRWATp064eTkhIeHBx4eHty+fVuxz5kzZ/Dw8MDd3Z3KlSsD8ObNG6pUqYKbmxvu7u4sWLAg1/LkcjkDBgzA2dmZEiVKcPPmzX/8HIVvy9TZ84eU2/2XUdgVL49HlfpK6yfNXkQBz0p4V2+Ed/VGHDl1FpDGIjYqWFKxvu8IabKj5OQUGrbvSbGKtSnpV49RU+eolLX70DG0bItw4869XOtyLOA87r61KFren1mLxPiF/xXm7r4/pNwewydi710dz5rKsyS36/crZeq0pkyd1rj41qNMHeUJE1+HhmPu7su8lRuU1mdlZeFTtw2Nuw5UrAu4dJWy9drgWbMFXYeMIzMzM9e6bNx1APcqjXCv0oiNu8Q43f8FxvkL/5Byu/UbjE3hEpQsV1Vp/bipsyhVoTpeFWtQq0lrwsIjAHj89BkV/Oujl8+JOYuWK7Z/EvQMr4o1FD+mDq4sWLYKgOFjJ+NephKlKlSnabuuxMbF5VqXoycDcCtdEVfPCsyct/gfOmPhW7L0+f7jo4ZEvKNW12F4NuqOV+PuLNm0R/Ha7uPn8GrcHf2Stbjx4KlifXRsPLW6DsPSpyG/TMu9bTXrPx7vxj0Uy6PmrMKjQVfKNO1Fy0ETiY1PzHW/4xeuUbJ+V4rV7cTs1du+0VkK/7QCA/747mWmZmRRc/pB/Cbvp+KEvczcf1vxWv3fjlBl8n6qTN5P8eHb6bBUGvs9KCKO2jMOk7/vRpYcV547Ji45nS4rzlB+3B4qjN/LtefvAJiw8zrlx+2h8qT9dFx2mrjk9Fzr4zVqJ5Un7qPK5P3UmHrwnzlp4Zty7Lnqu5eZmp6J/8Rd+I3dju+orczcc1XxWr9Vp/Eaugm/sdvxG7ude6+iADhyM5jKY7bhN3Y71Sfs5MrTcAAuPApVbOs3djv5u63k8I1gAAauDsBv7HYqj9lG58XHSEzNUKnL68h47LuvVOw/dN3Z7/AOCN9C4amBP6zsrGw5/svu0OGPRyqvjT0crFS3tMxsem1/SoUFN6m38h5vYlKVtg+NTaPw1ECWXwwD4FlUCjWW3VH8uE67yqrL4SrlyOVyxh4OpsKCm1Rfeod7YbnfU/zXafzoCgiS0NBQFi5cyMOHD9HV1aVFixZs3bqVTp06AfDbb7/RrFkzpX1iY2Pp06cPR48excHBgXfvpJsKDQ0N5syZg6enJwkJCXh5eVGjRg3c3NyU9j9y5AhBQUEEBQURGBhI7969CQz8cX/4wn9Hh5aN6dO5LZ0H/qry2oDuHRncu6vK+oKODlw/uVdl/S+9OuNXoSzp6enUbNGZo6fPUauqNNtsQmIii3/fSBnPkrnWIysri4GjJnF46xry2+SjXJ3m1KtZFTcX5793gsJPq33T+vTu0IKuQ8Yrrd+0eIbi9xFT5mJkpNwZOGLKPGpWVp1xefHaLbg6FyAhMQmA7Oxsug2dwNFNyyhc0JGJc5excddBOrdspLTf+9g4pi5YxaX9G5HJZJSr34561Stjamz0jc5U+Jl0aN2CPt0707nXQKX1Q/v3ZtLo4QAsWrGaKbPmsXTeTMxMTZg/YzL7Dh1V2t61sDM3zp8ApOung5sXjerWBqB6lUpMGz8SDQ0Nfh0/lRlzFzNj4mil/bOyshgwbDRH92whv60NZavWoX5tf9yKuPxTpy78R6mrqzN9SA9KuRUmISmZCq36UbWcJ0ULOeLmXIAtc8fRf/JCpX10tLQY17cjD5695OGzlyrH3HvyAgZ6OkrrqpbzZNLALmhoqDNm3u/MXr2VKb90U9omKyuLX6Yt4eDK6djls6Bi6/7U9StL0UJ/fyZy4eejraHGrl9qYqCjSUZWNvVnHaFaMTu8C1pyYFhtxXadlwdQq6QDACZ6WkxrVYYjt1+rHG/0tqtUdbdlTU8/0jOzSEnPAqCymw1jGnuioa7GpF03WHDkHuOaeuVap91DamJuoJPra4IAoK2pzu4RDaR2m5lFvWl7qVbcAW9nawDGtyxHg9KFlPap6JafWqUKIJPJePAmmm5LjnN5Rmt8i9pxZrKULBGTmEqZEZvxK5YfgCltKmCoqwXA2C0XWX3yHgPrqSYlFbAyUhxDEL7G71fCKWypS0JaltL6O6GJxKYoJ9RsufkOY10NLg70ZN+9KKaeeM3yFjn3ohOOvaSKs4li2dlClxO9pXhCVrYcrzk3qF3UTKUOp4NiCY5O5cKAUtwMSWTkwWAO9ij+Dc/y3+GnzwT+9ddfWbJkiWJ5woQJzJ49m8TERKpVq4anpyfFixdn3759KvueOXOGevXqKZb79evHunXrALhx4waVK1fGy8uLmjVrEh6u2pOQV5mZmaSkpJCZmUlycjK2trZ/uf3mzZtp0qQJDg7SDYiVlRUANjY2eHpKF2NDQ0OKFi1KaKjqeIv79u2jQ4cOyGQyypYtS2xs7Dc5D+F/M2rqHJatzcl4mDR7EXOXrSYxKYmaLTpRxr8JparWZ//RUyr7nr0USKMOPRXLA0dNYsO23QDcvHufak3a4VOzCXVbdyX87bu/XdeKZUtjamr8t4+jp6eLX4WyAGhpaVGquBuhHzLZACbMWsjQvt3Q0dbKdf9rt+5SqIADBR3t0dLSokXDOhw4pvr+CP+sMTMXsnzDdsXy5PkrmLdyA4lJydRq24uy9drgVasFB46fUdn37JXrSlm0g8bNZMPO/QDcvPeI6i27U65+W+p16Ev4u8i/XdeKPp6Ymny+7crlcnYePknL+rUU6/YfD6CAvS1FXZRvnkPC33Ik4IJSgDc6Jg4tTQ0KF5SCC9V8y7L36GmVck6cu0w1Xx/MTIwxNTaimq8Px89e+ptnJ+TFyAnTWLpqnWJ54ow5zFm0nMTEJGo0bEHpyjXxKF+N/YdVx3w9c+ESDVp2UCwPGDaa9Zul7MIbt+9SpW5TyvjVonbTNoRHvP3bda1UoSxmpiYq642MDBW/JyUlI5NJw4VZWVpQ2tMDTU3Nzx7z1NkLFCzgiKOD9MXOv2plNDSk3ICypT0JDVO9H7h64xaFChagYAFH6ZrbpGGu74/wzxk7fzXLt+5XLE9ZupH563aQmJxCnW4jKNeiL6Wb9ORAgOr15Ny1OzTpN1ax/Mu0xWzcdxyAmw+D8O88lPIt+9Kg1yjCI6P/Vj1tLM0p5SZlzhvq6+HqZE/YOyn7rEhBB1yc7FX20dfTobxnsVw/8xOTU1i0cTcjerRRWl+9vBcaGuoAlC5RlNC3USr7Xr//hEIOtjjlt0FLU5Nmtfw4GHD5b52fkHeTd99gdUDOfBuzDtxmyfH7JKZm0HTuMapNOUDliftyDaRefBJB28U593e/brnC1kvPALjzKpqGs49SfeoBWiw4wdu45L9VT5lMhoGOdO3MyMomIysb2Z9GYkxISefCkwjqeEjt2NJIl1IFLNBQV/5qHZ+SzpWgt7StIP0taGmoY6wnte8qbnaK7b0KWhAWm/S36i38MyZtv8LqkznZ3bP2XGPJkdskpmbQZOZ+qo7fQaUx2zhyM1hl34uPQmkz77BiecTG82w5L/0N3HkZSYPpe6k2fgfNZx8k4m/+/+febv96CFEDHU3FNslpGSrtHODA9RdUK+6AnrZ07I8BYLlcTmp65hfLEH6caSdesS4w53v1nIA3LL8YRlJaFi3WPaDm8rtUW3KbY4/fq+x7KThOKSN39KEXbLslxRDuhiXSdM19ai2/S5sND3mbkPtTDHkRFpfGqacxtPbMp7Q+K1vO5OOvGOOv3Gl7/PF7mntYAlDXzZwLwXF8nIvs6KP3OJho42qll2tZF17E4WiqQ34TbZXXjj1+TzMPS2QyGV72hsSlZn6T8/u3+ekzgVu2bMmgQYPo27cvANu3b+fYsWPo6OiwZ88ejIyMiIqKomzZsjRo0OCrLmQZGRn079+fffv2YWlpybZt2xg9ejRr1qxR2u6PP/7gt99+U9nf2dmZnTt3Kq2zs7Nj6NChODg4oKuri7+/P/7+/orXR48ezaRJk6hWrRozZsxAW1ubp0+fkpGRgZ+fHwkJCQwcOJAOHTooHffly5fcunULHx8flXqEhoZib59zE54/f35CQ0OxsbH54nsgfHvNG9Rm6Php9O7cFoCdB45yaPPv6Ghrs2P1YowMDYiKjqFi/ZbUr1n1q9vqoNFT2LVuKZbmZmzfd5hxM+azat40pe027z7A3KWrVfYv5OTAtlULVdb/lWVr/2DTzn14lSjGrPEjFAG3l69DKF2jMUaG+kwcMQhfH2+l/WLj4jl0IoB+3aQ2fOvuA96EhVOnuh9zl6nWDSA04i35bXPaq52NNddu3slTfYW/r1k9f4ZOmkOvDlKP/65DJziwfjE62lpsXz5barvvY6jUpBP1alT+6rY7eMIsdqyci6W5KTsOHmf87KWsnKWcwbtl72Hmrdyosn8hR3u2LJuV53O5cPUW+SzMcHaSOtcSk5KZs3w9hzYuZd4q5XKGTZrDtF8HkpCUc+NuYWZCZmYWN+4+xKuEG3uOnCTkk46Nj8Ii3pHfJudGx87airCIv99BI3y9Fk0aMHjkePp07wTAzr0HOLzzD3R0tNm1cTVGRoZERb+nQo361K/t/9XtduDwMezZvBZLC3O2797H2Ckz+X3xXKXtNm/fzZxFy1T2L1SwANvX5+0x0jGTZ7Bp606MjYw4eWDHV++3ffc+WjVtlOtrazdtpUXjBirrw8IjsLfL6aDOb2vD1Ru38lRf4e9pWrMyw2ctp1cr6f9n9/Fz7F8+FR0tLbbOH4eRgT5RMXH4tRtIPb9yX9luMxkyfQnbF0zA0syEnUfPMGHROlZMGqK03dZDp5m3TrWNFbK3ZfPcsSrrP3oVGsGdx88pXbxIHs82x6TF6xnQoSl6Oqpf2j7asOcYzWpVVlkf9jYau3yWimW7fBZcuycm//3eGnkXYMz2a3StIrWD/Tdesm1ADXQ01VnXuwqGulpEJ6ZSe8ZhapW0/7q2m5XNyK2BbOhTFQtDHfZeC2ba3lss6FhBabudgS9UhmkAcLIyYk1PP5X1WdnZVJ96kODIBLpULoKXk6XS64dvv6FiERtFQOxzXkUlYm6ozYD1F3kQEkNJB3OmtCyNvrZyB92Wi89o6F0g12PIkNFi/glkMuhQ0ZUOlcSTF99TI59CjNl8ka7ViwGw79pztg+ph46mOusH1JLabUIKtSbvVmTVfklGZhYjN51nw4DaWBjpsifwGdN2XWVh1ypK2+289JTFR26r7O+Uz5i1/WqqrM/Kzqba+J0Ev4uja7VieBXKuc+ctiuQOfuuU9EtP2Obl0VbU+o8O3TjBVN2BBKVkMLmX+qoHHNPYBC9ayo/kdn/99OcuvsaF1tTJrZSfUoO4HVkAlXG7cBQV5ORTcpQzvWvk9uEb69BMQvGHwmmk4+UDX7gQTR/tC+KtoYaq1u5YqijwfukDOr/fg9/V9OvvuaOORzM2tZFMNfXZN/9KGaees3cRspP4e6+G8myD0MxfKqAmQ6rWrqqrB9/9CVj/B1J/FMW8NrACPxdTclnqHytjUhIx9ZIWqehLsNIW52Y5Ey0NdRYciGUrR3cWH5JtXyAffejaFTcPNfXPj0ugI2RFhHx6Srl/9f99EHgUqVK8e7dO8LCwoiMjMTU1BR7e3syMjIYNWoU586dQ01NjdDQUN6+fYu1tfUXj/nkyRPu379PjRo1AOkxs9wCp23btqVt27ZfVc+YmBj27dtHcHAwJiYmNG/enE2bNtGuXTumT5+OtbU16enp9OjRg5kzZzJunDTO5I0bNzh16hQpKSmUK1eOsmXL4uIi3RwkJibStGlT5s+fj5GReMT4365UcTfeRb0nLOItkdExmBobYW9nQ0ZGBmOnz+V84HXUZGqERrzlbWQU1laWXzzmk+fBPHgSRO2WXQDIys7CJpf92jSpT5sm9VXW51XPjq0Z/UsfZDIZ42ctYPjEmayaNw0bKyueXzuNuZkpN+/ep1nnftw+cxAjQ+mR+8zMTNr3GULfru0p6GhPdnY2wybO4Pf50/92nYR/nod7ESKj3xP2NpKo6BhMjI2wt7UmIyODcb8t4cLVm6ipqREWEcnbqGisLS2+eMynL17x4Olz6rbvA0htN7f9WjeqQ+tGqjet/6vtB47Son7OjfWU+Svo36UNBvrKvcmHT53D0sIUz+JFOXvlumK9TCZj46LpDJs8h/T0DKpVLIu6mvo3q5/w7ZQqUYzIqCjCwiOIjIrGxNgY+/x2ZGRkMGbyDM5fCkRNTUZoeARv30Vinc/qi8d8EvScB4+fUKtxKwCysrKxtlbdr02LJrRp0eSbnMeUsb8yZeyvzJi7iCWr1jJh5NAv7pOens6BI8eZOm6kymvTZi9AQ0Pjm9VP+LY8ijoT+T6WsHfRRMXEYmJkQH5rKzIyMhm/cC0Xb9xHpiYj7F00b6NjsLZQfdzxz56+DOHhs1fU6ym1h+ysbKwtVfdrVbcqrepWVVn/VxKTU2g9eDKzhvfCyEA/T/t+dOfxc168CWfW8F68ClXtVAOYuXIzGhrqea6f8P0UdzAnKiGViNhkohJSMdbTws5Mn4ysbKbuvcnloHeoySAiNpl38ankM9b94jGfRcTxOCyW5vOljPbsbDlWuezXzKcgzXwKfnVd1dXUCBjbgLjkdDotC+BRaAxF7UwVr++5Fkxb3y+PEZ+Vlc3d1++Z1soHLydLRm+7yqKj9/m1YSnFNvMO30VdXfbZ+h0YVgsbU30i41NovuAEha2NKOfy5e+rwrdRwtGSqPgUImKSiEpIwVhPGztzAzIys5iyM5ArT8KQyWRExCTxLi6FfCa5Zx9+6llELI9C3tPsN2k+iGy5nHzGqvs1K+9Cs/JfH/RXV1PjzOQWxCWl0XHRUR6FRFM0vzljmvuQz1iP9MxsBq87w6LDtxjaUErGqetVkLpeBbn0JIwZu6+ya3hOB3BEbBKPQt5TpZjykxuLulUlKzubkZsusPfqc9pUVO7gy2eiz6257TEz0OHOy0g6LDzChamtvthpInxbxWz0iUrKJCI+nejkDIx1NLAz1iYjK5sZp14T+CoBmQwi4tOJTMzA6isCnc+jUnnyLoVWGx4CH665uezXpIQlTUp8OVYBcOJJDBb6mpSwNeBScM58FBHx6Rx8GM3OTu5fecYw58wbupezQV879+9e6ZnZHH8Sw8jqDl99zJ/RTx8EBmjevDk7d+4kIiKCli1bAlKWbmRkJDdu3EBTU5MCBQooJmL7SENDg+zsbMXyx9flcjnu7u5cvvzXj5LlJRP45MmTODk5YWkp/bE0adKES5cu0a5dO0WAWVtbm86dOzN79mxAytw1NzdHX18ffX19KlWqxJ07d3BxcSEjI4OmTZvStm1bmjTJ/YucnZ0db968USyHhIRgZ2f3l+ck/LOa1qvF7oPHiIiMonkDadyxLbsPEBkdQ+DRXWhqalK4TFVS09KU9tNQ1yA7W65YTk2THluQy+W4uTpz/sBfT4LyrTKB830SpOvatjmNOvQGQFtbC+0Pj3d6lihGwQL2BL0IxqukNMZO72HjcHZyZED3jgAkJCbx4HEQNZpKWcERkVE06dSH3euWKvYBsLPOR8gnjyyHhkdga6P8GInwfTSpU509h08SERVN87pSB9mWfUeIeh/D5QOb0NTUxMW3nqJtfqShrv6ntiu1bblcjlvhgpzdve4vy/2WmcCZmZnsOxrApQObFOuu3r7P7iOnGDVjIXHxCaipqaGjrU3o23ccOnmOowEXSUtLJz4xkU6DxrBu/hTKepbg9A7p7+nEucs8C36lUpattRXnrtxQLIdGvKNS2dzHAhT+OU0b1mPX/kNEvH1HiybSF5/NO3YTGR3N1TNH0NTUpFAJn6+45n7Sbou4cPH4X0/09y0zgT9q07wJ9Vu0/6og8NGTAZQqWZx8f+oUXL95G4eOn+TE3u25ZoTY2ljzJjQnsyIkLBxbGxGM+N4a+1dk74nzRES9p1lNKfN16+HTRMXEcXHrYjQ1NShSqwNpX7zeShP6yOVyihZy5Mym+X9Zbl4zgTMyMmkzeDKt6lalUfX/fTLQwDsPufnwKUVqdSAzM4vI97HU7DKMY2uke+yN+45z5NxVDq+akXu7zWdO6Nuc4YRC30Zha/Xlzkjh26vv5ciBm694F5dCI28nAHYFviA6IY2To+uhqa6G16idpGUoZ4Opq8vIlue03bQM6fuZHHC1MeHIr3/dGZzXTOCPjPW0qOBqzekHoYogcHRiKrdeRrGud5XP7veRjak+tqZ6ikzi+p6OLDyaM9Hx1kvPOH43hF2DP/+0iY2p1HliaaRLHQ8Hbr6MEkHg76xB6ULsv/6cd3HJNPKRhgbbeTmI6IQUTk5ohqaGOp5DNpGWoTxuqbq62p/arfS6XA5F7Mw4MvavO1vzmgn8kbG+Nr5F7Th97w1F85tjbSK1IW1Nddr4FmHJUdWnJsu72jIgMp7ohBTMDaWOlH1Xn1PH0wlNDdWAmrqaGo18nFl8+LZKEFhbU12RaVyygCUFLI15HhGLh9OXO9OFb6ueuxmHHkbzLjGDBsWk7Nfdd6OITsrkSM/iaKqr4TPvJmmZ2Ur7aajJ+KTpkpYpLciR42Kpy4Hufz1Obl4yga+/juf4kxhOB0n1SEjLov+uIBoWt+Dl+1QqLJSeOEvJyKbCgptcHOiJtaEWYfHp2Bprk5klJz4tC1M9DW6FJHLo4XumnnhNfGomajLQ1pDR2UeKpwU8i6W4jT6WBrkHvD8e96Pw+HSsjX6+zov/F0Hgli1b0r17d6Kiojh7VpqdMi4uDisrKzQ1NQkICODVK9Uv6Y6Ojjx8+JC0tDRSUlI4deoUvr6+uLq6EhkZyeXLlylXrhwZGRk8ffoUd3flXoq8ZAI7ODhw5coVkpOT0dXV5dSpU3h7Sz104eHh2NjYIJfL2bt3L8WKSY+jNGzYkH79+pGZmUl6ejqBgYH88ssvyOVyunbtStGiRRk8ePBny2zQoAGLFy+mVatWBAYGYmxsLIaC+MGaN6xN76FjiYqJ4dQuKbAVl5CIlYUZmpqanLl4hVchqhdUh/y2PHr6jLS0dFJSUwm4cJkKZTxxLeREVHQMV67foqx3KamtvniJu6ty9sK3ygQOf/sOmw/ZcvuOnFSUExn9HjMTY9TV1Xnx6g3Pgl/h5CD1Ko+bOZ+4hARWzJmiOI6xkSHhD64olqs3bc/MccOVAsAA3h7FeRb8iuDXIdhZW7F932E2LJn9t89DyLvm9fzpM3IKUe9jObFtJQDxCYlYmn9ou5ev8TpUdYxRBzsbHgW9kNpuWhoBl65RvrQHLgULEPk+his371LWswQZGRkEBb/G7U/j8n7LTODTF6/iUqiA0jANH4O5II11bKCnS++OUmfilOH9AWlc4/mrNrJuvtSG30W9x8rCjLS0dOasWM+Ivl1UyqpRqRzjfltCTFw8ACfPX2Hy8H7f5DyEr9eicQN6DhxG9Pv3nD64C4C4+ASsLCyk+4PzF3n1JkRlP0d7Ox49eSrdH6SmcvrsBSqULY1r4UJERb3n8tXrlCvjLV1zn73AvajyDe+3ygQOev6CwoWk7LH9R47h+qe/j8/ZunOvylAQR08GMHvhMk4f3IWeXu4ZeKU9PXj2PJjgV6+xs7Fm++59bFy1JNdthX9Os5qV6TtxPtGx8YpAaHxCEpZmJmhqanD26m1eh6mORe1ga8XjF69JS08nJTWdM4G3KO/pjotTfqJiYgm88xCfkm5kZGQS9CoEN+cCSvvnJRNYLpfTe/xcXJ3sGdCh6d863x4t69OjpXSP8io0gqb9xinO+/iFa8xbu4Nja35DTzf3ibO83F159iqUlyER2OYzZ+fRM6ydoTqxrfDPa+RdgMEbL/M+MY19Q6UgVnxKOhaGOmiqq3HhSThvolXHRrU3M+BpeCxpGVmkZmRx/nE4Ps5WOOczIjoxlWvP31G6kBUZWdk8fxtHEVtTpf3zkgkclZCKproaxnpapKRncvZRGP1rFlO8fuDGK2oUz4+O5pef8slnrIutqT7PIuJwtjbm3ONwXGxMADh9P5TFx++zd0gt9LRy/0qelJaBXC6N3ZqUlsGZh2EMrZv7ZMnCP6eRjzOD154hOiGVfSMbAh/brS6aGupceBTKm+gElf3szQ15Ghojtdv0TM4/DMWnsA3ONiZEJaRw7VkEpZ2tycjMktqtnfITGHnJBI6KT5Harb42KemZnHnwhgF1pIzziNgkrE30kcvlHL4ZrCjnxds4nKyMkMlk3HkZSVpGNmafTEC450oQY5qXVSzL5XKC38VTMJ8xcrmcY7deUvhDe/5zXUwNtFFXU+Plu3hevI3D0VI8lfwjNChmwbD9z3mfnMmuzlKsKiE1Cwt9TTTV1bgYHEdIbJrKfnYm2jyNTCEtM5vUjGwuvIijtIMhhcx1eZ+cwfU3CXjbG5KRlc2L6FSV8Xfzkgk8soYjI2tIY/5eCo5j+aUwFjWVYgi3h+UMH1l4aiAXB0rzXvm7mrHjdiTe9oYcehhNBSdjZDIZe7rmXKvnBLxBX0tdEQAG2HsvikbFP98J7F/EjHWBETQsZs7NkESMdNR/uqEg4P9JENjd3Z2EhATs7OwUQc62bdtSv359ihcvjre3N0WKqI5TZm9vT4sWLShWrBhOTk6UKiVdSLW0tNi5cycDBgwgLi6OzMxMBg0apBIEzgsfHx+aNWuGp6cnGhoalCpVih49eijqGhkZiVwux8PDg+XLlwNQtGhRatWqRYkSJVBTU6Nbt24UK1aMCxcusHHjRooXL46HhwcA06ZNo06dOop9e/XqRZ06dTh8+DDOzs7o6emxdu3a/7n+wrfh7lqYhKQk7KzzKYKprRvXp3GnXpSqWh+vEsVwdVa9ibW3s6Fp/dqUqlqfAvZ2lCzmBkhtdcvKBQweO5W4hAQyM7MY0L2DShA4r9r1Hsy5y9eIeh+Dk1dlxg3pT+c2zRg5ZTZ3HjxCJpPhmN+OpbMmAnD+yjUm/rYITQ0N1NTUWDxjAmamJoSERTBjwXJcnQtSxl8KiPTp3JYubZt/tuywiLf0GjqW/ZtWoqGhwfypY6nbpivZWdl0bNX0b5+b8L9xcylEQlISttaWiiFHWjWsTdNuv+BVqwWexd1wLVRAZT97W2ua1a2BZ60WFMhvi4e7FCzT0tJky9JZDJ7wG/EJiWRmZdGvc2uVIHBetR8wivNXrhMVE0uhcrUZM6inYmK37QeO0bLB5zMrvta8lRs4fPo82dlyerRrRpXyZQC4cfchq/7YyfKZ4zAzMWZk/25UaNgegFEDumP2FxPWCf8M96KuJCYmYWtjjY21FPxv07wJDVt3xKN8NbxKlaCIi7PKfvb57WjWqD4ly1elgKMDHiWkm04tLS22rV/BoBHjiI+PJzMriwG9uqkEgfOqbdc+nL14majo9zi6ezH+16F0ad+aUROn8zToOWpqajjY27F07gwAIt6+w6dqbeITElGTqbFw+SruXT6DkZEhSUnJnDxzjmXzZiqVMXD4GNLS0hRDWfh4e7J03kzCwiPoMWAYB3dsRENDgwWzplCnaRuysrLp1Lbl3z43Ie/cnAuQmJSCrZU5NpZSZk/LulVp1n88pZv0pJR7YVxzmXgtv7UVTf0r4d2kJwXsrClZVGrbWpqa/DFnLENnLCU+MYnMrCz6tm2sEgTOi8u3HrD54CmKFXbCp7n0VNDEAZ2pVbEM+05dZMj0pUTFxNG071hKFCnE/uXSXAVFanUgITGJ9IxMDpy+zIEV0yhayPGz5QyevoS09AzFUBZlShRh0diBhL2Lps+EeexdOgUNDXXmjupLg96jyMrKpkMj/791bsL/roitKUmpGdiY6Ckef2/qU5B2i09TeeI+SjqaU9ha9bPQzkyfBl4FqDRpHw7mBhSzl4JYWhrqrO7px+itgcSnZpCVlU2Pam4qQeC8eBuXTP91F8nKliOXy2ngVQD/Ejl/T3uvBzOgZvE/7ZOC/7SDJKRmoCaDlacecWFCQwx1tZjWyofeq8+TnpWNo4UBCz+MV/zr1kDSM7MUQ1l4FbRkdttyRMQm88vGS2zpX53I+FQ6LQ8ApKElmpQpSNVi4qnN762InRmJqRnYmOorsmqblStMu/lHqDRmGyULWOYaDLUzN6BhmUJUHLMNRwtDijtKwSctDXXW9K3JqD8ukJCSTmZWNj39S6gEgfPibVwy/VadJjs7m2y5nIZlnPH3KABA7xUniU5IRS6XU8zBgt86Sk+QHLz+gu0Xn6Chroaulgar+tRQZKS/jown9H0S5T8Zy1cuh36rTpOYmi49GW1vwW8dKwFw9FYwt4Mj+bVJGS4/CWPmnmtoqKuhpiZjdsdKmBrk3kkn/LNcrfRISsvC2lBLEcxsUsKCjpsfU23JbUrYGuBsodrxb2esTX13c6ouuYODqTbFbKR2r6WhxooWrow7Ekx8ahZZ2XK6lbX57CRs/5RWnlYM2B1EhQU3MdHVYGmzL3eWJKdnce55HDPrK8dSNlyThpnqUNqaaoVNOP00hgoLbqGrqaYy1vHPQib/NM/7Wx9cJpP/k8cXfl4ymQy5XP7DphuVyWTy9DAxaYiQN1q2RX54u00NvvHlDQXhEzpOXj+83WbGhP6o4oX/MA1Tux/edpPvHvtRxQv/UXolan73diuTyeTvVnT8nkUKPzmrnut/SDuOXNf7exYp/AQsOy37IW01dGK571mk8BOzG3/5m7ZhtW91IEEQBEEQBEEQBEEQBEEQBOHfRwSBBUEQBEEQBEEQBEEQBEEQfmIiCCwIgiAIgiAIgiAIgiAIgvATE0FgQRAEQRAEQRAEQRAEQRCEn9g/OjGcrq5uRGpqar5/rADhp6Wjo/M2JSXF+keVr6ujE5GalibarpAnOtrab1NSU0W7Ff5Tfni71dWJSE0V7VbIOx0d7bcpKT/ymqsdkZqWLtqukCc62lpvU1LTvmu71dXSiEjNyBJtVfhmdDTV36akZ4p2LPzr/Yi2qqOpFpGWKRdtVfgmtDVkb1Mzsr9ZG/5Hg8CCIAiCIAiCIAiCIAiCIAjCjyWGgxAEQRAEQRAEQRAEQRAEQfiJiSCwIAiCIAiCIAiCIAiCIAjCT0wEgQVBEARBEARBEARBEARBEH5iIggsCIIgCIIgCIIgCIIgCILwExNBYEEQBEEQBEEQBEEQBEEQhJ+YCAILgiAIgiAIgiAIgiAIgiD8xEQQWBAEQRAEQRAEQRAEQRAE4ScmgsCCIAiCIAiCIAiCIAiCIAg/MREEFgRBEARBEARBEARBEARB+ImJILAgCIIgCIIgCIIgCIIgCMJPTASBBUEQBEEQBEEQBEEQBEEQfmIiCCwIgiAIgiAIgiAIgiAIgvATE0FgQRAEQRAEQRAEQRAEQRCEn5gIAguCIAiCIAiCIAiCIAiCIPzERBBYEARBEARBEARBEARBEAThJyaCwIIgCIIgCIIgCIIgCIIgCD8xEQQWBEEQBEEQBEEQBEEQBEH4iYkgsCAIgiAIgiAIgiAIgiAIwk9MBIEFQRAEQRAEQRAEQRAEQRB+YiIILAiCIAiCIAiCIAiCIAiC8BMTQWBBEARBEARBEARBEARBEISfmAgCC4IgCIIgCIIgCIIgCIIg/MREEFgQBEEQBEEQBEEQBEEQBOEnJoLAgiAIgiAIgiAIgiAIgiAIPzERBBYEQRAEQRAEQRAEQRAEQfiJ/R/vr99JwfukqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1800x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,6))\n",
    "tree.plot_tree(decision_tree_fitted, ax=ax, fontsize=10, feature_names=decision_tree_fitted.feature_names_in_, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe25620",
   "metadata": {},
   "source": [
    "**Generate train and test predictions and metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c79cb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,518.8726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>12,192.5802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3304\n",
       "1   MAPE      0.4123\n",
       "2    MAE  7,518.8726\n",
       "3   RMSE 12,192.5802"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "decision_tree_train_pred = decision_tree_fitted.predict(X_train_num[x_variables])\n",
    "decision_tree_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, decision_tree_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, decision_tree_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, decision_tree_train_pred), \n",
    "               metrics.mean_squared_error(y_train, decision_tree_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "decision_tree_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "221f10f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.2876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.4274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>7,750.4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>12,632.3128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.2876\n",
       "1   MAPE      0.4274\n",
       "2    MAE  7,750.4859\n",
       "3   RMSE 12,632.3128"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model out-of-sample prediction and metrics\n",
    "decision_tree_test_pred = decision_tree_fitted.predict(X_test_num[x_variables])\n",
    "decision_tree_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, decision_tree_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, decision_tree_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, decision_tree_test_pred), \n",
    "               metrics.mean_squared_error(y_test, decision_tree_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "decision_tree_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461410",
   "metadata": {},
   "source": [
    "### Tuning the decision tree regression using Grid Search\n",
    "\n",
    "Grid Search offers a way to test all combinations of specific parameters and their possible values. Every set of parameters will be used to train a model, and the parameters of the best model are typically selected. To avoid overfitting, cross-validation is generally used, and models are compared using the cross-validation metrics. \n",
    "\n",
    "Syntax: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "If there are too many combinations of parameter values to test, consider:\n",
    "* Randomized search: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html. See the Gradient Boosting model for an example. \n",
    "* Bayesian tuning. It is available in a different library https://scikit-optimize.github.io/stable/, and examples will be provided in a future notebook template.\n",
    "\n",
    "**Note:** If you have a very large number of variables (especially variables are highly correlated), it is recommended that you also perform some feature selection, as there is high risk of overfitting in a decision tree. You can perform feature selection in many ways. A popular approach is to use some of the more complex methods such as random forest, gradient boosting, or ExtraTrees (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html) to find the most important variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6cf76",
   "metadata": {},
   "source": [
    "**Setting the Grid-Search values for the parameters to be tuned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5988545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3,4],\n",
    "    \"min_samples_split\":[50,250],\n",
    "    \"min_samples_leaf\": [20,100],\n",
    "    \"min_impurity_decrease\": [0.1, 1],\n",
    "    \"ccp_alpha\": [0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Fixed parameters can also be passed directly in the model instantiation\n",
    "decision_tree_model = tree.DecisionTreeRegressor(criterion='absolute_error')\n",
    "\n",
    "decision_tree_tuning = GridSearchCV(estimator=decision_tree_model, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce6e86ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7774.544 total time=   2.4s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7602.504 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7572.957 total time=   1.7s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7526.786 total time=   2.3s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7602.504 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7526.786 total time=   1.8s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7448.449 total time=   2.1s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7774.544 total time=   2.1s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7539.095 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7572.957 total time=   1.8s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7562.337 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7448.449 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7774.544 total time=   2.5s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7539.095 total time=   2.3s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7562.337 total time=   1.8s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7774.544 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7602.504 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7572.957 total time=   2.7s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7526.786 total time=   2.5s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7474.476 total time=   2.1s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7774.544 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7602.504 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7572.957 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7526.786 total time=   2.1s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7448.449 total time=   2.2s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7539.095 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7572.957 total time=   1.7s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7562.337 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7448.449 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7774.544 total time=   1.7s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7539.095 total time=   1.7s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7562.337 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7263.707 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7384.057 total time=   2.2s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7366.768 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7298.548 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7164.950 total time=   2.1s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7244.616 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7424.390 total time=   2.1s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7409.111 total time=   2.2s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7318.185 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7210.643 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7149.970 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7424.390 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7349.192 total time=   2.2s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7316.581 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7217.418 total time=   2.3s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7149.970 total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7424.390 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7385.859 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7318.185 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7249.851 total time=   2.6s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7263.707 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7384.057 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7366.768 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7298.548 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7164.950 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7244.616 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7424.390 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7409.111 total time=   1.8s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7318.185 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7210.643 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7149.970 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7424.390 total time=   2.5s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7349.192 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7316.581 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7217.418 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7149.970 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7424.390 total time=   2.3s\n",
      "[CV 3/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7385.859 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7318.185 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7249.851 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7602.504 total time=   2.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7572.957 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7526.786 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7474.476 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7774.544 total time=   2.3s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7602.504 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7572.957 total time=   2.5s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7526.786 total time=   2.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7448.449 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7774.544 total time=   1.7s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7539.095 total time=   1.7s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7562.337 total time=   2.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7448.449 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7539.095 total time=   1.7s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7562.337 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7774.544 total time=   2.1s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7602.504 total time=   1.8s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7526.786 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7474.476 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7774.544 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7602.504 total time=   2.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7572.957 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7526.786 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7448.449 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7774.544 total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7539.095 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7572.957 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7562.337 total time=   1.8s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7448.449 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7774.544 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7539.095 total time=   2.7s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7572.957 total time=   2.9s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7562.337 total time=   2.5s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7263.707 total time=   2.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7384.057 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7366.768 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7298.548 total time=   1.8s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7164.950 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7244.616 total time=   2.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7424.390 total time=   2.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7409.111 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7318.185 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7210.643 total time=   2.3s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7149.970 total time=   2.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7424.390 total time=   2.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7349.192 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7316.581 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7217.418 total time=   2.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7149.970 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7424.390 total time=   2.4s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7385.859 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7318.185 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7249.851 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7263.707 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7384.057 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7366.768 total time=   2.4s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7298.548 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7164.950 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7244.616 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7424.390 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7409.111 total time=   2.7s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7318.185 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7210.643 total time=   2.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7149.970 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7424.390 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7349.192 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7316.581 total time=   2.4s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7217.418 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7149.970 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7424.390 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7385.859 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7318.185 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7249.851 total time=   2.3s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7774.544 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7602.504 total time=   1.6s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7526.786 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7474.476 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7602.504 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7526.786 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7448.449 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7539.095 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7572.957 total time=   1.7s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7562.337 total time=   1.8s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7448.449 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7539.095 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7572.957 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7562.337 total time=   1.8s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7474.476 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7774.544 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7602.504 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7572.957 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7526.786 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7474.476 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7774.544 total time=   1.9s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7602.504 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7572.957 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7526.786 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7448.449 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7774.544 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7539.095 total time=   1.8s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7572.957 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7562.337 total time=   1.7s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7448.449 total time=   1.7s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7774.544 total time=   1.8s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7539.095 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7572.957 total time=   1.9s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=3, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7562.337 total time=   1.9s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7263.707 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7384.057 total time=   2.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7366.768 total time=   2.3s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7298.548 total time=   2.3s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=50;, score=-7164.950 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7244.616 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7424.390 total time=   2.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7409.111 total time=   2.6s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7318.185 total time=   2.4s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=20, min_samples_split=250;, score=-7210.643 total time=   2.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7149.970 total time=   1.9s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7424.390 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7349.192 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7316.581 total time=   2.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=50;, score=-7217.418 total time=   2.3s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7149.970 total time=   1.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7424.390 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7385.859 total time=   2.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7318.185 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=0.1, min_samples_leaf=100, min_samples_split=250;, score=-7249.851 total time=   2.6s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7257.289 total time=   2.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7384.057 total time=   2.3s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7366.768 total time=   2.3s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7298.548 total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=50;, score=-7164.950 total time=   2.4s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7244.616 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7424.390 total time=   2.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7409.111 total time=   2.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7318.185 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=20, min_samples_split=250;, score=-7210.643 total time=   2.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7149.970 total time=   2.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7424.390 total time=   2.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7349.192 total time=   1.9s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7316.581 total time=   2.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=50;, score=-7217.418 total time=   2.3s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7149.970 total time=   2.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7424.390 total time=   2.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7385.859 total time=   2.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7318.185 total time=   2.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=4, min_impurity_decrease=1, min_samples_leaf=100, min_samples_split=250;, score=-7249.851 total time=   2.1s\n"
     ]
    }
   ],
   "source": [
    "decision_tree_tuning = decision_tree_tuning.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423d9af",
   "metadata": {},
   "source": [
    "**Parse the results from the cross-validation for every combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b870193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ccp_alpha</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.2358</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.1662</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.1380</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.1718</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.1878</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "26         2.2358        0.0716           0.0026          0.0005   \n",
       "46         2.1662        0.1377           0.0028          0.0008   \n",
       "42         2.1380        0.1416           0.0022          0.0007   \n",
       "30         2.1718        0.1991           0.0026          0.0005   \n",
       "10         2.1878        0.1794           0.0026          0.0005   \n",
       "\n",
       "   param_ccp_alpha param_max_depth param_min_impurity_decrease  \\\n",
       "26          0.0100               4                      0.1000   \n",
       "46          0.1000               4                           1   \n",
       "42          0.1000               4                      0.1000   \n",
       "30          0.0100               4                           1   \n",
       "10               0               4                      0.1000   \n",
       "\n",
       "   param_min_samples_leaf param_min_samples_split  split0_test_score  \\\n",
       "26                    100                      50        -7,149.9699   \n",
       "46                    100                      50        -7,149.9699   \n",
       "42                    100                      50        -7,149.9699   \n",
       "30                    100                      50        -7,149.9699   \n",
       "10                    100                      50        -7,149.9699   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "26        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "46        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "42        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "30        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "10        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "26        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "46        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "42        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "30        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "10        -7,217.4177      -7,291.5101         97.0939                1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.DataFrame(decision_tree_tuning.cv_results_).drop(columns=['params']).sort_values(by=['mean_test_score'], ascending=False)\n",
    "full_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d73e2",
   "metadata": {},
   "source": [
    "**We can identify the parameter set resulting in the best score** or view the scores close to best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4cdedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -7291.51010550221\n",
      "Best index: 10\n",
      "Best parameters: {'ccp_alpha': 0, 'max_depth': 4, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 100, 'min_samples_split': 50}\n"
     ]
    }
   ],
   "source": [
    "# Best\n",
    "print(\"Best score: {}\".format(decision_tree_tuning.best_score_))\n",
    "print(\"Best index: {}\".format(decision_tree_tuning.best_index_))\n",
    "print(\"Best parameters: {}\".format(decision_tree_tuning.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e400eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ccp_alpha</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.2358</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.1662</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.1380</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.1718</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.1878</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.2582</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,349.1922</td>\n",
       "      <td>-7,316.5807</td>\n",
       "      <td>-7,217.4177</td>\n",
       "      <td>-7,291.5101</td>\n",
       "      <td>97.0939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.3854</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,257.2892</td>\n",
       "      <td>-7,384.0574</td>\n",
       "      <td>-7,366.7678</td>\n",
       "      <td>-7,298.5480</td>\n",
       "      <td>-7,164.9504</td>\n",
       "      <td>-7,294.3226</td>\n",
       "      <td>79.2807</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0112</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,263.7069</td>\n",
       "      <td>-7,384.0574</td>\n",
       "      <td>-7,366.7678</td>\n",
       "      <td>-7,298.5480</td>\n",
       "      <td>-7,164.9504</td>\n",
       "      <td>-7,295.6061</td>\n",
       "      <td>78.7207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.2418</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,263.7069</td>\n",
       "      <td>-7,384.0574</td>\n",
       "      <td>-7,366.7678</td>\n",
       "      <td>-7,298.5480</td>\n",
       "      <td>-7,164.9504</td>\n",
       "      <td>-7,295.6061</td>\n",
       "      <td>78.7207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.1599</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,263.7069</td>\n",
       "      <td>-7,384.0574</td>\n",
       "      <td>-7,366.7678</td>\n",
       "      <td>-7,298.5480</td>\n",
       "      <td>-7,164.9504</td>\n",
       "      <td>-7,295.6061</td>\n",
       "      <td>78.7207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.1252</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,263.7069</td>\n",
       "      <td>-7,384.0574</td>\n",
       "      <td>-7,366.7678</td>\n",
       "      <td>-7,298.5480</td>\n",
       "      <td>-7,164.9504</td>\n",
       "      <td>-7,295.6061</td>\n",
       "      <td>78.7207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0404</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,263.7069</td>\n",
       "      <td>-7,384.0574</td>\n",
       "      <td>-7,366.7678</td>\n",
       "      <td>-7,298.5480</td>\n",
       "      <td>-7,164.9504</td>\n",
       "      <td>-7,295.6061</td>\n",
       "      <td>78.7207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.2452</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,385.8588</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,249.8511</td>\n",
       "      <td>-7,305.6509</td>\n",
       "      <td>98.0199</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.1254</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,385.8588</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,249.8511</td>\n",
       "      <td>-7,305.6509</td>\n",
       "      <td>98.0199</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.1416</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,385.8588</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,249.8511</td>\n",
       "      <td>-7,305.6509</td>\n",
       "      <td>98.0199</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.2388</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,385.8588</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,249.8511</td>\n",
       "      <td>-7,305.6509</td>\n",
       "      <td>98.0199</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.1622</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,385.8588</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,249.8511</td>\n",
       "      <td>-7,305.6509</td>\n",
       "      <td>98.0199</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.1642</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,149.9699</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,385.8588</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,249.8511</td>\n",
       "      <td>-7,305.6509</td>\n",
       "      <td>98.0199</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.9919</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,244.6164</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,409.1114</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,210.6429</td>\n",
       "      <td>-7,321.3891</td>\n",
       "      <td>85.4089</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.3260</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,244.6164</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,409.1114</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,210.6429</td>\n",
       "      <td>-7,321.3891</td>\n",
       "      <td>85.4089</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.1128</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,244.6164</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,409.1114</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,210.6429</td>\n",
       "      <td>-7,321.3891</td>\n",
       "      <td>85.4089</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.1882</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,244.6164</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,409.1114</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,210.6429</td>\n",
       "      <td>-7,321.3891</td>\n",
       "      <td>85.4089</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.2186</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,244.6164</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,409.1114</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,210.6429</td>\n",
       "      <td>-7,321.3891</td>\n",
       "      <td>85.4089</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.2582</td>\n",
       "      <td>0.2656</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,244.6164</td>\n",
       "      <td>-7,424.3900</td>\n",
       "      <td>-7,409.1114</td>\n",
       "      <td>-7,318.1845</td>\n",
       "      <td>-7,210.6429</td>\n",
       "      <td>-7,321.3891</td>\n",
       "      <td>85.4089</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.9884</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.0334</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.9012</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.8960</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.9778</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.9618</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1771</td>\n",
       "      <td>0.2509</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.4718</td>\n",
       "      <td>0.4297</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0526</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.1064</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.9066</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.9398</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,448.4488</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,539.0946</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,562.3373</td>\n",
       "      <td>-7,579.4764</td>\n",
       "      <td>106.9455</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2694</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.1310</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0512</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.9097</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.0290</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.0576</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.9306</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.2646</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.9274</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0636</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0596</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1312</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,474.4757</td>\n",
       "      <td>-7,774.5443</td>\n",
       "      <td>-7,602.5037</td>\n",
       "      <td>-7,572.9568</td>\n",
       "      <td>-7,526.7858</td>\n",
       "      <td>-7,590.2533</td>\n",
       "      <td>101.8283</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "26         2.2358        0.0716           0.0026          0.0005   \n",
       "46         2.1662        0.1377           0.0028          0.0008   \n",
       "42         2.1380        0.1416           0.0022          0.0007   \n",
       "30         2.1718        0.1991           0.0026          0.0005   \n",
       "10         2.1878        0.1794           0.0026          0.0005   \n",
       "14         2.2582        0.1782           0.0026          0.0010   \n",
       "44         2.3854        0.0369           0.0024          0.0005   \n",
       "24         2.0112        0.0874           0.0024          0.0008   \n",
       "40         2.2418        0.1974           0.0024          0.0008   \n",
       "8          2.1599        0.1049           0.0020          0.0000   \n",
       "28         2.1252        0.1764           0.0020          0.0006   \n",
       "12         2.0404        0.1153           0.0028          0.0004   \n",
       "43         2.2452        0.2760           0.0024          0.0005   \n",
       "31         2.1254        0.2072           0.0022          0.0004   \n",
       "27         2.1416        0.1566           0.0016          0.0005   \n",
       "47         2.2388        0.0695           0.0024          0.0008   \n",
       "11         2.1622        0.2771           0.0028          0.0004   \n",
       "15         2.1642        0.1749           0.0022          0.0004   \n",
       "13         1.9919        0.0589           0.0018          0.0004   \n",
       "41         2.3260        0.2394           0.0024          0.0005   \n",
       "45         2.1128        0.0329           0.0022          0.0004   \n",
       "9          2.1882        0.1521           0.0026          0.0005   \n",
       "25         2.2186        0.1068           0.0020          0.0000   \n",
       "29         2.2582        0.2656           0.0024          0.0005   \n",
       "6          1.9884        0.1634           0.0022          0.0007   \n",
       "35         2.0334        0.1895           0.0028          0.0004   \n",
       "34         1.9012        0.0715           0.0028          0.0004   \n",
       "7          1.8960        0.0953           0.0022          0.0004   \n",
       "38         1.9778        0.1058           0.0024          0.0008   \n",
       "39         1.9618        0.1474           0.0020          0.0000   \n",
       "3          2.1771        0.2509           0.0030          0.0011   \n",
       "23         2.4718        0.4297           0.0034          0.0008   \n",
       "22         2.0526        0.0957           0.0030          0.0011   \n",
       "2          2.1064        0.0948           0.0030          0.0006   \n",
       "19         1.9066        0.0543           0.0022          0.0004   \n",
       "18         1.9398        0.1625           0.0026          0.0010   \n",
       "4          2.2694        0.3604           0.0030          0.0006   \n",
       "5          2.1310        0.0743           0.0026          0.0005   \n",
       "16         2.0512        0.1780           0.0032          0.0004   \n",
       "32         1.9097        0.0905           0.0024          0.0005   \n",
       "37         2.0290        0.0857           0.0026          0.0005   \n",
       "36         2.0576        0.1799           0.0032          0.0007   \n",
       "33         1.9306        0.1073           0.0028          0.0004   \n",
       "17         2.2646        0.1910           0.0032          0.0007   \n",
       "1          1.9274        0.0784           0.0024          0.0005   \n",
       "21         2.0636        0.1599           0.0024          0.0005   \n",
       "20         2.0596        0.1637           0.0030          0.0006   \n",
       "0          2.1312        0.2618           0.0022          0.0004   \n",
       "\n",
       "   param_ccp_alpha param_max_depth param_min_impurity_decrease  \\\n",
       "26          0.0100               4                      0.1000   \n",
       "46          0.1000               4                           1   \n",
       "42          0.1000               4                      0.1000   \n",
       "30          0.0100               4                           1   \n",
       "10               0               4                      0.1000   \n",
       "14               0               4                           1   \n",
       "44          0.1000               4                           1   \n",
       "24          0.0100               4                      0.1000   \n",
       "40          0.1000               4                      0.1000   \n",
       "8                0               4                      0.1000   \n",
       "28          0.0100               4                           1   \n",
       "12               0               4                           1   \n",
       "43          0.1000               4                      0.1000   \n",
       "31          0.0100               4                           1   \n",
       "27          0.0100               4                      0.1000   \n",
       "47          0.1000               4                           1   \n",
       "11               0               4                      0.1000   \n",
       "15               0               4                           1   \n",
       "13               0               4                           1   \n",
       "41          0.1000               4                      0.1000   \n",
       "45          0.1000               4                           1   \n",
       "9                0               4                      0.1000   \n",
       "25          0.0100               4                      0.1000   \n",
       "29          0.0100               4                           1   \n",
       "6                0               3                           1   \n",
       "35          0.1000               3                      0.1000   \n",
       "34          0.1000               3                      0.1000   \n",
       "7                0               3                           1   \n",
       "38          0.1000               3                           1   \n",
       "39          0.1000               3                           1   \n",
       "3                0               3                      0.1000   \n",
       "23          0.0100               3                           1   \n",
       "22          0.0100               3                           1   \n",
       "2                0               3                      0.1000   \n",
       "19          0.0100               3                      0.1000   \n",
       "18          0.0100               3                      0.1000   \n",
       "4                0               3                           1   \n",
       "5                0               3                           1   \n",
       "16          0.0100               3                      0.1000   \n",
       "32          0.1000               3                      0.1000   \n",
       "37          0.1000               3                           1   \n",
       "36          0.1000               3                           1   \n",
       "33          0.1000               3                      0.1000   \n",
       "17          0.0100               3                      0.1000   \n",
       "1                0               3                      0.1000   \n",
       "21          0.0100               3                           1   \n",
       "20          0.0100               3                           1   \n",
       "0                0               3                      0.1000   \n",
       "\n",
       "   param_min_samples_leaf param_min_samples_split  split0_test_score  \\\n",
       "26                    100                      50        -7,149.9699   \n",
       "46                    100                      50        -7,149.9699   \n",
       "42                    100                      50        -7,149.9699   \n",
       "30                    100                      50        -7,149.9699   \n",
       "10                    100                      50        -7,149.9699   \n",
       "14                    100                      50        -7,149.9699   \n",
       "44                     20                      50        -7,257.2892   \n",
       "24                     20                      50        -7,263.7069   \n",
       "40                     20                      50        -7,263.7069   \n",
       "8                      20                      50        -7,263.7069   \n",
       "28                     20                      50        -7,263.7069   \n",
       "12                     20                      50        -7,263.7069   \n",
       "43                    100                     250        -7,149.9699   \n",
       "31                    100                     250        -7,149.9699   \n",
       "27                    100                     250        -7,149.9699   \n",
       "47                    100                     250        -7,149.9699   \n",
       "11                    100                     250        -7,149.9699   \n",
       "15                    100                     250        -7,149.9699   \n",
       "13                     20                     250        -7,244.6164   \n",
       "41                     20                     250        -7,244.6164   \n",
       "45                     20                     250        -7,244.6164   \n",
       "9                      20                     250        -7,244.6164   \n",
       "25                     20                     250        -7,244.6164   \n",
       "29                     20                     250        -7,244.6164   \n",
       "6                     100                      50        -7,448.4488   \n",
       "35                    100                     250        -7,448.4488   \n",
       "34                    100                      50        -7,448.4488   \n",
       "7                     100                     250        -7,448.4488   \n",
       "38                    100                      50        -7,448.4488   \n",
       "39                    100                     250        -7,448.4488   \n",
       "3                     100                     250        -7,448.4488   \n",
       "23                    100                     250        -7,448.4488   \n",
       "22                    100                      50        -7,448.4488   \n",
       "2                     100                      50        -7,448.4488   \n",
       "19                    100                     250        -7,448.4488   \n",
       "18                    100                      50        -7,448.4488   \n",
       "4                      20                      50        -7,474.4757   \n",
       "5                      20                     250        -7,474.4757   \n",
       "16                     20                      50        -7,474.4757   \n",
       "32                     20                      50        -7,474.4757   \n",
       "37                     20                     250        -7,474.4757   \n",
       "36                     20                      50        -7,474.4757   \n",
       "33                     20                     250        -7,474.4757   \n",
       "17                     20                     250        -7,474.4757   \n",
       "1                      20                     250        -7,474.4757   \n",
       "21                     20                     250        -7,474.4757   \n",
       "20                     20                      50        -7,474.4757   \n",
       "0                      20                      50        -7,474.4757   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "26        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "46        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "42        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "30        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "10        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "14        -7,424.3900        -7,349.1922        -7,316.5807   \n",
       "44        -7,384.0574        -7,366.7678        -7,298.5480   \n",
       "24        -7,384.0574        -7,366.7678        -7,298.5480   \n",
       "40        -7,384.0574        -7,366.7678        -7,298.5480   \n",
       "8         -7,384.0574        -7,366.7678        -7,298.5480   \n",
       "28        -7,384.0574        -7,366.7678        -7,298.5480   \n",
       "12        -7,384.0574        -7,366.7678        -7,298.5480   \n",
       "43        -7,424.3900        -7,385.8588        -7,318.1845   \n",
       "31        -7,424.3900        -7,385.8588        -7,318.1845   \n",
       "27        -7,424.3900        -7,385.8588        -7,318.1845   \n",
       "47        -7,424.3900        -7,385.8588        -7,318.1845   \n",
       "11        -7,424.3900        -7,385.8588        -7,318.1845   \n",
       "15        -7,424.3900        -7,385.8588        -7,318.1845   \n",
       "13        -7,424.3900        -7,409.1114        -7,318.1845   \n",
       "41        -7,424.3900        -7,409.1114        -7,318.1845   \n",
       "45        -7,424.3900        -7,409.1114        -7,318.1845   \n",
       "9         -7,424.3900        -7,409.1114        -7,318.1845   \n",
       "25        -7,424.3900        -7,409.1114        -7,318.1845   \n",
       "29        -7,424.3900        -7,409.1114        -7,318.1845   \n",
       "6         -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "35        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "34        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "7         -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "38        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "39        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "3         -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "23        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "22        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "2         -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "19        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "18        -7,774.5443        -7,539.0946        -7,572.9568   \n",
       "4         -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "5         -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "16        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "32        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "37        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "36        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "33        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "17        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "1         -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "21        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "20        -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "0         -7,774.5443        -7,602.5037        -7,572.9568   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "26        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "46        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "42        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "30        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "10        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "14        -7,217.4177      -7,291.5101         97.0939                1  \n",
       "44        -7,164.9504      -7,294.3226         79.2807                7  \n",
       "24        -7,164.9504      -7,295.6061         78.7207                8  \n",
       "40        -7,164.9504      -7,295.6061         78.7207                8  \n",
       "8         -7,164.9504      -7,295.6061         78.7207                8  \n",
       "28        -7,164.9504      -7,295.6061         78.7207                8  \n",
       "12        -7,164.9504      -7,295.6061         78.7207                8  \n",
       "43        -7,249.8511      -7,305.6509         98.0199               13  \n",
       "31        -7,249.8511      -7,305.6509         98.0199               13  \n",
       "27        -7,249.8511      -7,305.6509         98.0199               13  \n",
       "47        -7,249.8511      -7,305.6509         98.0199               13  \n",
       "11        -7,249.8511      -7,305.6509         98.0199               13  \n",
       "15        -7,249.8511      -7,305.6509         98.0199               13  \n",
       "13        -7,210.6429      -7,321.3891         85.4089               19  \n",
       "41        -7,210.6429      -7,321.3891         85.4089               19  \n",
       "45        -7,210.6429      -7,321.3891         85.4089               19  \n",
       "9         -7,210.6429      -7,321.3891         85.4089               19  \n",
       "25        -7,210.6429      -7,321.3891         85.4089               19  \n",
       "29        -7,210.6429      -7,321.3891         85.4089               19  \n",
       "6         -7,562.3373      -7,579.4764        106.9455               25  \n",
       "35        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "34        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "7         -7,562.3373      -7,579.4764        106.9455               25  \n",
       "38        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "39        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "3         -7,562.3373      -7,579.4764        106.9455               25  \n",
       "23        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "22        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "2         -7,562.3373      -7,579.4764        106.9455               25  \n",
       "19        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "18        -7,562.3373      -7,579.4764        106.9455               25  \n",
       "4         -7,526.7858      -7,590.2533        101.8283               37  \n",
       "5         -7,526.7858      -7,590.2533        101.8283               37  \n",
       "16        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "32        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "37        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "36        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "33        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "17        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "1         -7,526.7858      -7,590.2533        101.8283               37  \n",
       "21        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "20        -7,526.7858      -7,590.2533        101.8283               37  \n",
       "0         -7,526.7858      -7,590.2533        101.8283               37  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All within scores within 1 standard deviation away of the best score\n",
    "full_results.loc[full_results['mean_test_score'] - full_results['std_test_score'] <= decision_tree_tuning.best_score_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944da619",
   "metadata": {},
   "source": [
    "**You can then train a single decision tree for selected trees**\n",
    "\n",
    "If there is demand, we can create a function that quickly compares the structure and variables in multiple decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b9409",
   "metadata": {},
   "source": [
    "## Random Forest regression\n",
    "\n",
    "A Random Forest model is built as a collection of independently developed decision trees, where the simple average is taken as the prediction. Each tree has a degree of randomness, to avoid every tree becoming the same one (e.g. by sampling a subset of data for each tree, and subset of variables to consider for splitting at each node). \n",
    "\n",
    "The independence across trees allows the expected outcome to stay constant while variance of outcome is reduced as the number of trees increase. Thereby addressing the issues with instability of individual decision trees. \n",
    "\n",
    "As a model that aggregates a number of separate models (decision trees), Random Forest is a so-called Ensemble. It has the same parameters as a single decision tree, plus a number of ensembling parameters:\n",
    "* Number of trees\n",
    "* Sampling rate of dataset for building each tree. A benefit of sampling the data for use in each tree, is that each tree will naturally have its own 'out of sample' dataset, so-called \"Out-Of-Bag\", that can be used to measure performance without cross-validation. (Cross-validation is still the norm for hyperparameter tuning)\n",
    "\n",
    "See syntax here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b570981",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variables = ['Recent', 'Automatic', 'log_Levy', 'log_Mileage', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', 'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2e1df",
   "metadata": {},
   "source": [
    "### Tuning the random forest model using Grid Search\n",
    "\n",
    "We use Grid Search here, though the following are also good options given the very many parameters to consider:\n",
    "* Randomized search: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html. See the Gradient Boosting model for an example of this.\n",
    "* Bayesian tuning. It is available in a different library https://scikit-optimize.github.io/stable/, and examples will be provided in a future notebook template.\n",
    "\n",
    "(Read more about Hyperparameter tuning in the Decision Tree section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9df50a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7612.168 total time=  13.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7940.983 total time=  13.4s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7807.578 total time=  12.7s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7802.628 total time=  13.8s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7686.263 total time=  13.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7618.658 total time=  12.5s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7915.518 total time=  12.5s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7818.988 total time=  12.9s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7780.535 total time=  12.9s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7703.994 total time=  12.5s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7623.058 total time=  13.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7933.152 total time=  13.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7795.966 total time=  13.8s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7766.314 total time=  12.4s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-7697.929 total time=  12.6s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7596.612 total time=  13.5s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7930.381 total time=  13.7s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7772.682 total time=  14.7s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7771.270 total time=  13.6s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=2, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7691.489 total time=  12.4s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6691.596 total time=  18.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6838.745 total time=  20.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6815.098 total time=  18.8s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6807.948 total time=  17.3s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6687.441 total time=  19.9s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6959.115 total time=  18.8s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7084.800 total time=  17.7s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7002.928 total time=  19.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6964.427 total time=  18.7s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=0.01, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6889.193 total time=  19.4s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6721.096 total time=  20.9s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6851.617 total time=  19.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6807.206 total time=  19.7s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6783.986 total time=  19.8s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=25, n_estimators=50;, score=-6669.178 total time=  21.3s\n",
      "[CV 1/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6948.998 total time=  18.7s\n",
      "[CV 2/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-7072.110 total time=  19.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6996.100 total time=  21.3s\n",
      "[CV 4/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6981.072 total time=  20.4s\n",
      "[CV 5/5] END ccp_alpha=0.1, max_depth=5, max_samples=0.5, min_impurity_decrease=1, min_samples_leaf=25, min_samples_split=250, n_estimators=50;, score=-6893.708 total time=  19.7s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_samples\": [0.5],\n",
    "    \"max_depth\": [2,5],\n",
    "    \"min_samples_split\":[25, 250],\n",
    "    \"min_samples_leaf\": [25],\n",
    "    \"min_impurity_decrease\": [0.01, 1],\n",
    "    \"ccp_alpha\": [0.1]\n",
    "}\n",
    "# Fixed parameters can also be passed directly in the model instantiation\n",
    "random_forest_model = ensemble.RandomForestRegressor(criterion='absolute_error', bootstrap=True)\n",
    "\n",
    "random_forest_tuning = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", cv=5, verbose=3)\n",
    "random_forest_tuning = random_forest_tuning.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88583485",
   "metadata": {},
   "source": [
    "**Parsing the results and viewing the hyperparameters with the best score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c19b4e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ccp_alpha</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.2387</td>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>-6,721.0960</td>\n",
       "      <td>-6,851.6174</td>\n",
       "      <td>-6,807.2059</td>\n",
       "      <td>-6,783.9856</td>\n",
       "      <td>-6,669.1780</td>\n",
       "      <td>-6,766.6166</td>\n",
       "      <td>64.4061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.9409</td>\n",
       "      <td>1.0734</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>-6,691.5957</td>\n",
       "      <td>-6,838.7450</td>\n",
       "      <td>-6,815.0978</td>\n",
       "      <td>-6,807.9480</td>\n",
       "      <td>-6,687.4410</td>\n",
       "      <td>-6,768.1655</td>\n",
       "      <td>65.0325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.9245</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>250</td>\n",
       "      <td>50</td>\n",
       "      <td>-6,948.9979</td>\n",
       "      <td>-7,072.1095</td>\n",
       "      <td>-6,996.1001</td>\n",
       "      <td>-6,981.0720</td>\n",
       "      <td>-6,893.7076</td>\n",
       "      <td>-6,978.3974</td>\n",
       "      <td>58.5478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.8240</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>250</td>\n",
       "      <td>50</td>\n",
       "      <td>-6,959.1145</td>\n",
       "      <td>-7,084.7997</td>\n",
       "      <td>-7,002.9282</td>\n",
       "      <td>-6,964.4268</td>\n",
       "      <td>-6,889.1934</td>\n",
       "      <td>-6,980.0925</td>\n",
       "      <td>63.9269</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6738</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>250</td>\n",
       "      <td>50</td>\n",
       "      <td>-7,596.6124</td>\n",
       "      <td>-7,930.3810</td>\n",
       "      <td>-7,772.6816</td>\n",
       "      <td>-7,771.2696</td>\n",
       "      <td>-7,691.4891</td>\n",
       "      <td>-7,752.4867</td>\n",
       "      <td>109.9314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        20.2387        0.8161           0.0182          0.0057   \n",
       "4        18.9409        1.0734           0.0142          0.0031   \n",
       "7        19.9245        0.9400           0.0168          0.0052   \n",
       "5        18.8240        0.5699           0.0120          0.0009   \n",
       "3        13.6738        0.7250           0.0116          0.0008   \n",
       "\n",
       "  param_ccp_alpha param_max_depth param_max_samples  \\\n",
       "6          0.1000               5            0.5000   \n",
       "4          0.1000               5            0.5000   \n",
       "7          0.1000               5            0.5000   \n",
       "5          0.1000               5            0.5000   \n",
       "3          0.1000               2            0.5000   \n",
       "\n",
       "  param_min_impurity_decrease param_min_samples_leaf param_min_samples_split  \\\n",
       "6                           1                     25                      25   \n",
       "4                      0.0100                     25                      25   \n",
       "7                           1                     25                     250   \n",
       "5                      0.0100                     25                     250   \n",
       "3                           1                     25                     250   \n",
       "\n",
       "  param_n_estimators  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "6                 50        -6,721.0960        -6,851.6174        -6,807.2059   \n",
       "4                 50        -6,691.5957        -6,838.7450        -6,815.0978   \n",
       "7                 50        -6,948.9979        -7,072.1095        -6,996.1001   \n",
       "5                 50        -6,959.1145        -7,084.7997        -7,002.9282   \n",
       "3                 50        -7,596.6124        -7,930.3810        -7,772.6816   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "6        -6,783.9856        -6,669.1780      -6,766.6166         64.4061   \n",
       "4        -6,807.9480        -6,687.4410      -6,768.1655         65.0325   \n",
       "7        -6,981.0720        -6,893.7076      -6,978.3974         58.5478   \n",
       "5        -6,964.4268        -6,889.1934      -6,980.0925         63.9269   \n",
       "3        -7,771.2696        -7,691.4891      -7,752.4867        109.9314   \n",
       "\n",
       "   rank_test_score  \n",
       "6                1  \n",
       "4                2  \n",
       "7                3  \n",
       "5                4  \n",
       "3                5  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.DataFrame(random_forest_tuning.cv_results_).drop(columns=['params']).sort_values(by=['mean_test_score'], ascending=False)\n",
    "full_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18e52920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -6766.616569918381\n",
      "Best index: 6\n",
      "Best parameters: {'ccp_alpha': 0.1, 'max_depth': 5, 'max_samples': 0.5, 'min_impurity_decrease': 1, 'min_samples_leaf': 25, 'min_samples_split': 25, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Best\n",
    "print(\"Best score: {}\".format(random_forest_tuning.best_score_))\n",
    "print(\"Best index: {}\".format(random_forest_tuning.best_index_))\n",
    "print(\"Best parameters: {}\".format(random_forest_tuning.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca10ef",
   "metadata": {},
   "source": [
    "### Fit a single random forest model\n",
    "\n",
    "We can fit a single random forest model by specifying the parameters it should have. The number of trees can be set higher than needed, as you can trace the model performance as the number of trees increases.\n",
    "\n",
    "Here, we use the best parameters from the Hyper-Parameter tuning above. Instead of typing out each argument, we can use a dictionary to pass the parameters to the function, with help of the ** symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c4be04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 500\n",
      "building tree 3 of 500\n",
      "building tree 4 of 500\n",
      "building tree 5 of 500\n",
      "building tree 6 of 500\n",
      "building tree 7 of 500\n",
      "building tree 8 of 500\n",
      "building tree 9 of 500\n",
      "building tree 10 of 500\n",
      "building tree 11 of 500\n",
      "building tree 12 of 500\n",
      "building tree 13 of 500\n",
      "building tree 14 of 500\n",
      "building tree 15 of 500\n",
      "building tree 16 of 500\n",
      "building tree 17 of 500\n",
      "building tree 18 of 500\n",
      "building tree 19 of 500\n",
      "building tree 20 of 500\n",
      "building tree 21 of 500\n",
      "building tree 22 of 500\n",
      "building tree 23 of 500\n",
      "building tree 24 of 500\n",
      "building tree 25 of 500\n",
      "building tree 26 of 500\n",
      "building tree 27 of 500\n",
      "building tree 28 of 500\n",
      "building tree 29 of 500\n",
      "building tree 30 of 500\n",
      "building tree 31 of 500\n",
      "building tree 32 of 500\n",
      "building tree 33 of 500\n",
      "building tree 34 of 500\n",
      "building tree 35 of 500\n",
      "building tree 36 of 500\n",
      "building tree 37 of 500\n",
      "building tree 38 of 500\n",
      "building tree 39 of 500\n",
      "building tree 40 of 500\n",
      "building tree 41 of 500\n",
      "building tree 42 of 500\n",
      "building tree 43 of 500\n",
      "building tree 44 of 500\n",
      "building tree 45 of 500\n",
      "building tree 46 of 500\n",
      "building tree 47 of 500\n",
      "building tree 48 of 500\n",
      "building tree 49 of 500\n",
      "building tree 50 of 500\n",
      "building tree 51 of 500\n",
      "building tree 52 of 500\n",
      "building tree 53 of 500\n",
      "building tree 54 of 500\n",
      "building tree 55 of 500\n",
      "building tree 56 of 500\n",
      "building tree 57 of 500\n",
      "building tree 58 of 500\n",
      "building tree 59 of 500\n",
      "building tree 60 of 500\n",
      "building tree 61 of 500\n",
      "building tree 62 of 500\n",
      "building tree 63 of 500\n",
      "building tree 64 of 500\n",
      "building tree 65 of 500\n",
      "building tree 66 of 500\n",
      "building tree 67 of 500\n",
      "building tree 68 of 500\n",
      "building tree 69 of 500\n",
      "building tree 70 of 500\n",
      "building tree 71 of 500\n",
      "building tree 72 of 500\n",
      "building tree 73 of 500\n",
      "building tree 74 of 500\n",
      "building tree 75 of 500\n",
      "building tree 76 of 500\n",
      "building tree 77 of 500\n",
      "building tree 78 of 500\n",
      "building tree 79 of 500\n",
      "building tree 80 of 500\n",
      "building tree 81 of 500\n",
      "building tree 82 of 500\n",
      "building tree 83 of 500\n",
      "building tree 84 of 500\n",
      "building tree 85 of 500\n",
      "building tree 86 of 500\n",
      "building tree 87 of 500\n",
      "building tree 88 of 500\n",
      "building tree 89 of 500\n",
      "building tree 90 of 500\n",
      "building tree 91 of 500\n",
      "building tree 92 of 500\n",
      "building tree 93 of 500\n",
      "building tree 94 of 500\n",
      "building tree 95 of 500\n",
      "building tree 96 of 500\n",
      "building tree 97 of 500\n",
      "building tree 98 of 500\n",
      "building tree 99 of 500\n",
      "building tree 100 of 500\n",
      "building tree 101 of 500\n",
      "building tree 102 of 500\n",
      "building tree 103 of 500\n",
      "building tree 104 of 500\n",
      "building tree 105 of 500\n",
      "building tree 106 of 500\n",
      "building tree 107 of 500\n",
      "building tree 108 of 500\n",
      "building tree 109 of 500\n",
      "building tree 110 of 500\n",
      "building tree 111 of 500\n",
      "building tree 112 of 500\n",
      "building tree 113 of 500\n",
      "building tree 114 of 500\n",
      "building tree 115 of 500\n",
      "building tree 116 of 500\n",
      "building tree 117 of 500\n",
      "building tree 118 of 500\n",
      "building tree 119 of 500\n",
      "building tree 120 of 500\n",
      "building tree 121 of 500\n",
      "building tree 122 of 500\n",
      "building tree 123 of 500\n",
      "building tree 124 of 500\n",
      "building tree 125 of 500\n",
      "building tree 126 of 500\n",
      "building tree 127 of 500\n",
      "building tree 128 of 500\n",
      "building tree 129 of 500\n",
      "building tree 130 of 500\n",
      "building tree 131 of 500\n",
      "building tree 132 of 500\n",
      "building tree 133 of 500\n",
      "building tree 134 of 500\n",
      "building tree 135 of 500\n",
      "building tree 136 of 500\n",
      "building tree 137 of 500\n",
      "building tree 138 of 500\n",
      "building tree 139 of 500\n",
      "building tree 140 of 500\n",
      "building tree 141 of 500\n",
      "building tree 142 of 500\n",
      "building tree 143 of 500\n",
      "building tree 144 of 500\n",
      "building tree 145 of 500\n",
      "building tree 146 of 500\n",
      "building tree 147 of 500\n",
      "building tree 148 of 500\n",
      "building tree 149 of 500\n",
      "building tree 150 of 500\n",
      "building tree 151 of 500\n",
      "building tree 152 of 500\n",
      "building tree 153 of 500\n",
      "building tree 154 of 500\n",
      "building tree 155 of 500\n",
      "building tree 156 of 500\n",
      "building tree 157 of 500\n",
      "building tree 158 of 500\n",
      "building tree 159 of 500\n",
      "building tree 160 of 500\n",
      "building tree 161 of 500\n",
      "building tree 162 of 500\n",
      "building tree 163 of 500\n",
      "building tree 164 of 500\n",
      "building tree 165 of 500\n",
      "building tree 166 of 500\n",
      "building tree 167 of 500\n",
      "building tree 168 of 500\n",
      "building tree 169 of 500\n",
      "building tree 170 of 500\n",
      "building tree 171 of 500\n",
      "building tree 172 of 500\n",
      "building tree 173 of 500\n",
      "building tree 174 of 500\n",
      "building tree 175 of 500\n",
      "building tree 176 of 500\n",
      "building tree 177 of 500\n",
      "building tree 178 of 500\n",
      "building tree 179 of 500\n",
      "building tree 180 of 500\n",
      "building tree 181 of 500\n",
      "building tree 182 of 500\n",
      "building tree 183 of 500\n",
      "building tree 184 of 500\n",
      "building tree 185 of 500\n",
      "building tree 186 of 500\n",
      "building tree 187 of 500\n",
      "building tree 188 of 500\n",
      "building tree 189 of 500\n",
      "building tree 190 of 500\n",
      "building tree 191 of 500\n",
      "building tree 192 of 500\n",
      "building tree 193 of 500\n",
      "building tree 194 of 500\n",
      "building tree 195 of 500\n",
      "building tree 196 of 500\n",
      "building tree 197 of 500\n",
      "building tree 198 of 500\n",
      "building tree 199 of 500\n",
      "building tree 200 of 500\n",
      "building tree 201 of 500\n",
      "building tree 202 of 500\n",
      "building tree 203 of 500\n",
      "building tree 204 of 500\n",
      "building tree 205 of 500\n",
      "building tree 206 of 500\n",
      "building tree 207 of 500\n",
      "building tree 208 of 500\n",
      "building tree 209 of 500\n",
      "building tree 210 of 500\n",
      "building tree 211 of 500\n",
      "building tree 212 of 500\n",
      "building tree 213 of 500\n",
      "building tree 214 of 500\n",
      "building tree 215 of 500\n",
      "building tree 216 of 500\n",
      "building tree 217 of 500\n",
      "building tree 218 of 500\n",
      "building tree 219 of 500\n",
      "building tree 220 of 500\n",
      "building tree 221 of 500\n",
      "building tree 222 of 500\n",
      "building tree 223 of 500\n",
      "building tree 224 of 500\n",
      "building tree 225 of 500\n",
      "building tree 226 of 500\n",
      "building tree 227 of 500\n",
      "building tree 228 of 500\n",
      "building tree 229 of 500\n",
      "building tree 230 of 500\n",
      "building tree 231 of 500\n",
      "building tree 232 of 500\n",
      "building tree 233 of 500\n",
      "building tree 234 of 500\n",
      "building tree 235 of 500\n",
      "building tree 236 of 500\n",
      "building tree 237 of 500\n",
      "building tree 238 of 500\n",
      "building tree 239 of 500\n",
      "building tree 240 of 500\n",
      "building tree 241 of 500\n",
      "building tree 242 of 500\n",
      "building tree 243 of 500\n",
      "building tree 244 of 500\n",
      "building tree 245 of 500\n",
      "building tree 246 of 500\n",
      "building tree 247 of 500\n",
      "building tree 248 of 500\n",
      "building tree 249 of 500\n",
      "building tree 250 of 500\n",
      "building tree 251 of 500\n",
      "building tree 252 of 500\n",
      "building tree 253 of 500\n",
      "building tree 254 of 500\n",
      "building tree 255 of 500\n",
      "building tree 256 of 500\n",
      "building tree 257 of 500\n",
      "building tree 258 of 500\n",
      "building tree 259 of 500\n",
      "building tree 260 of 500\n",
      "building tree 261 of 500\n",
      "building tree 262 of 500\n",
      "building tree 263 of 500\n",
      "building tree 264 of 500\n",
      "building tree 265 of 500\n",
      "building tree 266 of 500\n",
      "building tree 267 of 500\n",
      "building tree 268 of 500\n",
      "building tree 269 of 500\n",
      "building tree 270 of 500\n",
      "building tree 271 of 500\n",
      "building tree 272 of 500\n",
      "building tree 273 of 500\n",
      "building tree 274 of 500\n",
      "building tree 275 of 500\n",
      "building tree 276 of 500\n",
      "building tree 277 of 500\n",
      "building tree 278 of 500\n",
      "building tree 279 of 500\n",
      "building tree 280 of 500\n",
      "building tree 281 of 500\n",
      "building tree 282 of 500\n",
      "building tree 283 of 500\n",
      "building tree 284 of 500\n",
      "building tree 285 of 500\n",
      "building tree 286 of 500\n",
      "building tree 287 of 500\n",
      "building tree 288 of 500\n",
      "building tree 289 of 500\n",
      "building tree 290 of 500\n",
      "building tree 291 of 500\n",
      "building tree 292 of 500\n",
      "building tree 293 of 500\n",
      "building tree 294 of 500\n",
      "building tree 295 of 500\n",
      "building tree 296 of 500\n",
      "building tree 297 of 500\n",
      "building tree 298 of 500\n",
      "building tree 299 of 500\n",
      "building tree 300 of 500\n",
      "building tree 301 of 500\n",
      "building tree 302 of 500\n",
      "building tree 303 of 500\n",
      "building tree 304 of 500\n",
      "building tree 305 of 500\n",
      "building tree 306 of 500\n",
      "building tree 307 of 500\n",
      "building tree 308 of 500\n",
      "building tree 309 of 500\n",
      "building tree 310 of 500\n",
      "building tree 311 of 500\n",
      "building tree 312 of 500\n",
      "building tree 313 of 500\n",
      "building tree 314 of 500\n",
      "building tree 315 of 500\n",
      "building tree 316 of 500\n",
      "building tree 317 of 500\n",
      "building tree 318 of 500\n",
      "building tree 319 of 500\n",
      "building tree 320 of 500\n",
      "building tree 321 of 500\n",
      "building tree 322 of 500\n",
      "building tree 323 of 500\n",
      "building tree 324 of 500\n",
      "building tree 325 of 500\n",
      "building tree 326 of 500\n",
      "building tree 327 of 500\n",
      "building tree 328 of 500\n",
      "building tree 329 of 500\n",
      "building tree 330 of 500\n",
      "building tree 331 of 500\n",
      "building tree 332 of 500\n",
      "building tree 333 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 334 of 500\n",
      "building tree 335 of 500\n",
      "building tree 336 of 500\n",
      "building tree 337 of 500\n",
      "building tree 338 of 500\n",
      "building tree 339 of 500\n",
      "building tree 340 of 500\n",
      "building tree 341 of 500\n",
      "building tree 342 of 500\n",
      "building tree 343 of 500\n",
      "building tree 344 of 500\n",
      "building tree 345 of 500\n",
      "building tree 346 of 500\n",
      "building tree 347 of 500\n",
      "building tree 348 of 500\n",
      "building tree 349 of 500\n",
      "building tree 350 of 500\n",
      "building tree 351 of 500\n",
      "building tree 352 of 500\n",
      "building tree 353 of 500\n",
      "building tree 354 of 500\n",
      "building tree 355 of 500\n",
      "building tree 356 of 500\n",
      "building tree 357 of 500\n",
      "building tree 358 of 500\n",
      "building tree 359 of 500\n",
      "building tree 360 of 500\n",
      "building tree 361 of 500\n",
      "building tree 362 of 500\n",
      "building tree 363 of 500\n",
      "building tree 364 of 500\n",
      "building tree 365 of 500\n",
      "building tree 366 of 500\n",
      "building tree 367 of 500\n",
      "building tree 368 of 500\n",
      "building tree 369 of 500\n",
      "building tree 370 of 500\n",
      "building tree 371 of 500\n",
      "building tree 372 of 500\n",
      "building tree 373 of 500\n",
      "building tree 374 of 500\n",
      "building tree 375 of 500\n",
      "building tree 376 of 500\n",
      "building tree 377 of 500\n",
      "building tree 378 of 500\n",
      "building tree 379 of 500\n",
      "building tree 380 of 500\n",
      "building tree 381 of 500\n",
      "building tree 382 of 500\n",
      "building tree 383 of 500\n",
      "building tree 384 of 500\n",
      "building tree 385 of 500\n",
      "building tree 386 of 500\n",
      "building tree 387 of 500\n",
      "building tree 388 of 500\n",
      "building tree 389 of 500\n",
      "building tree 390 of 500\n",
      "building tree 391 of 500\n",
      "building tree 392 of 500\n",
      "building tree 393 of 500\n",
      "building tree 394 of 500\n",
      "building tree 395 of 500\n",
      "building tree 396 of 500\n",
      "building tree 397 of 500\n",
      "building tree 398 of 500\n",
      "building tree 399 of 500\n",
      "building tree 400 of 500\n",
      "building tree 401 of 500\n",
      "building tree 402 of 500\n",
      "building tree 403 of 500\n",
      "building tree 404 of 500\n",
      "building tree 405 of 500\n",
      "building tree 406 of 500\n",
      "building tree 407 of 500\n",
      "building tree 408 of 500\n",
      "building tree 409 of 500\n",
      "building tree 410 of 500\n",
      "building tree 411 of 500\n",
      "building tree 412 of 500\n",
      "building tree 413 of 500\n",
      "building tree 414 of 500\n",
      "building tree 415 of 500\n",
      "building tree 416 of 500\n",
      "building tree 417 of 500\n",
      "building tree 418 of 500\n",
      "building tree 419 of 500\n",
      "building tree 420 of 500\n",
      "building tree 421 of 500\n",
      "building tree 422 of 500\n",
      "building tree 423 of 500\n",
      "building tree 424 of 500\n",
      "building tree 425 of 500\n",
      "building tree 426 of 500\n",
      "building tree 427 of 500\n",
      "building tree 428 of 500\n",
      "building tree 429 of 500\n",
      "building tree 430 of 500\n",
      "building tree 431 of 500\n",
      "building tree 432 of 500\n",
      "building tree 433 of 500\n",
      "building tree 434 of 500\n",
      "building tree 435 of 500\n",
      "building tree 436 of 500\n",
      "building tree 437 of 500\n",
      "building tree 438 of 500\n",
      "building tree 439 of 500\n",
      "building tree 440 of 500\n",
      "building tree 441 of 500\n",
      "building tree 442 of 500\n",
      "building tree 443 of 500\n",
      "building tree 444 of 500\n",
      "building tree 445 of 500\n",
      "building tree 446 of 500\n",
      "building tree 447 of 500\n",
      "building tree 448 of 500\n",
      "building tree 449 of 500\n",
      "building tree 450 of 500\n",
      "building tree 451 of 500\n",
      "building tree 452 of 500\n",
      "building tree 453 of 500\n",
      "building tree 454 of 500\n",
      "building tree 455 of 500\n",
      "building tree 456 of 500\n",
      "building tree 457 of 500\n",
      "building tree 458 of 500\n",
      "building tree 459 of 500\n",
      "building tree 460 of 500\n",
      "building tree 461 of 500\n",
      "building tree 462 of 500\n",
      "building tree 463 of 500\n",
      "building tree 464 of 500\n",
      "building tree 465 of 500\n",
      "building tree 466 of 500\n",
      "building tree 467 of 500\n",
      "building tree 468 of 500\n",
      "building tree 469 of 500\n",
      "building tree 470 of 500\n",
      "building tree 471 of 500\n",
      "building tree 472 of 500\n",
      "building tree 473 of 500\n",
      "building tree 474 of 500\n",
      "building tree 475 of 500\n",
      "building tree 476 of 500\n",
      "building tree 477 of 500\n",
      "building tree 478 of 500\n",
      "building tree 479 of 500\n",
      "building tree 480 of 500\n",
      "building tree 481 of 500\n",
      "building tree 482 of 500\n",
      "building tree 483 of 500\n",
      "building tree 484 of 500\n",
      "building tree 485 of 500\n",
      "building tree 486 of 500\n",
      "building tree 487 of 500\n",
      "building tree 488 of 500\n",
      "building tree 489 of 500\n",
      "building tree 490 of 500\n",
      "building tree 491 of 500\n",
      "building tree 492 of 500\n",
      "building tree 493 of 500\n",
      "building tree 494 of 500\n",
      "building tree 495 of 500\n",
      "building tree 496 of 500\n",
      "building tree 497 of 500\n",
      "building tree 498 of 500\n",
      "building tree 499 of 500\n",
      "building tree 500 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  5.4min finished\n"
     ]
    }
   ],
   "source": [
    "best_parameters = {'ccp_alpha': 0.1, 'max_depth': 5, 'max_samples': 0.5, 'min_impurity_decrease': 0.01, \n",
    "                   'min_samples_leaf': 25, 'min_samples_split': 25, 'n_estimators': 500}\n",
    "random_forest_model = ensemble.RandomForestRegressor(criterion='absolute_error', bootstrap=True, **best_parameters, \n",
    "                                                     oob_score=True, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "random_forest_model_fitted = random_forest_model.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12b7d6",
   "metadata": {},
   "source": [
    "**Variable importance**\n",
    "\n",
    "We can't easily visualize a random forest with hundreds of trees like we could for a single decision tree, and we don't have variable coefficients like a linear model. Therefore, we need other techniques to understand the importance of each variable in the model.\n",
    "\n",
    "Variable importance (a.k.a. feature importance) is therefore often calculated, and measure the impact of a variable on the model fit. The RandomForestRegressor provides a simple estimate of feature importance, based on the (normalized) total reduction of the error term brought by that feature. \n",
    "\n",
    "This estimate doesn't work well for features with very many unique values (e.g. continuous variables). Sklearn provides a model-agnostic feature importance metric, based on the impact of a variable on model fit if that variable is permutated (shuffled). This is accomplished using https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance and is covered in the notebook for Model Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b46c83a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_encoded</td>\n",
       "      <td>0.6546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>0.2074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage</td>\n",
       "      <td>0.0562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy</td>\n",
       "      <td>0.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Variable  Importance\n",
       "13                  Model_encoded      0.6546\n",
       "0                          Recent      0.2074\n",
       "3                     log_Mileage      0.0562\n",
       "2                        log_Levy      0.0480\n",
       "7       Cylinders_clean_7 or more      0.0154\n",
       "4             Category_clean_Jeep      0.0074\n",
       "6          Cylinders_clean_5 or 6      0.0057\n",
       "1                       Automatic      0.0023\n",
       "12       Manufacturer_clean_Other      0.0019\n",
       "9      Manufacturer_clean_HYUNDAI      0.0007\n",
       "5            Category_clean_Other      0.0005\n",
       "11  Manufacturer_clean_VOLKSWAGEN      0.0000\n",
       "10      Manufacturer_clean_NISSAN      0.0000\n",
       "8         Manufacturer_clean_FORD      0.0000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Variable\": random_forest_model_fitted.feature_names_in_, \"Importance\": random_forest_model_fitted.feature_importances_}).sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa0cb2",
   "metadata": {},
   "source": [
    "**Model performance on train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb69ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.3784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>6,650.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,143.4254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.4407\n",
       "1   MAPE      0.3784\n",
       "2    MAE  6,650.7840\n",
       "3   RMSE 11,143.4254"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model in-sample prediction and metrics\n",
    "random_forest_train_pred = random_forest_model_fitted.predict(X_train_num[x_variables])\n",
    "random_forest_train_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_train, random_forest_train_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_train, random_forest_train_pred), \n",
    "               metrics.mean_absolute_error(y_train, random_forest_train_pred), \n",
    "               metrics.mean_squared_error(y_train, random_forest_train_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "random_forest_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ac754b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.3938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>6,958.1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11,772.3896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Value\n",
       "0     r2      0.3813\n",
       "1   MAPE      0.3938\n",
       "2    MAE  6,958.1817\n",
       "3   RMSE 11,772.3896"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model out-of-sample prediction and metrics\n",
    "random_forest_test_pred = random_forest_model_fitted.predict(X_test_num[x_variables])\n",
    "random_forest_test_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"r2\", \"MAPE\", \"MAE\", \"RMSE\"],\n",
    "    \"Value\": [metrics.r2_score(y_test, random_forest_test_pred), \n",
    "               metrics.mean_absolute_percentage_error(y_test, random_forest_test_pred), \n",
    "               metrics.mean_absolute_error(y_test, random_forest_test_pred), \n",
    "               metrics.mean_squared_error(y_test, random_forest_test_pred, squared=False)]\n",
    "}\n",
    ")\n",
    "\n",
    "random_forest_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39666d",
   "metadata": {},
   "source": [
    "### Examine model performance across trees in random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17505364",
   "metadata": {},
   "source": [
    "Random Forest models do not overfit as the number of trees increases, but it is often useful to understand how model performance evolves as the number of trees increases, to limit model complexity / computational effort.\n",
    "\n",
    "While we can access each individual tree of a fitted random forest using: random_forest_model_fitted.estimators_ to generate predictions for each tree, it doesn't give us access to the out-of-bag prediction. \n",
    "\n",
    "To generate the out-of-bag predictions, we need to run Random Forest in an incremental manner, one tree at a time. This is easily accomplished using the \"warm_start\" argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b172b22b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 15\n",
      "Number of trees: 20\n",
      "Number of trees: 25\n",
      "Number of trees: 30\n",
      "Number of trees: 35\n",
      "Number of trees: 40\n",
      "Number of trees: 45\n",
      "Number of trees: 50\n",
      "Number of trees: 55\n",
      "Number of trees: 60\n",
      "Number of trees: 65\n",
      "Number of trees: 70\n",
      "Number of trees: 75\n",
      "Number of trees: 80\n",
      "Number of trees: 85\n",
      "Number of trees: 90\n",
      "Number of trees: 95\n",
      "Number of trees: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Trees</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.6418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.6423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.6447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0.6452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>0.6457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>0.6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>0.6436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>0.6437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75</td>\n",
       "      <td>0.6440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>85</td>\n",
       "      <td>0.6419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90</td>\n",
       "      <td>0.6416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>95</td>\n",
       "      <td>0.6444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Trees  Error\n",
       "0        15 0.6448\n",
       "1        20 0.6418\n",
       "2        25 0.6423\n",
       "3        30 0.6447\n",
       "4        35 0.6452\n",
       "5        40 0.6435\n",
       "6        45 0.6457\n",
       "7        50 0.6466\n",
       "8        55 0.6436\n",
       "9        60 0.6437\n",
       "10       65 0.6435\n",
       "11       70 0.6435\n",
       "12       75 0.6440\n",
       "13       80 0.6435\n",
       "14       85 0.6419\n",
       "15       90 0.6416\n",
       "16       95 0.6444\n",
       "17      100 0.6435"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_trees = 15\n",
    "max_trees = 100\n",
    "step_size = 5\n",
    "\n",
    "RF_model = ensemble.RandomForestRegressor(criterion='absolute_error', bootstrap=True, oob_score=True,\n",
    "                                          ccp_alpha = 0.1, max_depth = 3, \n",
    "                                          max_samples = 0.5, min_impurity_decrease = 0.01,\n",
    "                                          min_samples_leaf = 25, min_samples_split = 25)\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "for n_tree in range(min_trees, max_trees + 1, step_size):\n",
    "    print(\"Number of trees: {}\".format(n_tree))\n",
    "    \n",
    "    RF_model.set_params(n_estimators=n_tree)\n",
    "    RF_model.fit(X_train_num[x_variables], y_train)\n",
    "    \n",
    "    # Record the OOB error for each `n_estimators=i` setting.\n",
    "    oob_error = 1 - RF_model.oob_score_\n",
    "    error_rate.append((n_tree, oob_error))\n",
    "\n",
    "results = pd.DataFrame(error_rate, columns=[\"# Trees\", \"Error\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "75772b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "results.plot(x=\"# Trees\", y=\"Error\", kind='line', ax=ax)\n",
    "ax.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749534cc",
   "metadata": {},
   "source": [
    "**In this example, some more trees may be useful to improve stability**\n",
    "\n",
    "An even more complete example can be found here: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430e34d",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree Regression\n",
    "\n",
    "Gradient Boosted Models (GBM) work in an entirely different way compared to Random Forest Models, even though they are also built using a large number of small trees. \n",
    "\n",
    "Gradient Boosted Trees are decision trees that are built iteratively and not independently, where each subsequent tree attempts to predict the residuals of the sum of the prior trees, and thereby theoretically improving the overall fit. The total sum across all trees generates the prediction. \n",
    "\n",
    "The basic Gradient Boosted Tree has some drawbacks over more sophisticated methods:\n",
    "* Susceptible to overfitting (early stopping can be adopted to avoid too many trees)\n",
    "* Cannot be parallelized, since each tree is dependent on the prior trees\n",
    "\n",
    "Popular gradient boosting algorithms include xgboost, lightgbm, cat-boost have superior performance and speed. We will cover these in other notebook templates. \n",
    "\n",
    "**Parameters**\n",
    "\n",
    "GBT have additional parameters compared to a single decision tree:\n",
    "* **Number of trees** (Random Forest has this too)\n",
    "* **Subsampling rate** for each tree, which is 100% for basic gradient boosting (unlike Random Forest, where a smaller fraction is expected)\n",
    "* **Fraction of dataset** to set aside for validation, which is used for early stopping \n",
    "* **Stopping criteria**, set as number of iterations without improvement to validation fit, where amount of required improvement is provided as a **tolerance** value\n",
    "* **Learning rate** applied to each incremental tree to limit its contribution. There is a trade-off between learning rate and number of trees. Too high learning rate may risk overfitting easier\n",
    "\n",
    "For syntax, see: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "Read more about early stopping here: https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_early_stopping.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29fd0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variables = ['Recent', 'Automatic', 'log_Levy', 'log_Mileage', \n",
    "               'Category_clean_Jeep', 'Category_clean_Other',\n",
    "               'Cylinders_clean_5 or 6', 'Cylinders_clean_7 or more',\n",
    "               'Manufacturer_clean_FORD', 'Manufacturer_clean_HYUNDAI', 'Manufacturer_clean_NISSAN', 'Manufacturer_clean_VOLKSWAGEN', 'Manufacturer_clean_Other',\n",
    "               \"Model_encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddba5d9",
   "metadata": {},
   "source": [
    "### Tuning the gradient boosted tree regression using Randomized Search\n",
    "\n",
    "Given the large number of different parameters to set for Gradient Boosted Tree regression, we will use Randomized Search instead of Grid Search. Another popular method is Bayesian Search, which is not offered by sklearn, and is covered in a separate template for advanced tuning and feature selection. \n",
    "\n",
    "Overall, RandomizedSearchCV is set up similar to GridSearchCV (covered in Decision Tree and Random Forest sections), but instead of traversing all combinations of parameters, it randomizes the selection of parameter values. Note:\n",
    "* Possible values for a parameter can be provided as a list, or as a distribution. If any parameter range is provided as a distribution, sampling will always be 'with replacement', and if not, it will be 'without replacement'. It is highly recommended to use distributions for continuous variables. \n",
    "\n",
    "\n",
    "Syntax: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39cd56e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END ccp_alpha=1.307179170929219, learning_rate=0.15750347156220287, max_depth=5, max_features=sqrt, min_impurity_decrease=0.9643828028559964, min_samples_leaf=0.08724745351820354, min_samples_split=0.021233268092271995, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.307179170929219, learning_rate=0.15750347156220287, max_depth=5, max_features=sqrt, min_impurity_decrease=0.9643828028559964, min_samples_leaf=0.08724745351820354, min_samples_split=0.021233268092271995, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.307179170929219, learning_rate=0.15750347156220287, max_depth=5, max_features=sqrt, min_impurity_decrease=0.9643828028559964, min_samples_leaf=0.08724745351820354, min_samples_split=0.021233268092271995, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.307179170929219, learning_rate=0.15750347156220287, max_depth=5, max_features=sqrt, min_impurity_decrease=0.9643828028559964, min_samples_leaf=0.08724745351820354, min_samples_split=0.021233268092271995, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.307179170929219, learning_rate=0.15750347156220287, max_depth=5, max_features=sqrt, min_impurity_decrease=0.9643828028559964, min_samples_leaf=0.08724745351820354, min_samples_split=0.021233268092271995, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.08141924953817825, learning_rate=0.29859723067285293, max_depth=2, max_features=sqrt, min_impurity_decrease=1.6834814485061231, min_samples_leaf=0.02070823443867469, min_samples_split=0.07424695335824087, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.08141924953817825, learning_rate=0.29859723067285293, max_depth=2, max_features=sqrt, min_impurity_decrease=1.6834814485061231, min_samples_leaf=0.02070823443867469, min_samples_split=0.07424695335824087, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.08141924953817825, learning_rate=0.29859723067285293, max_depth=2, max_features=sqrt, min_impurity_decrease=1.6834814485061231, min_samples_leaf=0.02070823443867469, min_samples_split=0.07424695335824087, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.08141924953817825, learning_rate=0.29859723067285293, max_depth=2, max_features=sqrt, min_impurity_decrease=1.6834814485061231, min_samples_leaf=0.02070823443867469, min_samples_split=0.07424695335824087, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.08141924953817825, learning_rate=0.29859723067285293, max_depth=2, max_features=sqrt, min_impurity_decrease=1.6834814485061231, min_samples_leaf=0.02070823443867469, min_samples_split=0.07424695335824087, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.7843082556176826, learning_rate=0.19112825997619218, max_depth=2, max_features=sqrt, min_impurity_decrease=0.1391641619399091, min_samples_leaf=0.08853372043807507, min_samples_split=0.09526443992215418, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.7843082556176826, learning_rate=0.19112825997619218, max_depth=2, max_features=sqrt, min_impurity_decrease=0.1391641619399091, min_samples_leaf=0.08853372043807507, min_samples_split=0.09526443992215418, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7843082556176826, learning_rate=0.19112825997619218, max_depth=2, max_features=sqrt, min_impurity_decrease=0.1391641619399091, min_samples_leaf=0.08853372043807507, min_samples_split=0.09526443992215418, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7843082556176826, learning_rate=0.19112825997619218, max_depth=2, max_features=sqrt, min_impurity_decrease=0.1391641619399091, min_samples_leaf=0.08853372043807507, min_samples_split=0.09526443992215418, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.7843082556176826, learning_rate=0.19112825997619218, max_depth=2, max_features=sqrt, min_impurity_decrease=0.1391641619399091, min_samples_leaf=0.08853372043807507, min_samples_split=0.09526443992215418, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.8622868693550216, learning_rate=0.3077154765224539, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9640549691963953, min_samples_leaf=0.03396376836352886, min_samples_split=0.07066871938888039, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.8622868693550216, learning_rate=0.3077154765224539, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9640549691963953, min_samples_leaf=0.03396376836352886, min_samples_split=0.07066871938888039, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.8622868693550216, learning_rate=0.3077154765224539, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9640549691963953, min_samples_leaf=0.03396376836352886, min_samples_split=0.07066871938888039, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.8622868693550216, learning_rate=0.3077154765224539, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9640549691963953, min_samples_leaf=0.03396376836352886, min_samples_split=0.07066871938888039, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END ccp_alpha=1.8622868693550216, learning_rate=0.3077154765224539, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9640549691963953, min_samples_leaf=0.03396376836352886, min_samples_split=0.07066871938888039, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.7237541352151236, learning_rate=0.11755294897568072, max_depth=4, max_features=sqrt, min_impurity_decrease=1.3145070162809849, min_samples_leaf=0.07656829941452387, min_samples_split=0.05540872380043942, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.7237541352151236, learning_rate=0.11755294897568072, max_depth=4, max_features=sqrt, min_impurity_decrease=1.3145070162809849, min_samples_leaf=0.07656829941452387, min_samples_split=0.05540872380043942, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.7237541352151236, learning_rate=0.11755294897568072, max_depth=4, max_features=sqrt, min_impurity_decrease=1.3145070162809849, min_samples_leaf=0.07656829941452387, min_samples_split=0.05540872380043942, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.7237541352151236, learning_rate=0.11755294897568072, max_depth=4, max_features=sqrt, min_impurity_decrease=1.3145070162809849, min_samples_leaf=0.07656829941452387, min_samples_split=0.05540872380043942, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.7237541352151236, learning_rate=0.11755294897568072, max_depth=4, max_features=sqrt, min_impurity_decrease=1.3145070162809849, min_samples_leaf=0.07656829941452387, min_samples_split=0.05540872380043942, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.7701858732211992, learning_rate=0.5520988076986811, max_depth=5, max_features=sqrt, min_impurity_decrease=0.14911347228485594, min_samples_leaf=0.024462920975978533, min_samples_split=0.013330475245148478, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.7701858732211992, learning_rate=0.5520988076986811, max_depth=5, max_features=sqrt, min_impurity_decrease=0.14911347228485594, min_samples_leaf=0.024462920975978533, min_samples_split=0.013330475245148478, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END ccp_alpha=1.7701858732211992, learning_rate=0.5520988076986811, max_depth=5, max_features=sqrt, min_impurity_decrease=0.14911347228485594, min_samples_leaf=0.024462920975978533, min_samples_split=0.013330475245148478, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.7701858732211992, learning_rate=0.5520988076986811, max_depth=5, max_features=sqrt, min_impurity_decrease=0.14911347228485594, min_samples_leaf=0.024462920975978533, min_samples_split=0.013330475245148478, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.7701858732211992, learning_rate=0.5520988076986811, max_depth=5, max_features=sqrt, min_impurity_decrease=0.14911347228485594, min_samples_leaf=0.024462920975978533, min_samples_split=0.013330475245148478, n_estimators=100, subsample=1; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=1.3958502008194384, learning_rate=0.2991024417629675, max_depth=3, max_features=sqrt, min_impurity_decrease=0.362015020547406, min_samples_leaf=0.04324991717920135, min_samples_split=0.0018143202754672628, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.3958502008194384, learning_rate=0.2991024417629675, max_depth=3, max_features=sqrt, min_impurity_decrease=0.362015020547406, min_samples_leaf=0.04324991717920135, min_samples_split=0.0018143202754672628, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.3958502008194384, learning_rate=0.2991024417629675, max_depth=3, max_features=sqrt, min_impurity_decrease=0.362015020547406, min_samples_leaf=0.04324991717920135, min_samples_split=0.0018143202754672628, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.3958502008194384, learning_rate=0.2991024417629675, max_depth=3, max_features=sqrt, min_impurity_decrease=0.362015020547406, min_samples_leaf=0.04324991717920135, min_samples_split=0.0018143202754672628, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.3958502008194384, learning_rate=0.2991024417629675, max_depth=3, max_features=sqrt, min_impurity_decrease=0.362015020547406, min_samples_leaf=0.04324991717920135, min_samples_split=0.0018143202754672628, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.382875723377685, learning_rate=0.3348453260179184, max_depth=3, max_features=0.5, min_impurity_decrease=1.7826741025789183, min_samples_leaf=0.09182036244711153, min_samples_split=0.007312099367876846, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.382875723377685, learning_rate=0.3348453260179184, max_depth=3, max_features=0.5, min_impurity_decrease=1.7826741025789183, min_samples_leaf=0.09182036244711153, min_samples_split=0.007312099367876846, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.382875723377685, learning_rate=0.3348453260179184, max_depth=3, max_features=0.5, min_impurity_decrease=1.7826741025789183, min_samples_leaf=0.09182036244711153, min_samples_split=0.007312099367876846, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.382875723377685, learning_rate=0.3348453260179184, max_depth=3, max_features=0.5, min_impurity_decrease=1.7826741025789183, min_samples_leaf=0.09182036244711153, min_samples_split=0.007312099367876846, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.382875723377685, learning_rate=0.3348453260179184, max_depth=3, max_features=0.5, min_impurity_decrease=1.7826741025789183, min_samples_leaf=0.09182036244711153, min_samples_split=0.007312099367876846, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.09089588646009039, learning_rate=0.3192864478708265, max_depth=2, max_features=0.5, min_impurity_decrease=0.6204540679312003, min_samples_leaf=0.06819082419851494, min_samples_split=0.02090131508415152, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.09089588646009039, learning_rate=0.3192864478708265, max_depth=2, max_features=0.5, min_impurity_decrease=0.6204540679312003, min_samples_leaf=0.06819082419851494, min_samples_split=0.02090131508415152, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.09089588646009039, learning_rate=0.3192864478708265, max_depth=2, max_features=0.5, min_impurity_decrease=0.6204540679312003, min_samples_leaf=0.06819082419851494, min_samples_split=0.02090131508415152, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.09089588646009039, learning_rate=0.3192864478708265, max_depth=2, max_features=0.5, min_impurity_decrease=0.6204540679312003, min_samples_leaf=0.06819082419851494, min_samples_split=0.02090131508415152, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.09089588646009039, learning_rate=0.3192864478708265, max_depth=2, max_features=0.5, min_impurity_decrease=0.6204540679312003, min_samples_leaf=0.06819082419851494, min_samples_split=0.02090131508415152, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.0392085944470695, learning_rate=0.38299441528453515, max_depth=5, max_features=0.5, min_impurity_decrease=0.27511231441853456, min_samples_leaf=0.02135431911374628, min_samples_split=0.013337189210614298, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.0392085944470695, learning_rate=0.38299441528453515, max_depth=5, max_features=0.5, min_impurity_decrease=0.27511231441853456, min_samples_leaf=0.02135431911374628, min_samples_split=0.013337189210614298, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=1.0392085944470695, learning_rate=0.38299441528453515, max_depth=5, max_features=0.5, min_impurity_decrease=0.27511231441853456, min_samples_leaf=0.02135431911374628, min_samples_split=0.013337189210614298, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=1.0392085944470695, learning_rate=0.38299441528453515, max_depth=5, max_features=0.5, min_impurity_decrease=0.27511231441853456, min_samples_leaf=0.02135431911374628, min_samples_split=0.013337189210614298, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END ccp_alpha=1.0392085944470695, learning_rate=0.38299441528453515, max_depth=5, max_features=0.5, min_impurity_decrease=0.27511231441853456, min_samples_leaf=0.02135431911374628, min_samples_split=0.013337189210614298, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END ccp_alpha=0.6445934029966216, learning_rate=0.21694355758731457, max_depth=3, max_features=sqrt, min_impurity_decrease=1.1319423239531072, min_samples_leaf=0.04382252847860599, min_samples_split=0.03218726240801089, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=0.6445934029966216, learning_rate=0.21694355758731457, max_depth=3, max_features=sqrt, min_impurity_decrease=1.1319423239531072, min_samples_leaf=0.04382252847860599, min_samples_split=0.03218726240801089, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.6445934029966216, learning_rate=0.21694355758731457, max_depth=3, max_features=sqrt, min_impurity_decrease=1.1319423239531072, min_samples_leaf=0.04382252847860599, min_samples_split=0.03218726240801089, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.6445934029966216, learning_rate=0.21694355758731457, max_depth=3, max_features=sqrt, min_impurity_decrease=1.1319423239531072, min_samples_leaf=0.04382252847860599, min_samples_split=0.03218726240801089, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.6445934029966216, learning_rate=0.21694355758731457, max_depth=3, max_features=sqrt, min_impurity_decrease=1.1319423239531072, min_samples_leaf=0.04382252847860599, min_samples_split=0.03218726240801089, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.119281621384532, learning_rate=0.5326727905922534, max_depth=3, max_features=sqrt, min_impurity_decrease=0.21563433197022275, min_samples_leaf=0.03163194839742879, min_samples_split=0.04094786588012881, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.119281621384532, learning_rate=0.5326727905922534, max_depth=3, max_features=sqrt, min_impurity_decrease=0.21563433197022275, min_samples_leaf=0.03163194839742879, min_samples_split=0.04094786588012881, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.119281621384532, learning_rate=0.5326727905922534, max_depth=3, max_features=sqrt, min_impurity_decrease=0.21563433197022275, min_samples_leaf=0.03163194839742879, min_samples_split=0.04094786588012881, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.119281621384532, learning_rate=0.5326727905922534, max_depth=3, max_features=sqrt, min_impurity_decrease=0.21563433197022275, min_samples_leaf=0.03163194839742879, min_samples_split=0.04094786588012881, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.119281621384532, learning_rate=0.5326727905922534, max_depth=3, max_features=sqrt, min_impurity_decrease=0.21563433197022275, min_samples_leaf=0.03163194839742879, min_samples_split=0.04094786588012881, n_estimators=100, subsample=1; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=1.374178027844899, learning_rate=0.4511176437366383, max_depth=3, max_features=sqrt, min_impurity_decrease=0.8406441561984266, min_samples_leaf=0.08026305910699383, min_samples_split=0.05386175653186749, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.374178027844899, learning_rate=0.4511176437366383, max_depth=3, max_features=sqrt, min_impurity_decrease=0.8406441561984266, min_samples_leaf=0.08026305910699383, min_samples_split=0.05386175653186749, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.374178027844899, learning_rate=0.4511176437366383, max_depth=3, max_features=sqrt, min_impurity_decrease=0.8406441561984266, min_samples_leaf=0.08026305910699383, min_samples_split=0.05386175653186749, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.374178027844899, learning_rate=0.4511176437366383, max_depth=3, max_features=sqrt, min_impurity_decrease=0.8406441561984266, min_samples_leaf=0.08026305910699383, min_samples_split=0.05386175653186749, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.374178027844899, learning_rate=0.4511176437366383, max_depth=3, max_features=sqrt, min_impurity_decrease=0.8406441561984266, min_samples_leaf=0.08026305910699383, min_samples_split=0.05386175653186749, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.8470009788280914, learning_rate=0.13095376861234573, max_depth=5, max_features=sqrt, min_impurity_decrease=1.940797544900835, min_samples_leaf=0.06991039483608943, min_samples_split=0.08909755799272392, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.8470009788280914, learning_rate=0.13095376861234573, max_depth=5, max_features=sqrt, min_impurity_decrease=1.940797544900835, min_samples_leaf=0.06991039483608943, min_samples_split=0.08909755799272392, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.8470009788280914, learning_rate=0.13095376861234573, max_depth=5, max_features=sqrt, min_impurity_decrease=1.940797544900835, min_samples_leaf=0.06991039483608943, min_samples_split=0.08909755799272392, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.8470009788280914, learning_rate=0.13095376861234573, max_depth=5, max_features=sqrt, min_impurity_decrease=1.940797544900835, min_samples_leaf=0.06991039483608943, min_samples_split=0.08909755799272392, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.8470009788280914, learning_rate=0.13095376861234573, max_depth=5, max_features=sqrt, min_impurity_decrease=1.940797544900835, min_samples_leaf=0.06991039483608943, min_samples_split=0.08909755799272392, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.5071054367898991, learning_rate=0.46276355291055427, max_depth=5, max_features=sqrt, min_impurity_decrease=1.0750236474731132, min_samples_leaf=0.023694300372696753, min_samples_split=0.04364921597693634, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.5071054367898991, learning_rate=0.46276355291055427, max_depth=5, max_features=sqrt, min_impurity_decrease=1.0750236474731132, min_samples_leaf=0.023694300372696753, min_samples_split=0.04364921597693634, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.5071054367898991, learning_rate=0.46276355291055427, max_depth=5, max_features=sqrt, min_impurity_decrease=1.0750236474731132, min_samples_leaf=0.023694300372696753, min_samples_split=0.04364921597693634, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.5071054367898991, learning_rate=0.46276355291055427, max_depth=5, max_features=sqrt, min_impurity_decrease=1.0750236474731132, min_samples_leaf=0.023694300372696753, min_samples_split=0.04364921597693634, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.5071054367898991, learning_rate=0.46276355291055427, max_depth=5, max_features=sqrt, min_impurity_decrease=1.0750236474731132, min_samples_leaf=0.023694300372696753, min_samples_split=0.04364921597693634, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.59604902704385, learning_rate=0.25420458242013766, max_depth=5, max_features=0.5, min_impurity_decrease=0.8792962352907192, min_samples_leaf=0.09133237054420863, min_samples_split=0.06586859031511709, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=1.59604902704385, learning_rate=0.25420458242013766, max_depth=5, max_features=0.5, min_impurity_decrease=0.8792962352907192, min_samples_leaf=0.09133237054420863, min_samples_split=0.06586859031511709, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.59604902704385, learning_rate=0.25420458242013766, max_depth=5, max_features=0.5, min_impurity_decrease=0.8792962352907192, min_samples_leaf=0.09133237054420863, min_samples_split=0.06586859031511709, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.59604902704385, learning_rate=0.25420458242013766, max_depth=5, max_features=0.5, min_impurity_decrease=0.8792962352907192, min_samples_leaf=0.09133237054420863, min_samples_split=0.06586859031511709, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.59604902704385, learning_rate=0.25420458242013766, max_depth=5, max_features=0.5, min_impurity_decrease=0.8792962352907192, min_samples_leaf=0.09133237054420863, min_samples_split=0.06586859031511709, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.3072628962304444, learning_rate=0.2792288916898492, max_depth=2, max_features=0.5, min_impurity_decrease=0.09017462464891501, min_samples_leaf=0.009430966190368963, min_samples_split=0.09216121930580363, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.3072628962304444, learning_rate=0.2792288916898492, max_depth=2, max_features=0.5, min_impurity_decrease=0.09017462464891501, min_samples_leaf=0.009430966190368963, min_samples_split=0.09216121930580363, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.3072628962304444, learning_rate=0.2792288916898492, max_depth=2, max_features=0.5, min_impurity_decrease=0.09017462464891501, min_samples_leaf=0.009430966190368963, min_samples_split=0.09216121930580363, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.3072628962304444, learning_rate=0.2792288916898492, max_depth=2, max_features=0.5, min_impurity_decrease=0.09017462464891501, min_samples_leaf=0.009430966190368963, min_samples_split=0.09216121930580363, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.3072628962304444, learning_rate=0.2792288916898492, max_depth=2, max_features=0.5, min_impurity_decrease=0.09017462464891501, min_samples_leaf=0.009430966190368963, min_samples_split=0.09216121930580363, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.1460890027970252, learning_rate=0.5647086772705293, max_depth=5, max_features=0.5, min_impurity_decrease=1.2446210914786904, min_samples_leaf=0.07549897141156996, min_samples_split=0.01416699089686273, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=0.1460890027970252, learning_rate=0.5647086772705293, max_depth=5, max_features=0.5, min_impurity_decrease=1.2446210914786904, min_samples_leaf=0.07549897141156996, min_samples_split=0.01416699089686273, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.1460890027970252, learning_rate=0.5647086772705293, max_depth=5, max_features=0.5, min_impurity_decrease=1.2446210914786904, min_samples_leaf=0.07549897141156996, min_samples_split=0.01416699089686273, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.1460890027970252, learning_rate=0.5647086772705293, max_depth=5, max_features=0.5, min_impurity_decrease=1.2446210914786904, min_samples_leaf=0.07549897141156996, min_samples_split=0.01416699089686273, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.1460890027970252, learning_rate=0.5647086772705293, max_depth=5, max_features=0.5, min_impurity_decrease=1.2446210914786904, min_samples_leaf=0.07549897141156996, min_samples_split=0.01416699089686273, n_estimators=100, subsample=1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=1.5876443953948995, learning_rate=0.4627015749441883, max_depth=3, max_features=sqrt, min_impurity_decrease=0.9651689863268573, min_samples_leaf=0.04764776103724863, min_samples_split=0.044603283044001046, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.5876443953948995, learning_rate=0.4627015749441883, max_depth=3, max_features=sqrt, min_impurity_decrease=0.9651689863268573, min_samples_leaf=0.04764776103724863, min_samples_split=0.044603283044001046, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=1.5876443953948995, learning_rate=0.4627015749441883, max_depth=3, max_features=sqrt, min_impurity_decrease=0.9651689863268573, min_samples_leaf=0.04764776103724863, min_samples_split=0.044603283044001046, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.5876443953948995, learning_rate=0.4627015749441883, max_depth=3, max_features=sqrt, min_impurity_decrease=0.9651689863268573, min_samples_leaf=0.04764776103724863, min_samples_split=0.044603283044001046, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.5876443953948995, learning_rate=0.4627015749441883, max_depth=3, max_features=sqrt, min_impurity_decrease=0.9651689863268573, min_samples_leaf=0.04764776103724863, min_samples_split=0.044603283044001046, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.632140124814285, learning_rate=0.23717574667684696, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9205926833271365, min_samples_leaf=0.0458118129915735, min_samples_split=0.07578920644633035, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.632140124814285, learning_rate=0.23717574667684696, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9205926833271365, min_samples_leaf=0.0458118129915735, min_samples_split=0.07578920644633035, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.632140124814285, learning_rate=0.23717574667684696, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9205926833271365, min_samples_leaf=0.0458118129915735, min_samples_split=0.07578920644633035, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.632140124814285, learning_rate=0.23717574667684696, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9205926833271365, min_samples_leaf=0.0458118129915735, min_samples_split=0.07578920644633035, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.632140124814285, learning_rate=0.23717574667684696, max_depth=4, max_features=sqrt, min_impurity_decrease=1.9205926833271365, min_samples_leaf=0.0458118129915735, min_samples_split=0.07578920644633035, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.3623172056055484, learning_rate=0.3708889628867331, max_depth=2, max_features=sqrt, min_impurity_decrease=0.506411269651033, min_samples_leaf=0.04438555930724907, min_samples_split=0.05587499066699819, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.3623172056055484, learning_rate=0.3708889628867331, max_depth=2, max_features=sqrt, min_impurity_decrease=0.506411269651033, min_samples_leaf=0.04438555930724907, min_samples_split=0.05587499066699819, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.3623172056055484, learning_rate=0.3708889628867331, max_depth=2, max_features=sqrt, min_impurity_decrease=0.506411269651033, min_samples_leaf=0.04438555930724907, min_samples_split=0.05587499066699819, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.3623172056055484, learning_rate=0.3708889628867331, max_depth=2, max_features=sqrt, min_impurity_decrease=0.506411269651033, min_samples_leaf=0.04438555930724907, min_samples_split=0.05587499066699819, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.3623172056055484, learning_rate=0.3708889628867331, max_depth=2, max_features=sqrt, min_impurity_decrease=0.506411269651033, min_samples_leaf=0.04438555930724907, min_samples_split=0.05587499066699819, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6277287092837398, learning_rate=0.2589141681324494, max_depth=3, max_features=sqrt, min_impurity_decrease=1.7803364965868074, min_samples_leaf=0.08254162078009138, min_samples_split=0.010668708302947217, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6277287092837398, learning_rate=0.2589141681324494, max_depth=3, max_features=sqrt, min_impurity_decrease=1.7803364965868074, min_samples_leaf=0.08254162078009138, min_samples_split=0.010668708302947217, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6277287092837398, learning_rate=0.2589141681324494, max_depth=3, max_features=sqrt, min_impurity_decrease=1.7803364965868074, min_samples_leaf=0.08254162078009138, min_samples_split=0.010668708302947217, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6277287092837398, learning_rate=0.2589141681324494, max_depth=3, max_features=sqrt, min_impurity_decrease=1.7803364965868074, min_samples_leaf=0.08254162078009138, min_samples_split=0.010668708302947217, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6277287092837398, learning_rate=0.2589141681324494, max_depth=3, max_features=sqrt, min_impurity_decrease=1.7803364965868074, min_samples_leaf=0.08254162078009138, min_samples_split=0.010668708302947217, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.31955175113641987, learning_rate=0.42560965431923403, max_depth=3, max_features=0.5, min_impurity_decrease=1.9681673464502163, min_samples_leaf=0.07491590126592107, min_samples_split=0.08023996308544096, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.31955175113641987, learning_rate=0.42560965431923403, max_depth=3, max_features=0.5, min_impurity_decrease=1.9681673464502163, min_samples_leaf=0.07491590126592107, min_samples_split=0.08023996308544096, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.31955175113641987, learning_rate=0.42560965431923403, max_depth=3, max_features=0.5, min_impurity_decrease=1.9681673464502163, min_samples_leaf=0.07491590126592107, min_samples_split=0.08023996308544096, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.31955175113641987, learning_rate=0.42560965431923403, max_depth=3, max_features=0.5, min_impurity_decrease=1.9681673464502163, min_samples_leaf=0.07491590126592107, min_samples_split=0.08023996308544096, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.31955175113641987, learning_rate=0.42560965431923403, max_depth=3, max_features=0.5, min_impurity_decrease=1.9681673464502163, min_samples_leaf=0.07491590126592107, min_samples_split=0.08023996308544096, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.45661976001512405, learning_rate=0.35935672297656895, max_depth=4, max_features=0.5, min_impurity_decrease=0.004370722890335799, min_samples_leaf=0.05132147656659758, min_samples_split=0.0449190168842061, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.45661976001512405, learning_rate=0.35935672297656895, max_depth=4, max_features=0.5, min_impurity_decrease=0.004370722890335799, min_samples_leaf=0.05132147656659758, min_samples_split=0.0449190168842061, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.45661976001512405, learning_rate=0.35935672297656895, max_depth=4, max_features=0.5, min_impurity_decrease=0.004370722890335799, min_samples_leaf=0.05132147656659758, min_samples_split=0.0449190168842061, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.45661976001512405, learning_rate=0.35935672297656895, max_depth=4, max_features=0.5, min_impurity_decrease=0.004370722890335799, min_samples_leaf=0.05132147656659758, min_samples_split=0.0449190168842061, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.45661976001512405, learning_rate=0.35935672297656895, max_depth=4, max_features=0.5, min_impurity_decrease=0.004370722890335799, min_samples_leaf=0.05132147656659758, min_samples_split=0.0449190168842061, n_estimators=100, subsample=1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=0.6987127007850957, learning_rate=0.23684062968947708, max_depth=4, max_features=sqrt, min_impurity_decrease=0.061948919998556784, min_samples_leaf=0.032416908981897474, min_samples_split=0.028659274764898823, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.6987127007850957, learning_rate=0.23684062968947708, max_depth=4, max_features=sqrt, min_impurity_decrease=0.061948919998556784, min_samples_leaf=0.032416908981897474, min_samples_split=0.028659274764898823, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.6987127007850957, learning_rate=0.23684062968947708, max_depth=4, max_features=sqrt, min_impurity_decrease=0.061948919998556784, min_samples_leaf=0.032416908981897474, min_samples_split=0.028659274764898823, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.6987127007850957, learning_rate=0.23684062968947708, max_depth=4, max_features=sqrt, min_impurity_decrease=0.061948919998556784, min_samples_leaf=0.032416908981897474, min_samples_split=0.028659274764898823, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.6987127007850957, learning_rate=0.23684062968947708, max_depth=4, max_features=sqrt, min_impurity_decrease=0.061948919998556784, min_samples_leaf=0.032416908981897474, min_samples_split=0.028659274764898823, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.9142721572783563, learning_rate=0.10826653303285008, max_depth=4, max_features=sqrt, min_impurity_decrease=0.6498715919579643, min_samples_leaf=0.06964633960269621, min_samples_split=0.06927497624448758, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.9142721572783563, learning_rate=0.10826653303285008, max_depth=4, max_features=sqrt, min_impurity_decrease=0.6498715919579643, min_samples_leaf=0.06964633960269621, min_samples_split=0.06927497624448758, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.9142721572783563, learning_rate=0.10826653303285008, max_depth=4, max_features=sqrt, min_impurity_decrease=0.6498715919579643, min_samples_leaf=0.06964633960269621, min_samples_split=0.06927497624448758, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.9142721572783563, learning_rate=0.10826653303285008, max_depth=4, max_features=sqrt, min_impurity_decrease=0.6498715919579643, min_samples_leaf=0.06964633960269621, min_samples_split=0.06927497624448758, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.9142721572783563, learning_rate=0.10826653303285008, max_depth=4, max_features=sqrt, min_impurity_decrease=0.6498715919579643, min_samples_leaf=0.06964633960269621, min_samples_split=0.06927497624448758, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.3652921385067651, learning_rate=0.5460652290100285, max_depth=4, max_features=sqrt, min_impurity_decrease=0.16361505074546678, min_samples_leaf=0.011688922055159479, min_samples_split=0.003686896722387101, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.3652921385067651, learning_rate=0.5460652290100285, max_depth=4, max_features=sqrt, min_impurity_decrease=0.16361505074546678, min_samples_leaf=0.011688922055159479, min_samples_split=0.003686896722387101, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.3652921385067651, learning_rate=0.5460652290100285, max_depth=4, max_features=sqrt, min_impurity_decrease=0.16361505074546678, min_samples_leaf=0.011688922055159479, min_samples_split=0.003686896722387101, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.3652921385067651, learning_rate=0.5460652290100285, max_depth=4, max_features=sqrt, min_impurity_decrease=0.16361505074546678, min_samples_leaf=0.011688922055159479, min_samples_split=0.003686896722387101, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.3652921385067651, learning_rate=0.5460652290100285, max_depth=4, max_features=sqrt, min_impurity_decrease=0.16361505074546678, min_samples_leaf=0.011688922055159479, min_samples_split=0.003686896722387101, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=1.8475804122903623, learning_rate=0.5909503962066437, max_depth=5, max_features=sqrt, min_impurity_decrease=0.12695201457035976, min_samples_leaf=0.012785646320834832, min_samples_split=0.08798888749341004, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.8475804122903623, learning_rate=0.5909503962066437, max_depth=5, max_features=sqrt, min_impurity_decrease=0.12695201457035976, min_samples_leaf=0.012785646320834832, min_samples_split=0.08798888749341004, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.8475804122903623, learning_rate=0.5909503962066437, max_depth=5, max_features=sqrt, min_impurity_decrease=0.12695201457035976, min_samples_leaf=0.012785646320834832, min_samples_split=0.08798888749341004, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.8475804122903623, learning_rate=0.5909503962066437, max_depth=5, max_features=sqrt, min_impurity_decrease=0.12695201457035976, min_samples_leaf=0.012785646320834832, min_samples_split=0.08798888749341004, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.8475804122903623, learning_rate=0.5909503962066437, max_depth=5, max_features=sqrt, min_impurity_decrease=0.12695201457035976, min_samples_leaf=0.012785646320834832, min_samples_split=0.08798888749341004, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.908096269679227, learning_rate=0.19974553109657242, max_depth=4, max_features=sqrt, min_impurity_decrease=1.552858811061811, min_samples_leaf=0.046454819403139974, min_samples_split=0.004036681781485052, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.908096269679227, learning_rate=0.19974553109657242, max_depth=4, max_features=sqrt, min_impurity_decrease=1.552858811061811, min_samples_leaf=0.046454819403139974, min_samples_split=0.004036681781485052, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.908096269679227, learning_rate=0.19974553109657242, max_depth=4, max_features=sqrt, min_impurity_decrease=1.552858811061811, min_samples_leaf=0.046454819403139974, min_samples_split=0.004036681781485052, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.908096269679227, learning_rate=0.19974553109657242, max_depth=4, max_features=sqrt, min_impurity_decrease=1.552858811061811, min_samples_leaf=0.046454819403139974, min_samples_split=0.004036681781485052, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.908096269679227, learning_rate=0.19974553109657242, max_depth=4, max_features=sqrt, min_impurity_decrease=1.552858811061811, min_samples_leaf=0.046454819403139974, min_samples_split=0.004036681781485052, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7478023193925505, learning_rate=0.5334592237443786, max_depth=2, max_features=sqrt, min_impurity_decrease=0.2250222394309176, min_samples_leaf=0.07801340008451672, min_samples_split=0.013504882557468557, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7478023193925505, learning_rate=0.5334592237443786, max_depth=2, max_features=sqrt, min_impurity_decrease=0.2250222394309176, min_samples_leaf=0.07801340008451672, min_samples_split=0.013504882557468557, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7478023193925505, learning_rate=0.5334592237443786, max_depth=2, max_features=sqrt, min_impurity_decrease=0.2250222394309176, min_samples_leaf=0.07801340008451672, min_samples_split=0.013504882557468557, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7478023193925505, learning_rate=0.5334592237443786, max_depth=2, max_features=sqrt, min_impurity_decrease=0.2250222394309176, min_samples_leaf=0.07801340008451672, min_samples_split=0.013504882557468557, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.7478023193925505, learning_rate=0.5334592237443786, max_depth=2, max_features=sqrt, min_impurity_decrease=0.2250222394309176, min_samples_leaf=0.07801340008451672, min_samples_split=0.013504882557468557, n_estimators=100, subsample=1; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=0.2571169442187491, learning_rate=0.22025158745576287, max_depth=4, max_features=0.5, min_impurity_decrease=0.6664729501296369, min_samples_leaf=0.07921640161408444, min_samples_split=0.024434692768040125, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2571169442187491, learning_rate=0.22025158745576287, max_depth=4, max_features=0.5, min_impurity_decrease=0.6664729501296369, min_samples_leaf=0.07921640161408444, min_samples_split=0.024434692768040125, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2571169442187491, learning_rate=0.22025158745576287, max_depth=4, max_features=0.5, min_impurity_decrease=0.6664729501296369, min_samples_leaf=0.07921640161408444, min_samples_split=0.024434692768040125, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2571169442187491, learning_rate=0.22025158745576287, max_depth=4, max_features=0.5, min_impurity_decrease=0.6664729501296369, min_samples_leaf=0.07921640161408444, min_samples_split=0.024434692768040125, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2571169442187491, learning_rate=0.22025158745576287, max_depth=4, max_features=0.5, min_impurity_decrease=0.6664729501296369, min_samples_leaf=0.07921640161408444, min_samples_split=0.024434692768040125, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.21076972067916433, learning_rate=0.15854036073568686, max_depth=5, max_features=0.5, min_impurity_decrease=0.4678806567564473, min_samples_leaf=0.0828130226292829, min_samples_split=0.06107876481070476, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=0.21076972067916433, learning_rate=0.15854036073568686, max_depth=5, max_features=0.5, min_impurity_decrease=0.4678806567564473, min_samples_leaf=0.0828130226292829, min_samples_split=0.06107876481070476, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.21076972067916433, learning_rate=0.15854036073568686, max_depth=5, max_features=0.5, min_impurity_decrease=0.4678806567564473, min_samples_leaf=0.0828130226292829, min_samples_split=0.06107876481070476, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=0.21076972067916433, learning_rate=0.15854036073568686, max_depth=5, max_features=0.5, min_impurity_decrease=0.4678806567564473, min_samples_leaf=0.0828130226292829, min_samples_split=0.06107876481070476, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.21076972067916433, learning_rate=0.15854036073568686, max_depth=5, max_features=0.5, min_impurity_decrease=0.4678806567564473, min_samples_leaf=0.0828130226292829, min_samples_split=0.06107876481070476, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.5799813889543464, learning_rate=0.5987192444329898, max_depth=4, max_features=sqrt, min_impurity_decrease=1.7894453888400779, min_samples_leaf=0.028824616441233488, min_samples_split=0.03134449222287613, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.5799813889543464, learning_rate=0.5987192444329898, max_depth=4, max_features=sqrt, min_impurity_decrease=1.7894453888400779, min_samples_leaf=0.028824616441233488, min_samples_split=0.03134449222287613, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.5799813889543464, learning_rate=0.5987192444329898, max_depth=4, max_features=sqrt, min_impurity_decrease=1.7894453888400779, min_samples_leaf=0.028824616441233488, min_samples_split=0.03134449222287613, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.5799813889543464, learning_rate=0.5987192444329898, max_depth=4, max_features=sqrt, min_impurity_decrease=1.7894453888400779, min_samples_leaf=0.028824616441233488, min_samples_split=0.03134449222287613, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.5799813889543464, learning_rate=0.5987192444329898, max_depth=4, max_features=sqrt, min_impurity_decrease=1.7894453888400779, min_samples_leaf=0.028824616441233488, min_samples_split=0.03134449222287613, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.9611229145576374, learning_rate=0.1445684344746199, max_depth=5, max_features=0.5, min_impurity_decrease=1.920008971765601, min_samples_leaf=0.03408171453147475, min_samples_split=0.09155355036842815, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.9611229145576374, learning_rate=0.1445684344746199, max_depth=5, max_features=0.5, min_impurity_decrease=1.920008971765601, min_samples_leaf=0.03408171453147475, min_samples_split=0.09155355036842815, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.9611229145576374, learning_rate=0.1445684344746199, max_depth=5, max_features=0.5, min_impurity_decrease=1.920008971765601, min_samples_leaf=0.03408171453147475, min_samples_split=0.09155355036842815, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.9611229145576374, learning_rate=0.1445684344746199, max_depth=5, max_features=0.5, min_impurity_decrease=1.920008971765601, min_samples_leaf=0.03408171453147475, min_samples_split=0.09155355036842815, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.9611229145576374, learning_rate=0.1445684344746199, max_depth=5, max_features=0.5, min_impurity_decrease=1.920008971765601, min_samples_leaf=0.03408171453147475, min_samples_split=0.09155355036842815, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.7972771950049211, learning_rate=0.5996837286226603, max_depth=4, max_features=sqrt, min_impurity_decrease=1.190217970376899, min_samples_leaf=0.07859269917162875, min_samples_split=0.07257362500832891, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.7972771950049211, learning_rate=0.5996837286226603, max_depth=4, max_features=sqrt, min_impurity_decrease=1.190217970376899, min_samples_leaf=0.07859269917162875, min_samples_split=0.07257362500832891, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.7972771950049211, learning_rate=0.5996837286226603, max_depth=4, max_features=sqrt, min_impurity_decrease=1.190217970376899, min_samples_leaf=0.07859269917162875, min_samples_split=0.07257362500832891, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.7972771950049211, learning_rate=0.5996837286226603, max_depth=4, max_features=sqrt, min_impurity_decrease=1.190217970376899, min_samples_leaf=0.07859269917162875, min_samples_split=0.07257362500832891, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.7972771950049211, learning_rate=0.5996837286226603, max_depth=4, max_features=sqrt, min_impurity_decrease=1.190217970376899, min_samples_leaf=0.07859269917162875, min_samples_split=0.07257362500832891, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6591588656495868, learning_rate=0.10972426945585764, max_depth=5, max_features=sqrt, min_impurity_decrease=0.32674640567011104, min_samples_leaf=0.002743245814889095, min_samples_split=0.09790234757273901, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.6591588656495868, learning_rate=0.10972426945585764, max_depth=5, max_features=sqrt, min_impurity_decrease=0.32674640567011104, min_samples_leaf=0.002743245814889095, min_samples_split=0.09790234757273901, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.6591588656495868, learning_rate=0.10972426945585764, max_depth=5, max_features=sqrt, min_impurity_decrease=0.32674640567011104, min_samples_leaf=0.002743245814889095, min_samples_split=0.09790234757273901, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.6591588656495868, learning_rate=0.10972426945585764, max_depth=5, max_features=sqrt, min_impurity_decrease=0.32674640567011104, min_samples_leaf=0.002743245814889095, min_samples_split=0.09790234757273901, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=1.6591588656495868, learning_rate=0.10972426945585764, max_depth=5, max_features=sqrt, min_impurity_decrease=0.32674640567011104, min_samples_leaf=0.002743245814889095, min_samples_split=0.09790234757273901, n_estimators=100, subsample=1; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=0.36973301533657277, learning_rate=0.5172281166492838, max_depth=3, max_features=0.5, min_impurity_decrease=0.0673322656684896, min_samples_leaf=0.007204403481688349, min_samples_split=0.06369458017871925, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.36973301533657277, learning_rate=0.5172281166492838, max_depth=3, max_features=0.5, min_impurity_decrease=0.0673322656684896, min_samples_leaf=0.007204403481688349, min_samples_split=0.06369458017871925, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=0.36973301533657277, learning_rate=0.5172281166492838, max_depth=3, max_features=0.5, min_impurity_decrease=0.0673322656684896, min_samples_leaf=0.007204403481688349, min_samples_split=0.06369458017871925, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.36973301533657277, learning_rate=0.5172281166492838, max_depth=3, max_features=0.5, min_impurity_decrease=0.0673322656684896, min_samples_leaf=0.007204403481688349, min_samples_split=0.06369458017871925, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.36973301533657277, learning_rate=0.5172281166492838, max_depth=3, max_features=0.5, min_impurity_decrease=0.0673322656684896, min_samples_leaf=0.007204403481688349, min_samples_split=0.06369458017871925, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.4915267254622766, learning_rate=0.3130565953074068, max_depth=2, max_features=sqrt, min_impurity_decrease=0.4103854933250428, min_samples_leaf=0.02354460411608448, min_samples_split=0.048674944292784905, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.4915267254622766, learning_rate=0.3130565953074068, max_depth=2, max_features=sqrt, min_impurity_decrease=0.4103854933250428, min_samples_leaf=0.02354460411608448, min_samples_split=0.048674944292784905, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.4915267254622766, learning_rate=0.3130565953074068, max_depth=2, max_features=sqrt, min_impurity_decrease=0.4103854933250428, min_samples_leaf=0.02354460411608448, min_samples_split=0.048674944292784905, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.4915267254622766, learning_rate=0.3130565953074068, max_depth=2, max_features=sqrt, min_impurity_decrease=0.4103854933250428, min_samples_leaf=0.02354460411608448, min_samples_split=0.048674944292784905, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.4915267254622766, learning_rate=0.3130565953074068, max_depth=2, max_features=sqrt, min_impurity_decrease=0.4103854933250428, min_samples_leaf=0.02354460411608448, min_samples_split=0.048674944292784905, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.5575033575379846, learning_rate=0.36081195050390613, max_depth=3, max_features=0.5, min_impurity_decrease=0.671280350665985, min_samples_leaf=0.001188882259431412, min_samples_split=0.07580211302220319, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.5575033575379846, learning_rate=0.36081195050390613, max_depth=3, max_features=0.5, min_impurity_decrease=0.671280350665985, min_samples_leaf=0.001188882259431412, min_samples_split=0.07580211302220319, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.5575033575379846, learning_rate=0.36081195050390613, max_depth=3, max_features=0.5, min_impurity_decrease=0.671280350665985, min_samples_leaf=0.001188882259431412, min_samples_split=0.07580211302220319, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.5575033575379846, learning_rate=0.36081195050390613, max_depth=3, max_features=0.5, min_impurity_decrease=0.671280350665985, min_samples_leaf=0.001188882259431412, min_samples_split=0.07580211302220319, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.5575033575379846, learning_rate=0.36081195050390613, max_depth=3, max_features=0.5, min_impurity_decrease=0.671280350665985, min_samples_leaf=0.001188882259431412, min_samples_split=0.07580211302220319, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.7798899096228478, learning_rate=0.2810086316259477, max_depth=2, max_features=sqrt, min_impurity_decrease=0.12131523457531501, min_samples_leaf=0.07388261957855007, min_samples_split=0.023401537039531406, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.7798899096228478, learning_rate=0.2810086316259477, max_depth=2, max_features=sqrt, min_impurity_decrease=0.12131523457531501, min_samples_leaf=0.07388261957855007, min_samples_split=0.023401537039531406, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.7798899096228478, learning_rate=0.2810086316259477, max_depth=2, max_features=sqrt, min_impurity_decrease=0.12131523457531501, min_samples_leaf=0.07388261957855007, min_samples_split=0.023401537039531406, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=1.7798899096228478, learning_rate=0.2810086316259477, max_depth=2, max_features=sqrt, min_impurity_decrease=0.12131523457531501, min_samples_leaf=0.07388261957855007, min_samples_split=0.023401537039531406, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.7798899096228478, learning_rate=0.2810086316259477, max_depth=2, max_features=sqrt, min_impurity_decrease=0.12131523457531501, min_samples_leaf=0.07388261957855007, min_samples_split=0.023401537039531406, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.261842190364618, learning_rate=0.17005799353706538, max_depth=5, max_features=sqrt, min_impurity_decrease=1.4596570936095852, min_samples_leaf=0.04319589503012186, min_samples_split=0.0698533277758479, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.261842190364618, learning_rate=0.17005799353706538, max_depth=5, max_features=sqrt, min_impurity_decrease=1.4596570936095852, min_samples_leaf=0.04319589503012186, min_samples_split=0.0698533277758479, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.261842190364618, learning_rate=0.17005799353706538, max_depth=5, max_features=sqrt, min_impurity_decrease=1.4596570936095852, min_samples_leaf=0.04319589503012186, min_samples_split=0.0698533277758479, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.261842190364618, learning_rate=0.17005799353706538, max_depth=5, max_features=sqrt, min_impurity_decrease=1.4596570936095852, min_samples_leaf=0.04319589503012186, min_samples_split=0.0698533277758479, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.261842190364618, learning_rate=0.17005799353706538, max_depth=5, max_features=sqrt, min_impurity_decrease=1.4596570936095852, min_samples_leaf=0.04319589503012186, min_samples_split=0.0698533277758479, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.2831091196660174, learning_rate=0.21196872806489972, max_depth=3, max_features=0.5, min_impurity_decrease=0.0076241774603840184, min_samples_leaf=0.022642668003059443, min_samples_split=0.08375605755782098, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2831091196660174, learning_rate=0.21196872806489972, max_depth=3, max_features=0.5, min_impurity_decrease=0.0076241774603840184, min_samples_leaf=0.022642668003059443, min_samples_split=0.08375605755782098, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.2831091196660174, learning_rate=0.21196872806489972, max_depth=3, max_features=0.5, min_impurity_decrease=0.0076241774603840184, min_samples_leaf=0.022642668003059443, min_samples_split=0.08375605755782098, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2831091196660174, learning_rate=0.21196872806489972, max_depth=3, max_features=0.5, min_impurity_decrease=0.0076241774603840184, min_samples_leaf=0.022642668003059443, min_samples_split=0.08375605755782098, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END ccp_alpha=0.2831091196660174, learning_rate=0.21196872806489972, max_depth=3, max_features=0.5, min_impurity_decrease=0.0076241774603840184, min_samples_leaf=0.022642668003059443, min_samples_split=0.08375605755782098, n_estimators=100, subsample=1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=1.3594232095065586, learning_rate=0.2369714737981655, max_depth=5, max_features=0.5, min_impurity_decrease=0.3410703859888735, min_samples_leaf=0.054227727004286144, min_samples_split=0.05991117465798246, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END ccp_alpha=1.3594232095065586, learning_rate=0.2369714737981655, max_depth=5, max_features=0.5, min_impurity_decrease=0.3410703859888735, min_samples_leaf=0.054227727004286144, min_samples_split=0.05991117465798246, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.3594232095065586, learning_rate=0.2369714737981655, max_depth=5, max_features=0.5, min_impurity_decrease=0.3410703859888735, min_samples_leaf=0.054227727004286144, min_samples_split=0.05991117465798246, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.3594232095065586, learning_rate=0.2369714737981655, max_depth=5, max_features=0.5, min_impurity_decrease=0.3410703859888735, min_samples_leaf=0.054227727004286144, min_samples_split=0.05991117465798246, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.3594232095065586, learning_rate=0.2369714737981655, max_depth=5, max_features=0.5, min_impurity_decrease=0.3410703859888735, min_samples_leaf=0.054227727004286144, min_samples_split=0.05991117465798246, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.9475120175419247, learning_rate=0.4368979642943279, max_depth=5, max_features=0.5, min_impurity_decrease=1.0171565830740847, min_samples_leaf=0.024750604610235594, min_samples_split=0.09875922562387651, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.9475120175419247, learning_rate=0.4368979642943279, max_depth=5, max_features=0.5, min_impurity_decrease=1.0171565830740847, min_samples_leaf=0.024750604610235594, min_samples_split=0.09875922562387651, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1.9475120175419247, learning_rate=0.4368979642943279, max_depth=5, max_features=0.5, min_impurity_decrease=1.0171565830740847, min_samples_leaf=0.024750604610235594, min_samples_split=0.09875922562387651, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.9475120175419247, learning_rate=0.4368979642943279, max_depth=5, max_features=0.5, min_impurity_decrease=1.0171565830740847, min_samples_leaf=0.024750604610235594, min_samples_split=0.09875922562387651, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1.9475120175419247, learning_rate=0.4368979642943279, max_depth=5, max_features=0.5, min_impurity_decrease=1.0171565830740847, min_samples_leaf=0.024750604610235594, min_samples_split=0.09875922562387651, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.8178698889291274, learning_rate=0.1430582995593044, max_depth=2, max_features=sqrt, min_impurity_decrease=1.793244665431124, min_samples_leaf=0.05331958233810247, min_samples_split=0.0035142390589952724, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.8178698889291274, learning_rate=0.1430582995593044, max_depth=2, max_features=sqrt, min_impurity_decrease=1.793244665431124, min_samples_leaf=0.05331958233810247, min_samples_split=0.0035142390589952724, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.8178698889291274, learning_rate=0.1430582995593044, max_depth=2, max_features=sqrt, min_impurity_decrease=1.793244665431124, min_samples_leaf=0.05331958233810247, min_samples_split=0.0035142390589952724, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.8178698889291274, learning_rate=0.1430582995593044, max_depth=2, max_features=sqrt, min_impurity_decrease=1.793244665431124, min_samples_leaf=0.05331958233810247, min_samples_split=0.0035142390589952724, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=0.8178698889291274, learning_rate=0.1430582995593044, max_depth=2, max_features=sqrt, min_impurity_decrease=1.793244665431124, min_samples_leaf=0.05331958233810247, min_samples_split=0.0035142390589952724, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.6754375655522147, learning_rate=0.5519539552853726, max_depth=4, max_features=sqrt, min_impurity_decrease=0.5620015747952125, min_samples_leaf=0.09327037834036017, min_samples_split=0.00179140491626002, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.6754375655522147, learning_rate=0.5519539552853726, max_depth=4, max_features=sqrt, min_impurity_decrease=0.5620015747952125, min_samples_leaf=0.09327037834036017, min_samples_split=0.00179140491626002, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.6754375655522147, learning_rate=0.5519539552853726, max_depth=4, max_features=sqrt, min_impurity_decrease=0.5620015747952125, min_samples_leaf=0.09327037834036017, min_samples_split=0.00179140491626002, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1.6754375655522147, learning_rate=0.5519539552853726, max_depth=4, max_features=sqrt, min_impurity_decrease=0.5620015747952125, min_samples_leaf=0.09327037834036017, min_samples_split=0.00179140491626002, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=1.6754375655522147, learning_rate=0.5519539552853726, max_depth=4, max_features=sqrt, min_impurity_decrease=0.5620015747952125, min_samples_leaf=0.09327037834036017, min_samples_split=0.00179140491626002, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END ccp_alpha=0.641275384070022, learning_rate=0.27559311064478065, max_depth=5, max_features=0.5, min_impurity_decrease=0.00867339239752396, min_samples_leaf=0.06480674709459937, min_samples_split=0.0555515525985642, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END ccp_alpha=0.641275384070022, learning_rate=0.27559311064478065, max_depth=5, max_features=0.5, min_impurity_decrease=0.00867339239752396, min_samples_leaf=0.06480674709459937, min_samples_split=0.0555515525985642, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.641275384070022, learning_rate=0.27559311064478065, max_depth=5, max_features=0.5, min_impurity_decrease=0.00867339239752396, min_samples_leaf=0.06480674709459937, min_samples_split=0.0555515525985642, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.641275384070022, learning_rate=0.27559311064478065, max_depth=5, max_features=0.5, min_impurity_decrease=0.00867339239752396, min_samples_leaf=0.06480674709459937, min_samples_split=0.0555515525985642, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END ccp_alpha=0.641275384070022, learning_rate=0.27559311064478065, max_depth=5, max_features=0.5, min_impurity_decrease=0.00867339239752396, min_samples_leaf=0.06480674709459937, min_samples_split=0.0555515525985642, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0.674801492518817, learning_rate=0.14261621711856629, max_depth=2, max_features=0.5, min_impurity_decrease=1.315692297548413, min_samples_leaf=0.004582827529542544, min_samples_split=0.00619115910285365, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.674801492518817, learning_rate=0.14261621711856629, max_depth=2, max_features=0.5, min_impurity_decrease=1.315692297548413, min_samples_leaf=0.004582827529542544, min_samples_split=0.00619115910285365, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.674801492518817, learning_rate=0.14261621711856629, max_depth=2, max_features=0.5, min_impurity_decrease=1.315692297548413, min_samples_leaf=0.004582827529542544, min_samples_split=0.00619115910285365, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.674801492518817, learning_rate=0.14261621711856629, max_depth=2, max_features=0.5, min_impurity_decrease=1.315692297548413, min_samples_leaf=0.004582827529542544, min_samples_split=0.00619115910285365, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.674801492518817, learning_rate=0.14261621711856629, max_depth=2, max_features=0.5, min_impurity_decrease=1.315692297548413, min_samples_leaf=0.004582827529542544, min_samples_split=0.00619115910285365, n_estimators=100, subsample=1; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ccp_alpha=0.9156790126537371, learning_rate=0.360529306724123, max_depth=3, max_features=sqrt, min_impurity_decrease=1.0655868988192319, min_samples_leaf=0.011922738802284272, min_samples_split=0.011432095765878947, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.9156790126537371, learning_rate=0.360529306724123, max_depth=3, max_features=sqrt, min_impurity_decrease=1.0655868988192319, min_samples_leaf=0.011922738802284272, min_samples_split=0.011432095765878947, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END ccp_alpha=0.9156790126537371, learning_rate=0.360529306724123, max_depth=3, max_features=sqrt, min_impurity_decrease=1.0655868988192319, min_samples_leaf=0.011922738802284272, min_samples_split=0.011432095765878947, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.9156790126537371, learning_rate=0.360529306724123, max_depth=3, max_features=sqrt, min_impurity_decrease=1.0655868988192319, min_samples_leaf=0.011922738802284272, min_samples_split=0.011432095765878947, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0.9156790126537371, learning_rate=0.360529306724123, max_depth=3, max_features=sqrt, min_impurity_decrease=1.0655868988192319, min_samples_leaf=0.011922738802284272, min_samples_split=0.011432095765878947, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.3705071741152077, learning_rate=0.25713816685786084, max_depth=3, max_features=sqrt, min_impurity_decrease=1.9068269351175544, min_samples_leaf=0.06531740944500637, min_samples_split=0.09957536943484001, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.3705071741152077, learning_rate=0.25713816685786084, max_depth=3, max_features=sqrt, min_impurity_decrease=1.9068269351175544, min_samples_leaf=0.06531740944500637, min_samples_split=0.09957536943484001, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.3705071741152077, learning_rate=0.25713816685786084, max_depth=3, max_features=sqrt, min_impurity_decrease=1.9068269351175544, min_samples_leaf=0.06531740944500637, min_samples_split=0.09957536943484001, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=1.3705071741152077, learning_rate=0.25713816685786084, max_depth=3, max_features=sqrt, min_impurity_decrease=1.9068269351175544, min_samples_leaf=0.06531740944500637, min_samples_split=0.09957536943484001, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END ccp_alpha=1.3705071741152077, learning_rate=0.25713816685786084, max_depth=3, max_features=sqrt, min_impurity_decrease=1.9068269351175544, min_samples_leaf=0.06531740944500637, min_samples_split=0.09957536943484001, n_estimators=100, subsample=1; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [100],\n",
    "    \"subsample\": [1],\n",
    "    \"learning_rate\": uniform(loc=0.1,scale=0.5),\n",
    "    \"max_depth\": [2,3,4,5],\n",
    "    \"min_samples_split\":uniform(loc=0,scale=0.1),\n",
    "    \"min_samples_leaf\":uniform(loc=0,scale=0.1),\n",
    "    \"min_impurity_decrease\": uniform(loc=0,scale=2),\n",
    "    \"ccp_alpha\": uniform(loc=0,scale=2),\n",
    "    \"max_features\": ['sqrt', 0.5],\n",
    "}\n",
    "\n",
    "# Fixed parameters can also be passed directly in the model instantiation\n",
    "gradient_boosting_model = ensemble.GradientBoostingRegressor(criterion='squared_error', validation_fraction=0.1, n_iter_no_change=10)\n",
    "\n",
    "gradient_boosting_tuning = RandomizedSearchCV(gradient_boosting_model, param_distributions, \n",
    "                                              n_iter = 50, cv = 5, random_state=1000, verbose=2)\n",
    "gradient_boosting_tuning = gradient_boosting_tuning.fit(X_train_num[x_variables], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfac8e",
   "metadata": {},
   "source": [
    "**We can view the full results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ea15ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ccp_alpha</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2751</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.3653</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.5959</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>0.5744</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1.7702</td>\n",
       "      <td>0.5521</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.5748</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>1.8476</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.5831</td>\n",
       "      <td>0.5807</td>\n",
       "      <td>0.5582</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.5767</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.5633</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9          0.9521        0.1605           0.0114          0.0016   \n",
       "26         0.4876        0.1483           0.0106          0.0024   \n",
       "5          0.6842        0.2668           0.0146          0.0044   \n",
       "27         0.4916        0.0705           0.0088          0.0007   \n",
       "14         0.6309        0.1070           0.0130          0.0030   \n",
       "\n",
       "   param_ccp_alpha param_learning_rate param_max_depth param_max_features  \\\n",
       "9           1.0392              0.3830               5             0.5000   \n",
       "26          1.3653              0.5461               4               sqrt   \n",
       "5           1.7702              0.5521               5               sqrt   \n",
       "27          1.8476              0.5910               5               sqrt   \n",
       "14          0.5071              0.4628               5               sqrt   \n",
       "\n",
       "   param_min_impurity_decrease param_min_samples_leaf  ... param_n_estimators  \\\n",
       "9                       0.2751                 0.0214  ...                100   \n",
       "26                      0.1636                 0.0117  ...                100   \n",
       "5                       0.1491                 0.0245  ...                100   \n",
       "27                      0.1270                 0.0128  ...                100   \n",
       "14                      1.0750                 0.0237  ...                100   \n",
       "\n",
       "   param_subsample split0_test_score  split1_test_score  split2_test_score  \\\n",
       "9                1            0.5687             0.6014             0.5948   \n",
       "26               1            0.5719             0.5983             0.5959   \n",
       "5                1            0.5716             0.5748             0.5714   \n",
       "27               1            0.5415             0.5905             0.5831   \n",
       "14               1            0.5776             0.5767             0.5761   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "9              0.5776             0.5690           0.5823          0.0135   \n",
       "26             0.5772             0.5288           0.5744          0.0250   \n",
       "5              0.5695             0.5692           0.5713          0.0020   \n",
       "27             0.5807             0.5582           0.5708          0.0182   \n",
       "14             0.5633             0.5513           0.5690          0.0103   \n",
       "\n",
       "    rank_test_score  \n",
       "9                 1  \n",
       "26                2  \n",
       "5                 3  \n",
       "27                4  \n",
       "14                5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.DataFrame(gradient_boosting_tuning.cv_results_).drop(columns=['params']).sort_values(by=['mean_test_score'], ascending=False)\n",
    "full_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3383d4",
   "metadata": {},
   "source": [
    "**And we can get the best results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bfe6fec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5823227389122438\n",
      "Best index: 9\n",
      "Best parameters: {'ccp_alpha': 1.0392085944470695, 'learning_rate': 0.38299441528453515, 'max_depth': 5, 'max_features': 0.5, 'min_impurity_decrease': 0.27511231441853456, 'min_samples_leaf': 0.02135431911374628, 'min_samples_split': 0.013337189210614298, 'n_estimators': 100, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "# Best results\n",
    "print(\"Best score: {}\".format(gradient_boosting_tuning.best_score_))\n",
    "print(\"Best index: {}\".format(gradient_boosting_tuning.best_index_))\n",
    "print(\"Best parameters: {}\".format(gradient_boosting_tuning.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04d3f4",
   "metadata": {},
   "source": [
    "### Fit a single gradient boosting model\n",
    "\n",
    "We can choose to fit a single gradient boosting model, which still requires appropriate selection of the number of trees through the use of early stopping.\n",
    "\n",
    "Here, we use the best parameters from the hyperparameter tuning above, rounding a bit to more convenient values. Instead of typing out each argument, we can use a dictionary to pass the parameters to the function, with help of the ** symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0bc41a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1   186050041.7223            4.49s\n",
      "         2   167159388.2284            4.73s\n",
      "         3   144608692.5604            4.31s\n",
      "         4   136089184.7558            3.84s\n",
      "         5   129016446.1491            3.76s\n",
      "         6   125527588.7903            3.54s\n",
      "         7   123055665.0123            3.66s\n",
      "         8   120502338.3409            3.63s\n",
      "         9   119132117.0215            3.55s\n",
      "        10   117857247.8823            3.63s\n",
      "        20   104562446.7765            3.58s\n",
      "        30    99123955.2949            3.46s\n",
      "        40    95836390.1285            3.35s\n",
      "        50    92707524.4207            3.28s\n",
      "        60    90904769.4747            3.26s\n",
      "        70    89594283.3494            3.18s\n",
      "        80    88004681.5472            3.08s\n",
      "        90    86462339.8627            2.99s\n",
      "       100    85558114.3577            2.88s\n"
     ]
    }
   ],
   "source": [
    "gbm_parameters = {'ccp_alpha': 1.4, 'learning_rate': 0.55, 'max_depth': 4, \n",
    "                  'max_features': 'sqrt', 'min_impurity_decrease': 0.16, \n",
    "                  'min_samples_leaf': 0.02, \n",
    "                  'min_samples_split': 0.004, 'n_estimators': 500, 'subsample': 1}\n",
    "\n",
    "gradient_boosting_model = ensemble.GradientBoostingRegressor(criterion='squared_error', \n",
    "                                                             **gbm_parameters, \n",
    "                                                             validation_fraction=0.1, n_iter_no_change=10, tol=0.01, \n",
    "                                                             verbose=1, random_state=10000)\n",
    "\n",
    "# Fit the model\n",
    "gradient_boosting_model_fitted = gradient_boosting_model.fit(X_train_num[x_variables], y_train)\n",
    "\n",
    "# Note that the 'Train Loss' are not indicative of expected model performance since Gradient Boosted models can easily overfit. See further below for analysis of model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b51da",
   "metadata": {},
   "source": [
    "**Variable importance**\n",
    "\n",
    "We can't easily visualize a gradient boosting model with hundreds of trees like we could for a single decision tree, and we don't have variable coefficients like a linear model. Therefore, we need other techniques to understand the importance of each variable in the model.\n",
    "\n",
    "Variable importance (a.k.a. feature importance) is therefore often calculated, and measure the impact of a variable on the model fit. The GradientBoostingRegressor provides a simple estimate of feature importance, based on the (normalized) total reduction of the error term brought by that feature. \n",
    "\n",
    "This estimate doesn't work well for features with very many unique values (e.g. continuous variables). Sklearn provides a model-agnostic feature importance metric, based on the impact of a variable on model fit if that variable is permutated (shuffled). This is accomplished using https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance and is covered in the notebook for Model Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3e7472b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_encoded</td>\n",
       "      <td>0.2466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent</td>\n",
       "      <td>0.1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_clean_Jeep</td>\n",
       "      <td>0.1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_Mileage</td>\n",
       "      <td>0.1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_Levy</td>\n",
       "      <td>0.1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cylinders_clean_7 or more</td>\n",
       "      <td>0.0405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic</td>\n",
       "      <td>0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cylinders_clean_5 or 6</td>\n",
       "      <td>0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Manufacturer_clean_Other</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_clean_Other</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturer_clean_NISSAN</td>\n",
       "      <td>0.0111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manufacturer_clean_HYUNDAI</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manufacturer_clean_VOLKSWAGEN</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manufacturer_clean_FORD</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Variable  Importance\n",
       "13                  Model_encoded      0.2466\n",
       "0                          Recent      0.1853\n",
       "4             Category_clean_Jeep      0.1633\n",
       "3                     log_Mileage      0.1404\n",
       "2                        log_Levy      0.1314\n",
       "7       Cylinders_clean_7 or more      0.0405\n",
       "1                       Automatic      0.0221\n",
       "6          Cylinders_clean_5 or 6      0.0173\n",
       "12       Manufacturer_clean_Other      0.0146\n",
       "5            Category_clean_Other      0.0135\n",
       "10      Manufacturer_clean_NISSAN      0.0111\n",
       "9      Manufacturer_clean_HYUNDAI      0.0067\n",
       "11  Manufacturer_clean_VOLKSWAGEN      0.0048\n",
       "8         Manufacturer_clean_FORD      0.0024"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Variable\": gradient_boosting_model.feature_names_in_, \"Importance\": gradient_boosting_model.feature_importances_}).sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988d415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "384px",
    "width": "384px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "520px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
